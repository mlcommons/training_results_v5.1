+ echo 'Beginning trial 4 of 5'
Beginning trial 4 of 5
+ echo ':::DLPAL /mnt/data/images/20251006/llama31_8b_20251006.sqsh 686 2 worker-[1,0] '\''unknown'\'' DGXB200_2x8x2xtp1pp1cp1_8b'
:::DLPAL /mnt/data/images/20251006/llama31_8b_20251006.sqsh 686 2 worker-[1,0] 'unknown' DGXB200_2x8x2xtp1pp1cp1_8b
++ srun -N1 -n1 --container-name=llama31_8b_686 --no-container-mount-home --container-remap-root --container-writable mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"2","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8580","host_processor_core_count":"40","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"1.7 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.09","framework_name":"","other_software_stack":{"cuda_version":"13.0.1.012","cuda_driver_version":"580.82.07","nccl_version":"v2.28.3-1","cublas_version":"13.0.2.14","cudnn_version":"9.13.1.26","trt_version":"10.13.3.9","dali_version":"1.51.2","mofed_version":"5.4-rdmacore56.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.11.0-1013-nvidia","nvidia_kernel_driver":"570.148.08"},"operating_system":"Ubuntu 24.04.3 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"2","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8580","host_processor_core_count":"40","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"1.7 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.09","framework_name":"","other_software_stack":{"cuda_version":"13.0.1.012","cuda_driver_version":"580.82.07","nccl_version":"v2.28.3-1","cublas_version":"13.0.2.14","cudnn_version":"9.13.1.26","trt_version":"10.13.3.9","dali_version":"1.51.2","mofed_version":"5.4-rdmacore56.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.11.0-1013-nvidia","nvidia_kernel_driver":"570.148.08"},"operating_system":"Ubuntu 24.04.3 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=llama31_8b_686 --no-container-mount-home --container-remap-root --container-writable bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID 06e7cd0aecce201e08e1cdaf9f598f58713ac6bc 
+ export SEED=19083
+ SEED=19083
+ '[' 1 -eq 1 ']'
+ srun --ntasks-per-node=1 bash -c '
                 host=$(hostname)
                 echo "$host sync_start"
                 sync && echo "$host sync_done"
                 cache_before=$(awk "/^Cached:/ {print \$2}" /proc/meminfo)
                 sudo /sbin/sysctl vm.drop_caches=3
                 cache_after=$(awk "/^Cached:/ {print \$2}" /proc/meminfo)
                 echo "$host cache_cleared ${cache_before}kB to ${cache_after}kB"
            '
worker-1 sync_start
worker-0 sync_start
worker-1 sync_done
worker-0 sync_done
vm.drop_caches = 3
worker-0 cache_cleared 106142628kB to 17939432kB
vm.drop_caches = 3
worker-1 cache_cleared 189348236kB to 101119748kB
+ srun --ntasks-per-node=1 --container-name=llama31_8b_686 --no-container-mount-home --container-remap-root --container-writable python -c '
from mlperf_common.callbacks import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
:::MLLOG {"namespace": "", "time_ms": 1759986855219, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1759986856312, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1759986859'
RUNANDTIME_START 1759986859
+ SLURM_HOSTFILE=/mnt/data/runs/b200n2/llama31_8b/logs/hostfile.686.ekxa
+ NV_MLPERF_DEBUG=1
+ srun -l --mpi=pmi2 --ntasks-per-node=8 --distribution=arbitrary --time=80 --container-name=llama31_8b_686 --no-container-mount-home --container-remap-root --container-writable --container-mounts=/mnt/data/runs/b200n2/llama31_8b/logs:/results,/mnt/data/runs/b200n2/llama31_8b/logs/251009022114975365827_npy_index:/npy_index,/mnt/data/runs/b200n2/llama31_8b/logs/mem_dump:/mem_dump,/mnt/data/datasets/llama31_8b/8b/tokenizer:/workspace/llm/nemo_tokenizer:ro,/mnt/data/datasets/llama31_8b/8b:/preproc_data:ro --container-workdir=/workspace/llm --container-env=MASTER_PORT,MASTER_ADDR,NCCL_SHARP_GROUP_SIZE_THRESH,NCCL_NVLS_ENABLE slurm2pytorch ./run_and_time.sh
 0: slurm2pytorch: MASTER_ADDR=worker-0 MASTER_PORT=29500 WORLD_SIZE=16
11: LOAD_CHECKPOINT=
10: LOAD_CHECKPOINT=
 8: LOAD_CHECKPOINT=
 8: Hello from: worker-1
 9: LOAD_CHECKPOINT=
14: LOAD_CHECKPOINT=
12: LOAD_CHECKPOINT=
15: LOAD_CHECKPOINT=
 3: LOAD_CHECKPOINT=
13: LOAD_CHECKPOINT=
 2: LOAD_CHECKPOINT=
 0: LOAD_CHECKPOINT=
 0: Hello from: worker-0
 0: running LLM benchmark
 0: Extra args:  exp_manager.explicit_log_dir="/results/251009022114975365827"
 5: LOAD_CHECKPOINT=
 7: LOAD_CHECKPOINT=
 6: LOAD_CHECKPOINT=
 1: LOAD_CHECKPOINT=
 4: LOAD_CHECKPOINT=
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 2: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 2:   import pynvml  # type: ignore[import]
 3: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 3:   import pynvml  # type: ignore[import]
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 0:   import pynvml  # type: ignore[import]
 8: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 8:   import pynvml  # type: ignore[import]
 9: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 9:   import pynvml  # type: ignore[import]
11: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
11:   import pynvml  # type: ignore[import]
10: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
10:   import pynvml  # type: ignore[import]
 7: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 7:   import pynvml  # type: ignore[import]
12: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
12:   import pynvml  # type: ignore[import]
13: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
13:   import pynvml  # type: ignore[import]
14: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
14:   import pynvml  # type: ignore[import]
15: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
15:   import pynvml  # type: ignore[import]
 4: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 4:   import pynvml  # type: ignore[import]
 1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 1:   import pynvml  # type: ignore[import]
 5: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 5:   import pynvml  # type: ignore[import]
 6: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 6:   import pynvml  # type: ignore[import]
 0: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 1: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 2: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 3: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 4: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 5: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 6: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 7: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 8: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 9: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
10: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
11: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
12: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
13: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
14: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
15: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 0: :::MLLOG {"namespace": "", "time_ms": 1759986902211, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 750}}
 0: [NeMo I 2025-10-09 05:15:02 nemo_logging:393] 
 0:     
 0:     **************** Experiment configuration ****************
 0: [NeMo I 2025-10-09 05:15:02 nemo_logging:393] 
 0:     model:
 0:       data:
 0:         data_prefix:
 0:           train:
 0:           - 0.5
 0:           - /preproc_data/c4_en_6_c4_spm_text_document
 0:           - 0.5
 0:           - /preproc_data/c4_en_7_c4_spm_text_document
 0:           validation:
 0:           - /preproc_data/c4_en_validation_subset_c4_spm_text_document
 0:           test:
 0:           - /preproc_data/c4_en_validation_subset_c4_spm_text_document
 0:         index_mapping_dir: /npy_index
 0:         splits_string: null
 0:         validation_drop_last: false
 0:         pad_samples_to_global_batch_size: true
 0:         shuffle_documents: false
 0:         legacy_dataset: true
 0:         delay_data_init: true
 0:         delay_data_mmap: true
 0:         no_seqlen_plus_one_input_tokens: true
 0:         exchange_indices_distributed: true
 0:         mock_dataset: false
 0:         mock_tokenizer_vocab_size: 32000
 0:       mcore_gpt: true
 0:       name: megatron_gpt_full_te_layer_autocast
 0:       micro_batch_size: 1
 0:       tensor_model_parallel_size: 1
 0:       pipeline_model_parallel_size: 1
 0:       virtual_pipeline_model_parallel_size: null
 0:       context_parallel_size: 1
 0:       expert_model_parallel_size: 1
 0:       global_batch_size: 32
 0:       use_tp_pp_dp_mapping: true
 0:       base_config: 8b
 0:       overwritten_attributes:
 0:         num_layers: 32
 0:         enable_cuda_graph: 1
 0:         cuda_graph_scope: full_iteration
 0:       encoder_seq_length: 8192
 0:       overlap_p2p_comm: true
 0:       batch_p2p_comm: false
 0:       account_for_embedding_in_pipeline_split: false
 0:       account_for_loss_in_pipeline_split: false
 0:       external_cuda_graph: false
 0:       defer_embedding_wgrad_compute: false
 0:       wgrad_deferral_limit: 50
 0:       tokenizer:
 0:         model: /workspace/llm/nemo_tokenizer
 0:       gradient_accumulation_fusion: true
 0:       fused_single_qkv_rope: true
 0:       cross_entropy_loss_fusion: true
 0:       deterministic_mode: false
 0:       seed: 19083
 0:       resume_from_checkpoint: null
 0:       dist_ckpt_format: torch_dist
 0:       dist_ckpt_parallel_load: true
 0:       sync_batch_comm: false
 0:       activations_checkpoint_granularity: null
 0:       activations_checkpoint_method: null
 0:       activations_checkpoint_num_layers: null
 0:       sequence_parallel: false
 0:       transformer_engine: true
 0:       fp8: false
 0:       fp8_hybrid: true
 0:       fp8_recipe: tensorwise
 0:       fp8_amax_history_len: 1
 0:       fp8_amax_compute_algo: most_recent
 0:       fp4: true
 0:       fp4_recipe: nvfp4
 0:       reduce_amax: true
 0:       tp_only_amax_red: true
 0:       first_last_layers_bf16: false
 0:       num_layers_at_start_in_bf16: 0
 0:       num_layers_at_end_in_bf16: 0
 0:       fp8_dot_product_attention: true
 0:       use_te_rng_tracker: true
 0:       use_transformer_engine_op_fuser: true
 0:       cross_entropy_fusion_impl: te
 0:       ub_tp_comm_overlap: false
 0:       tp_comm_overlap_ag: true
 0:       tp_comm_overlap_rs: true
 0:       nccl_communicator_config_path: /workspace/llm/conf/nccl/custom_communicator_cta.yaml
 0:       sharp: false
 0:       optim:
 0:         overlap_grad_reduce: true
 0:         overlap_param_gather: true
 0:         align_param_gather: false
 0:         use_distributed_optimizer: true
 0:         bucket_size: 134217728
 0:         fp8_param_gather: false
 0:         overlap_param_gather_with_optim_step: false
 0:         lr: 0.0008
 0:         sched:
 0:           min_lr: 8.0e-05
 0:           warmup_steps: 192
 0:           max_steps_for_lr_sched: 43200000.0
 0:         lock_timeout: null
 0:       gc_interval_train: 10000
 0:       gc_interval_valid: 10000
 0:       nsys_profile:
 0:         enabled: false
 0:         start_step: 10
 0:         end_step: 10
 0:         ranks:
 0:         - 0
 0:         gen_shape: false
 0:         nvtx_ranges: false
 0:       custom:
 0:         log_metrics: NEMO
 0:         init_global_step: 0
 0:         target_log_ppl: 3.3
 0:         use_distributed_checkpointing: 1
 0:         run_warmup_on_synth_data: 1
 0:         reset_fp8_stats_after_warmup: 1
 0:         pre_validate: 0
 0:         override_zero_consumed_samples: 1
 0:         force_success_status: 0
 0:         warmup_train_steps: 2
 0:         warmup_validation_steps: 2
 0:         extend_run_evals: 0
 0:         disable_nemo_logs: true
 0:     proxy_gbs: 32
 0:     is_proxy_run: false
 0:     skip_evals: 12
 0:     default_val_check_interval: 384
 0:     trainer:
 0:       devices: 8
 0:       num_nodes: 2
 0:       precision: bf16
 0:       max_steps: 1200000
 0:       max_epochs: 1
 0:       log_every_n_steps: 32
 0:       val_check_interval: 384
 0:       limit_val_batches: 32
 0:       limit_test_batches: 1
 0:       limit_train_batches: null
 0:       enable_progress_bar: false
 0:       num_sanity_val_steps: 0
 0:     exp_manager:
 0:       explicit_log_dir: /results/251009022114975365827
 0:       resume_if_exists: 0
 0:       create_checkpoint_callback: 0
 0:       checkpoint_callback_params:
 0:         save_top_k: 1
 0:         mode: max
 0:         every_n_epochs: 0
 0:         save_last: true
 0:       log_step_timing: true
 0:       create_tensorboard_logger: false
 0:       log_global_rank_0_only: true
 0:     misc:
 0:       print_config: false
 0:       memory_profiler:
 0:         enable: false
 0:         file_prefix: memdump
 0:         max_entries: 1000000
 0:         rank_0_only: true
 0:         start_location: init
 0:         end_location: train_start
 0:         force_oom_before_stop: false
 0:         possible_oom: false
 0:     
 0: [NeMo I 2025-10-09 05:15:02 nemo_logging:393] 
 0:     TP: 1; PP: 1; VP: None; CP: 1
 0: [NeMo I 2025-10-09 05:15:02 nemo_logging:393] ======== Benchmarked setups ========
 0: GPU available: True (cuda), used: True
 0: TPU available: False, using: 0 TPU cores
 0: HPU available: False, using: 0 HPUs
 0: `Trainer(limit_test_batches=1)` was configured so 1 batch will be used.
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903135, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama31_8b", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903135, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903135, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903135, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903135, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "2xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903135, "event_type": "POINT_IN_TIME", "key": "seed", "value": 19083, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903135, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 32, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903136, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 2.0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903136, "event_type": "POINT_IN_TIME", "key": "max_sequence_length", "value": 8192, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903136, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 1024, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903136, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1574207408, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903136, "event_type": "POINT_IN_TIME", "key": "init_checkpoint_step", "value": 0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903136, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903136, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0008, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903137, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903137, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.95, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903137, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-05, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903137, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.1, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903137, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 1.0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903137, "event_type": "POINT_IN_TIME", "key": "opt_end_learning_rate", "value": 8e-05, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903137, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 192, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903137, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_steps", "value": 1199808, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903138, "event_type": "POINT_IN_TIME", "key": "max_steps", "value": 1200000, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903138, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_schedule", "value": "cosine with linear warmup", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759986903138, "event_type": "POINT_IN_TIME", "key": "target_accuracy", "value": 3.3, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] ======== Benchmarked fit ========
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Experiments will be logged at /workspace/llm/nemo_experiments/default/2025-10-09_05-15-03
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has data parallel group : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Ranks 0 has data parallel rank: 0
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has context parallel group: [0]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Ranks 0 has context parallel rank: 0
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has model parallel group: [0]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] All model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has tensor model parallel group: [0]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] All tensor model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has tensor model parallel rank: 0
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has embedding group: [0]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has pipeline model parallel rank 0
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
 0: [NeMo I 2025-10-09 05:15:03 nemo_logging:393] Rank 0 has embedding rank: 0
 0: [AUX I 2025-10-09 05:15:03 megatron_strategy:607] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/16
 1: [W1009 05:15:03.028427549 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 2: [W1009 05:15:03.028438799 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 3: [W1009 05:15:03.028438410 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 4: [W1009 05:15:03.028460442 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 5: [W1009 05:15:03.028460513 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 7: [W1009 05:15:03.028460070 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 6: [W1009 05:15:03.066772602 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
14: [W1009 05:15:05.039485651 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
11: [W1009 05:15:05.040249147 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 8: [W1009 05:15:05.051319645 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
12: [W1009 05:15:05.055177421 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
15: [W1009 05:15:05.056110627 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
10: [W1009 05:15:05.060057535 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
13: [W1009 05:15:05.060979011 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 9: [W1009 05:15:05.061426835 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 0: [W1009 05:15:05.001691911 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 0: ----------------------------------------------------------------------------------------------------
 0: distributed_backend=nccl
 0: All distributed processes registered. Starting with 16 processes
 0: ----------------------------------------------------------------------------------------------------
 0: 
 0: [Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 1: [Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 2: [Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 3: [Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 4: [Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 5: [Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 8: [Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
13: [Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 6: [Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
10: [Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 9: [Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
11: [Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
12: [Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
14: [Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 7: [Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
15: [Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 0: [Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 1: [Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 2: [Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 3: [Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
14: [Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 4: [Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 5: [Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 6: [Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
10: [Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 9: [Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 8: [Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
12: [Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
13: [Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
11: [Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 7: [Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
15: [Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 8: [Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 9: [Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
12: [Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
13: [Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 0: [Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 1: [Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 2: [Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 3: [Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
15: [Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
10: [Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
11: [Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 4: [Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 5: [Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 6: [Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
14: [Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 7: [Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
 0: [NeMo I 2025-10-09 05:15:10 utils:662] Building GPTDataset splits with sizes=[38400000, 3201024, 32] and config=GPTDatasetConfig(random_seed=19083, sequence_length=8192, blend=None, blend_per_split=[(['/preproc_data/c4-train.en_6_text_document'], [50.0]), (['/preproc_data/c4-validation-91205-samples.en_text_document'], None), (['/preproc_data/c4-validation-91205-samples.en_text_document'], None)], multiple_validation_sets=None, full_validation=None, split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache='/npy_index', mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.huggingface.auto_tokenizer.AutoTokenizer object at 0x87b9f451730>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)
 0: [NeMo I 2025-10-09 05:15:10 utils:662] Load the _IndexReader from /preproc_data/c4-train.en_6_text_document.idx
 0: [NeMo I 2025-10-09 05:15:10 utils:662] 	Extract the sequence lengths
 0: [NeMo I 2025-10-09 05:15:10 utils:662] 	Extract the sequence pointers
 0: [NeMo I 2025-10-09 05:15:10 utils:662] 	Extract the document indices
 0: [NeMo I 2025-10-09 05:15:10 utils:662] > total number of sequences: 45608611
 0: [NeMo I 2025-10-09 05:15:10 utils:662] > total number of documents: 45608611
 0: [NeMo I 2025-10-09 05:15:10 utils:662] Build and save the GPTDataset train indices
 0: [NeMo I 2025-10-09 05:15:58 utils:662] > total number of samples: 38441516
 0: [NeMo I 2025-10-09 05:15:58 utils:662] > total number of epochs: 15
 0: [NeMo I 2025-10-09 05:15:58 utils:662] Load the _IndexReader from /preproc_data/c4-validation-91205-samples.en_text_document.idx
 0: [NeMo I 2025-10-09 05:15:58 utils:662] 	Extract the sequence lengths
 0: [NeMo I 2025-10-09 05:15:58 utils:662] 	Extract the sequence pointers
 0: [NeMo I 2025-10-09 05:15:58 utils:662] 	Extract the document indices
 0: [NeMo I 2025-10-09 05:15:58 utils:662] > total number of sequences: 91205
 0: [NeMo I 2025-10-09 05:15:58 utils:662] > total number of documents: 91205
 0: [NeMo I 2025-10-09 05:15:58 utils:662] Build and save the GPTDataset valid indices
 0: [NeMo I 2025-10-09 05:16:01 utils:662] > total number of samples: 3202455
 0: [NeMo I 2025-10-09 05:16:01 utils:662] > total number of epochs: 630
 0: [NeMo I 2025-10-09 05:16:01 utils:662] Load the _IndexReader from /preproc_data/c4-validation-91205-samples.en_text_document.idx
 0: [NeMo I 2025-10-09 05:16:01 utils:662] 	Extract the sequence lengths
 0: [NeMo I 2025-10-09 05:16:01 utils:662] 	Extract the sequence pointers
 0: [NeMo I 2025-10-09 05:16:01 utils:662] 	Extract the document indices
 0: [NeMo I 2025-10-09 05:16:01 utils:662] > total number of sequences: 91205
 0: [NeMo I 2025-10-09 05:16:01 utils:662] > total number of documents: 91205
 0: [NeMo I 2025-10-09 05:16:01 utils:662] Build and save the GPTDataset test indices
 0: [NeMo I 2025-10-09 05:16:01 utils:662] > total number of samples: 5083
 0: [NeMo I 2025-10-09 05:16:01 utils:662] > total number of epochs: 1
 0: [NeMo W 2025-10-09 05:16:01 nemo_logging:405] Recommend unsetting CUDA_DEVICE_MAX_CONNECTIONS for best performance                         but get 1
 0: [NeMo I 2025-10-09 05:16:01 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.
 0: [NeMo I 2025-10-09 05:16:01 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.
 3: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 5: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 6: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 2: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 4: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 7: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-09 05:16:01 nemo_logging:393] Copying Trainer's 'max_steps' (1200000) to LR scheduler's 'max_steps'.
 0: [NeMo I 2025-10-09 05:16:01 num_microbatches_calculator:228] setting number of microbatches to constant 2
 0: [NeMo I 2025-10-09 05:16:01 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 8030261248
 0: [NeMo I 2025-10-09 05:16:01 utils:662] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=False, check_for_large_grads=False, bucket_size=134217728, pad_buckets_for_high_nccl_busbw=False, average_in_collective=True, fp8_param_gather=False, reuse_grad_buf_for_mxfp8_param_ag=False, use_megatron_fsdp=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache=False, nccl_ub=False, fsdp_double_buffer=False, outer_dp_sharding_strategy='no_shard', disable_symmetric_registration=False, delay_wgrad_compute=False)
 0: [NeMo I 2025-10-09 05:16:01 utils:695] Number of buckets for gradient all-reduce / reduce-scatter: 34
 0:     Params for bucket 1 (525336576 elements, 525336576 padded size):
 0:     	module.output_layer.weight
 0:     Params for bucket 2 (176164864 elements, 176164864 padded size):
 0:     	module.decoder.final_layernorm.weight
 0:     	module.decoder.layers.31.mlp.linear_fc1.weight
 0:     	module.decoder.layers.31.mlp.linear_fc2.weight
 0:     Params for bucket 3 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.31.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.30.mlp.linear_fc1.weight
 0:     	module.decoder.layers.31.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.31.self_attention.linear_proj.weight
 0:     	module.decoder.layers.31.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.30.mlp.linear_fc2.weight
 0:     Params for bucket 4 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.30.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.29.mlp.linear_fc1.weight
 0:     	module.decoder.layers.30.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.30.self_attention.linear_proj.weight
 0:     	module.decoder.layers.30.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.29.mlp.linear_fc2.weight
 0:     Params for bucket 5 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.29.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.28.mlp.linear_fc1.weight
 0:     	module.decoder.layers.29.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.29.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.28.mlp.linear_fc2.weight
 0:     	module.decoder.layers.29.self_attention.linear_proj.weight
 0:     Params for bucket 6 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.28.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.27.mlp.linear_fc1.weight
 0:     	module.decoder.layers.28.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.28.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.27.mlp.linear_fc2.weight
 0:     	module.decoder.layers.28.self_attention.linear_proj.weight
 0:     Params for bucket 7 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.27.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.26.mlp.linear_fc1.weight
 0:     	module.decoder.layers.27.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.26.mlp.linear_fc2.weight
 0:     	module.decoder.layers.27.self_attention.linear_proj.weight
 0:     	module.decoder.layers.27.self_attention.linear_qkv.weight
 0:     Params for bucket 8 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.26.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.25.mlp.linear_fc1.weight
 0:     	module.decoder.layers.26.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.25.mlp.linear_fc2.weight
 0:     	module.decoder.layers.26.self_attention.linear_proj.weight
 0:     	module.decoder.layers.26.self_attention.linear_qkv.weight
 0:     Params for bucket 9 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.25.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.24.mlp.linear_fc1.weight
 0:     	module.decoder.layers.25.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.24.mlp.linear_fc2.weight
 0:     	module.decoder.layers.25.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.25.self_attention.linear_proj.weight
 0:     Params for bucket 10 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.23.mlp.linear_fc1.weight
 0:     	module.decoder.layers.24.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.24.self_attention.linear_proj.weight
 0:     	module.decoder.layers.24.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.23.mlp.linear_fc2.weight
 0:     Params for bucket 11 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.22.mlp.linear_fc1.weight
 0:     	module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.23.self_attention.linear_proj.weight
 0:     	module.decoder.layers.23.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.22.mlp.linear_fc2.weight
 0:     Params for bucket 12 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.21.mlp.linear_fc1.weight
 0:     	module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.22.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.21.mlp.linear_fc2.weight
 0:     	module.decoder.layers.22.self_attention.linear_proj.weight
 0:     Params for bucket 13 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.20.mlp.linear_fc1.weight
 0:     	module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.21.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.20.mlp.linear_fc2.weight
 0:     	module.decoder.layers.21.self_attention.linear_proj.weight
 0:     Params for bucket 14 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.19.mlp.linear_fc1.weight
 0:     	module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.20.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.19.mlp.linear_fc2.weight
 0:     	module.decoder.layers.20.self_attention.linear_proj.weight
 0:     Params for bucket 15 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.18.mlp.linear_fc1.weight
 0:     	module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.18.mlp.linear_fc2.weight
 0:     	module.decoder.layers.19.self_attention.linear_proj.weight
 0:     	module.decoder.layers.19.self_attention.linear_qkv.weight
 0:     Params for bucket 16 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.17.mlp.linear_fc1.weight
 0:     	module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.17.mlp.linear_fc2.weight
 0:     	module.decoder.layers.18.self_attention.linear_proj.weight
 0:     	module.decoder.layers.18.self_attention.linear_qkv.weight
 0:     Params for bucket 17 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.16.mlp.linear_fc1.weight
 0:     	module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.17.self_attention.linear_proj.weight
 0:     	module.decoder.layers.17.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.16.mlp.linear_fc2.weight
 0:     Params for bucket 18 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.15.mlp.linear_fc2.weight
 0:     	module.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.16.self_attention.linear_proj.weight
 0:     	module.decoder.layers.16.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.15.mlp.linear_fc1.weight
 0:     Params for bucket 19 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.14.mlp.linear_fc2.weight
 0:     	module.decoder.layers.15.self_attention.linear_proj.weight
 0:     	module.decoder.layers.15.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.14.mlp.linear_fc1.weight
 0:     Params for bucket 20 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.14.self_attention.linear_proj.weight
 0:     	module.decoder.layers.14.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.13.mlp.linear_fc1.weight
 0:     	module.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.13.mlp.linear_fc2.weight
 0:     Params for bucket 21 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.12.mlp.linear_fc1.weight
 0:     	module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.13.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.12.mlp.linear_fc2.weight
 0:     	module.decoder.layers.13.self_attention.linear_proj.weight
 0:     Params for bucket 22 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.11.mlp.linear_fc2.weight
 0:     	module.decoder.layers.12.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.11.mlp.linear_fc1.weight
 0:     	module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.12.self_attention.linear_proj.weight
 0:     Params for bucket 23 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.11.self_attention.linear_proj.weight
 0:     	module.decoder.layers.11.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.10.mlp.linear_fc1.weight
 0:     	module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.10.mlp.linear_fc2.weight
 0:     Params for bucket 24 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.9.mlp.linear_fc2.weight
 0:     	module.decoder.layers.9.mlp.linear_fc1.weight
 0:     	module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.10.self_attention.linear_proj.weight
 0:     	module.decoder.layers.10.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight
 0:     Params for bucket 25 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.9.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.8.mlp.linear_fc2.weight
 0:     	module.decoder.layers.9.self_attention.linear_proj.weight
 0:     	module.decoder.layers.8.mlp.linear_fc1.weight
 0:     Params for bucket 26 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.7.mlp.linear_fc2.weight
 0:     	module.decoder.layers.8.self_attention.linear_proj.weight
 0:     	module.decoder.layers.8.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.7.mlp.linear_fc1.weight
 0:     Params for bucket 27 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.7.self_attention.linear_proj.weight
 0:     	module.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.7.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.6.mlp.linear_fc2.weight
 0:     	module.decoder.layers.6.mlp.linear_fc1.weight
 0:     Params for bucket 28 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.6.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.5.mlp.linear_fc1.weight
 0:     	module.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.5.mlp.linear_fc2.weight
 0:     	module.decoder.layers.6.self_attention.linear_proj.weight
 0:     Params for bucket 29 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.5.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.4.mlp.linear_fc2.weight
 0:     	module.decoder.layers.5.self_attention.linear_proj.weight
 0:     	module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.4.mlp.linear_fc1.weight
 0:     Params for bucket 30 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.4.self_attention.linear_proj.weight
 0:     	module.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.4.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.3.mlp.linear_fc2.weight
 0:     	module.decoder.layers.3.mlp.linear_fc1.weight
 0:     Params for bucket 31 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.3.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.2.mlp.linear_fc1.weight
 0:     	module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.2.mlp.linear_fc2.weight
 0:     	module.decoder.layers.3.self_attention.linear_proj.weight
 0:     Params for bucket 32 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.2.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.2.self_attention.linear_proj.weight
 0:     	module.decoder.layers.1.mlp.linear_fc1.weight
 0:     	module.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.1.mlp.linear_fc2.weight
 0:     Params for bucket 33 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.0.mlp.linear_fc1.weight
 0:     	module.decoder.layers.1.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.0.mlp.linear_fc2.weight
 0:     	module.decoder.layers.1.self_attention.linear_proj.weight
 0:     Params for bucket 34 (567287808 elements, 567287808 padded size):
 0:     	module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
 0:     	module.embedding.word_embeddings.weight
 0:     	module.decoder.layers.0.self_attention.linear_proj.weight
 0:     	module.decoder.layers.0.self_attention.linear_qkv.weight
 0: [NeMo I 2025-10-09 05:16:01 utils:662] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0008, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp8_recipe='tensorwise', fp16=False, bf16=True, reuse_grad_buf_for_mxfp8_param_ag=False, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_ti
 0: me=False, timers=None, config_logger_dir='')
13: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
12: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 8: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 9: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
14: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
11: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
10: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
15: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: 
 0:   | Name   | Type | Params | Mode 
 0: ----------------------------------------
 0: 0 | module | DDP  | 8.0 B  | train
 0: ----------------------------------------
 0: 8.0 B     Trainable params
 0: 0         Non-trainable params
 0: 8.0 B     Total params
 0: 32,121.045Total estimated model params size (MB)
 0: 651       Modules in train mode
 0: 0         Modules in eval mode
 8: SLURM auto-requeueing enabled. Setting signal handlers.
 9: SLURM auto-requeueing enabled. Setting signal handlers.
10: SLURM auto-requeueing enabled. Setting signal handlers.
11: SLURM auto-requeueing enabled. Setting signal handlers.
12: SLURM auto-requeueing enabled. Setting signal handlers.
13: SLURM auto-requeueing enabled. Setting signal handlers.
14: SLURM auto-requeueing enabled. Setting signal handlers.
15: SLURM auto-requeueing enabled. Setting signal handlers.
 0: SLURM auto-requeueing enabled. Setting signal handlers.
 2: SLURM auto-requeueing enabled. Setting signal handlers.
 1: SLURM auto-requeueing enabled. Setting signal handlers.
 3: SLURM auto-requeueing enabled. Setting signal handlers.
 4: SLURM auto-requeueing enabled. Setting signal handlers.
 5: SLURM auto-requeueing enabled. Setting signal handlers.
 6: SLURM auto-requeueing enabled. Setting signal handlers.
 7: SLURM auto-requeueing enabled. Setting signal handlers.
 0: [AUX I 2025-10-09 05:16:02 data:291] Instantiating MegatronPretrainingSampler with total_samples: 38441516 and consumed_samples: 0
 0: [AUX I 2025-10-09 05:16:02 data:291] Instantiating MegatronPretrainingSampler with total_samples: 3202455 and consumed_samples: 0
 8: GPTModel(
 8:   (embedding): LanguageModelEmbedding(
 8:     (word_embeddings): VocabParallelEmbedding()
 8:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 8:   )
 8:   (rotary_pos_emb): RotaryEmbedding()
 8:   (decoder): TransformerBlock(
 8:     (layers): ModuleList(
 8:       (0-31): 32 x TransformerLayer(
 8:         (input_layernorm): IdentityOp()
 8:         (self_attention): SelfAttention(
 8:           (core_attention): TEDotProductAttention(
 8:             (flash_attention): FlashAttention()
 8:             (fused_attention): FusedAttention()
 8:             (unfused_attention): UnfusedDotProductAttention(
 8:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 8:               (attention_dropout): Dropout(p=0.0, inplace=False)
 8:             )
 8:           )
 8:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 8:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 8:           (q_layernorm): IdentityOp()
 8:           (k_layernorm): IdentityOp()
 5: GPTModel(
 5:   (embedding): LanguageModelEmbedding(
 5:     (word_embeddings): VocabParallelEmbedding()
 5:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 5:   )
 5:   (rotary_pos_emb): RotaryEmbedding()
 5:   (decoder): TransformerBlock(
 5:     (layers): ModuleList(
 5:       (0-31): 32 x TransformerLayer(
 5:         (input_layernorm): IdentityOp()
 5:         (self_attention): SelfAttention(
 5:           (core_attention): TEDotProductAttention(
 5:             (flash_attention): FlashAttention()
 5:             (fused_attention): FusedAttention()
 5:             (unfused_attention): UnfusedDotProductAttention(
 5:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 5:               (attention_dropout): Dropout(p=0.0, inplace=False)
 5:             )
 5:           )
 5:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 5:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 5:           (q_layernorm): IdentityOp()
 5:           (k_layernorm): IdentityOp()
 8:         )
 8:         (pre_cross_attn_layernorm): IdentityOp()
 8:         (cross_attention): IdentityOp()
 8:         (cross_attn_bda): IdentityFuncOp()
 8:         (pre_mlp_layernorm): IdentityOp()
 8:         (mlp): TEFusedMLP(
 8:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 8:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 8:         )
 8:       )
 8:     )
 8:     (final_layernorm): RMSNorm()
 8:   )
 8:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 8: )
 5:         )
 5:         (pre_cross_attn_layernorm): IdentityOp()
 5:         (cross_attention): IdentityOp()
 5:         (cross_attn_bda): IdentityFuncOp()
 5:         (pre_mlp_layernorm): IdentityOp()
 5:         (mlp): TEFusedMLP(
 5:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 5:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 5:         )
 5:       )
 5:     )
 5:     (final_layernorm): RMSNorm()
 5:   )
 5:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 5: )
 9: GPTModel(
 9:   (embedding): LanguageModelEmbedding(
 9:     (word_embeddings): VocabParallelEmbedding()
 9:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 9:   )
 9:   (rotary_pos_emb): RotaryEmbedding()
 9:   (decoder): TransformerBlock(
 9:     (layers): ModuleList(
 9:       (0-31): 32 x TransformerLayer(
 9:         (input_layernorm): IdentityOp()
 9:         (self_attention): SelfAttention(
 9:           (core_attention): TEDotProductAttention(
 9:             (flash_attention): FlashAttention()
 9:             (fused_attention): FusedAttention()
 9:             (unfused_attention): UnfusedDotProductAttention(
 9:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 9:               (attention_dropout): Dropout(p=0.0, inplace=False)
 9:             )
 9:           )
 9:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 9:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 9:           (q_layernorm): IdentityOp()
 9:           (k_layernorm): IdentityOp()
 6: GPTModel(
 6:   (embedding): LanguageModelEmbedding(
 6:     (word_embeddings): VocabParallelEmbedding()
 6:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 6:   )
 6:   (rotary_pos_emb): RotaryEmbedding()
 6:   (decoder): TransformerBlock(
 6:     (layers): ModuleList(
 6:       (0-31): 32 x TransformerLayer(
 6:         (input_layernorm): IdentityOp()
 6:         (self_attention): SelfAttention(
 6:           (core_attention): TEDotProductAttention(
 6:             (flash_attention): FlashAttention()
 6:             (fused_attention): FusedAttention()
 6:             (unfused_attention): UnfusedDotProductAttention(
 6:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 6:               (attention_dropout): Dropout(p=0.0, inplace=False)
 6:             )
 6:           )
 6:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 6:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 6:           (q_layernorm): IdentityOp()
 6:           (k_layernorm): IdentityOp()
 9:         )
 9:         (pre_cross_attn_layernorm): IdentityOp()
 9:         (cross_attention): IdentityOp()
 9:         (cross_attn_bda): IdentityFuncOp()
 9:         (pre_mlp_layernorm): IdentityOp()
 9:         (mlp): TEFusedMLP(
 9:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 9:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 9:         )
 9:       )
 9:     )
 9:     (final_layernorm): RMSNorm()
 9:   )
 9:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 9: )
 6:         )
 6:         (pre_cross_attn_layernorm): IdentityOp()
 6:         (cross_attention): IdentityOp()
 6:         (cross_attn_bda): IdentityFuncOp()
 6:         (pre_mlp_layernorm): IdentityOp()
 6:         (mlp): TEFusedMLP(
 6:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 6:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 6:         )
 6:       )
 6:     )
 6:     (final_layernorm): RMSNorm()
 6:   )
 6:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 6: )
10: GPTModel(
10:   (embedding): LanguageModelEmbedding(
10:     (word_embeddings): VocabParallelEmbedding()
10:     (embedding_dropout): Dropout(p=0.0, inplace=False)
10:   )
10:   (rotary_pos_emb): RotaryEmbedding()
10:   (decoder): TransformerBlock(
10:     (layers): ModuleList(
10:       (0-31): 32 x TransformerLayer(
10:         (input_layernorm): IdentityOp()
10:         (self_attention): SelfAttention(
10:           (core_attention): TEDotProductAttention(
10:             (flash_attention): FlashAttention()
10:             (fused_attention): FusedAttention()
10:             (unfused_attention): UnfusedDotProductAttention(
10:               (scale_mask_softmax): FusedScaleMaskSoftmax()
10:               (attention_dropout): Dropout(p=0.0, inplace=False)
10:             )
10:           )
10:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
10:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
10:           (q_layernorm): IdentityOp()
10:           (k_layernorm): IdentityOp()
 7: GPTModel(
 7:   (embedding): LanguageModelEmbedding(
 7:     (word_embeddings): VocabParallelEmbedding()
 7:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 7:   )
 7:   (rotary_pos_emb): RotaryEmbedding()
 7:   (decoder): TransformerBlock(
 7:     (layers): ModuleList(
 7:       (0-31): 32 x TransformerLayer(
 7:         (input_layernorm): IdentityOp()
 7:         (self_attention): SelfAttention(
 7:           (core_attention): TEDotProductAttention(
 7:             (flash_attention): FlashAttention()
 7:             (fused_attention): FusedAttention()
 7:             (unfused_attention): UnfusedDotProductAttention(
 7:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 7:               (attention_dropout): Dropout(p=0.0, inplace=False)
 7:             )
 7:           )
 7:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 7:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 7:           (q_layernorm): IdentityOp()
 7:           (k_layernorm): IdentityOp()
10:         )
10:         (pre_cross_attn_layernorm): IdentityOp()
10:         (cross_attention): IdentityOp()
10:         (cross_attn_bda): IdentityFuncOp()
10:         (pre_mlp_layernorm): IdentityOp()
10:         (mlp): TEFusedMLP(
10:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
10:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
10:         )
10:       )
10:     )
10:     (final_layernorm): RMSNorm()
10:   )
10:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
10: )
 7:         )
 7:         (pre_cross_attn_layernorm): IdentityOp()
 7:         (cross_attention): IdentityOp()
 7:         (cross_attn_bda): IdentityFuncOp()
 7:         (pre_mlp_layernorm): IdentityOp()
 7:         (mlp): TEFusedMLP(
 7:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 7:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 7:         )
 7:       )
 7:     )
 7:     (final_layernorm): RMSNorm()
 7:   )
 7:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 7: )
11: GPTModel(
11:   (embedding): LanguageModelEmbedding(
11:     (word_embeddings): VocabParallelEmbedding()
11:     (embedding_dropout): Dropout(p=0.0, inplace=False)
11:   )
11:   (rotary_pos_emb): RotaryEmbedding()
11:   (decoder): TransformerBlock(
11:     (layers): ModuleList(
11:       (0-31): 32 x TransformerLayer(
11:         (input_layernorm): IdentityOp()
11:         (self_attention): SelfAttention(
11:           (core_attention): TEDotProductAttention(
11:             (flash_attention): FlashAttention()
11:             (fused_attention): FusedAttention()
11:             (unfused_attention): UnfusedDotProductAttention(
11:               (scale_mask_softmax): FusedScaleMaskSoftmax()
11:               (attention_dropout): Dropout(p=0.0, inplace=False)
11:             )
11:           )
11:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
11:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
11:           (q_layernorm): IdentityOp()
11:           (k_layernorm): IdentityOp()
 0: GPTModel(
 0:   (embedding): LanguageModelEmbedding(
 0:     (word_embeddings): VocabParallelEmbedding()
 0:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 0:   )
 0:   (rotary_pos_emb): RotaryEmbedding()
 0:   (decoder): TransformerBlock(
 0:     (layers): ModuleList(
 0:       (0-31): 32 x TransformerLayer(
 0:         (input_layernorm): IdentityOp()
 0:         (self_attention): SelfAttention(
 0:           (core_attention): TEDotProductAttention(
 0:             (flash_attention): FlashAttention()
 0:             (fused_attention): FusedAttention()
 0:             (unfused_attention): UnfusedDotProductAttention(
 0:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 0:               (attention_dropout): Dropout(p=0.0, inplace=False)
 0:             )
 0:           )
 0:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 0:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 0:           (q_layernorm): IdentityOp()
 0:           (k_layernorm): IdentityOp()
11:         )
11:         (pre_cross_attn_layernorm): IdentityOp()
11:         (cross_attention): IdentityOp()
11:         (cross_attn_bda): IdentityFuncOp()
11:         (pre_mlp_layernorm): IdentityOp()
11:         (mlp): TEFusedMLP(
11:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
11:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
11:         )
11:       )
11:     )
11:     (final_layernorm): RMSNorm()
11:   )
11:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
11: )
 0:         )
 0:         (pre_cross_attn_layernorm): IdentityOp()
 0:         (cross_attention): IdentityOp()
 0:         (cross_attn_bda): IdentityFuncOp()
 0:         (pre_mlp_layernorm): IdentityOp()
 0:         (mlp): TEFusedMLP(
 0:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 0:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 0:         )
 0:       )
 0:     )
 0:     (final_layernorm): RMSNorm()
 0:   )
 0:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 0: )
13: GPTModel(
13:   (embedding): LanguageModelEmbedding(
13:     (word_embeddings): VocabParallelEmbedding()
13:     (embedding_dropout): Dropout(p=0.0, inplace=False)
13:   )
13:   (rotary_pos_emb): RotaryEmbedding()
13:   (decoder): TransformerBlock(
13:     (layers): ModuleList(
13:       (0-31): 32 x TransformerLayer(
13:         (input_layernorm): IdentityOp()
13:         (self_attention): SelfAttention(
13:           (core_attention): TEDotProductAttention(
13:             (flash_attention): FlashAttention()
13:             (fused_attention): FusedAttention()
13:             (unfused_attention): UnfusedDotProductAttention(
13:               (scale_mask_softmax): FusedScaleMaskSoftmax()
13:               (attention_dropout): Dropout(p=0.0, inplace=False)
13:             )
13:           )
13:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
13:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
13:           (q_layernorm): IdentityOp()
13:           (k_layernorm): IdentityOp()
 0: 
 0: MCore config:
13:         )
13:         (pre_cross_attn_layernorm): IdentityOp()
13:         (cross_attention): IdentityOp()
13:         (cross_attn_bda): IdentityFuncOp()
13:         (pre_mlp_layernorm): IdentityOp()
13:         (mlp): TEFusedMLP(
13:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
13:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
13:         )
13:       )
13:     )
13:     (final_layernorm): RMSNorm()
13:   )
13:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
13: )
 1: GPTModel(
 1:   (embedding): LanguageModelEmbedding(
 1:     (word_embeddings): VocabParallelEmbedding()
 1:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 1:   )
 1:   (rotary_pos_emb): RotaryEmbedding()
 1:   (decoder): TransformerBlock(
 1:     (layers): ModuleList(
 1:       (0-31): 32 x TransformerLayer(
 1:         (input_layernorm): IdentityOp()
 1:         (self_attention): SelfAttention(
 1:           (core_attention): TEDotProductAttention(
 1:             (flash_attention): FlashAttention()
 1:             (fused_attention): FusedAttention()
 1:             (unfused_attention): UnfusedDotProductAttention(
 1:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 1:               (attention_dropout): Dropout(p=0.0, inplace=False)
 1:             )
 1:           )
 1:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 1:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 1:           (q_layernorm): IdentityOp()
 1:           (k_layernorm): IdentityOp()
15: GPTModel(
15:   (embedding): LanguageModelEmbedding(
15:     (word_embeddings): VocabParallelEmbedding()
15:     (embedding_dropout): Dropout(p=0.0, inplace=False)
15:   )
15:   (rotary_pos_emb): RotaryEmbedding()
15:   (decoder): TransformerBlock(
15:     (layers): ModuleList(
15:       (0-31): 32 x TransformerLayer(
15:         (input_layernorm): IdentityOp()
15:         (self_attention): SelfAttention(
15:           (core_attention): TEDotProductAttention(
15:             (flash_attention): FlashAttention()
15:             (fused_attention): FusedAttention()
15:             (unfused_attention): UnfusedDotProductAttention(
15:               (scale_mask_softmax): FusedScaleMaskSoftmax()
15:               (attention_dropout): Dropout(p=0.0, inplace=False)
15:             )
15:           )
15:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
15:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
15:           (q_layernorm): IdentityOp()
15:           (k_layernorm): IdentityOp()
 1:         )
 1:         (pre_cross_attn_layernorm): IdentityOp()
 1:         (cross_attention): IdentityOp()
 1:         (cross_attn_bda): IdentityFuncOp()
 1:         (pre_mlp_layernorm): IdentityOp()
 1:         (mlp): TEFusedMLP(
 1:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 1:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 1:         )
 1:       )
 1:     )
 1:     (final_layernorm): RMSNorm()
 1:   )
 1:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 1: )
15:         )
15:         (pre_cross_attn_layernorm): IdentityOp()
15:         (cross_attention): IdentityOp()
15:         (cross_attn_bda): IdentityFuncOp()
15:         (pre_mlp_layernorm): IdentityOp()
15:         (mlp): TEFusedMLP(
15:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
15:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
15:         )
15:       )
15:     )
15:     (final_layernorm): RMSNorm()
15:   )
15:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
15: )
 2: GPTModel(
 2:   (embedding): LanguageModelEmbedding(
 2:     (word_embeddings): VocabParallelEmbedding()
 2:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 2:   )
 2:   (rotary_pos_emb): RotaryEmbedding()
 2:   (decoder): TransformerBlock(
 2:     (layers): ModuleList(
 2:       (0-31): 32 x TransformerLayer(
 2:         (input_layernorm): IdentityOp()
 2:         (self_attention): SelfAttention(
 2:           (core_attention): TEDotProductAttention(
 2:             (flash_attention): FlashAttention()
 2:             (fused_attention): FusedAttention()
 2:             (unfused_attention): UnfusedDotProductAttention(
 2:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 2:               (attention_dropout): Dropout(p=0.0, inplace=False)
 2:             )
 2:           )
 2:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 2:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 2:           (q_layernorm): IdentityOp()
 2:           (k_layernorm): IdentityOp()
12: GPTModel(
12:   (embedding): LanguageModelEmbedding(
12:     (word_embeddings): VocabParallelEmbedding()
12:     (embedding_dropout): Dropout(p=0.0, inplace=False)
12:   )
12:   (rotary_pos_emb): RotaryEmbedding()
12:   (decoder): TransformerBlock(
12:     (layers): ModuleList(
12:       (0-31): 32 x TransformerLayer(
12:         (input_layernorm): IdentityOp()
12:         (self_attention): SelfAttention(
12:           (core_attention): TEDotProductAttention(
12:             (flash_attention): FlashAttention()
12:             (fused_attention): FusedAttention()
12:             (unfused_attention): UnfusedDotProductAttention(
12:               (scale_mask_softmax): FusedScaleMaskSoftmax()
12:               (attention_dropout): Dropout(p=0.0, inplace=False)
12:             )
12:           )
12:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
12:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
12:           (q_layernorm): IdentityOp()
12:           (k_layernorm): IdentityOp()
 2:         )
 2:         (pre_cross_attn_layernorm): IdentityOp()
 2:         (cross_attention): IdentityOp()
 2:         (cross_attn_bda): IdentityFuncOp()
 2:         (pre_mlp_layernorm): IdentityOp()
 2:         (mlp): TEFusedMLP(
 2:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 2:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 2:         )
 2:       )
 2:     )
 2:     (final_layernorm): RMSNorm()
 2:   )
 2:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 2: )
12:         )
12:         (pre_cross_attn_layernorm): IdentityOp()
12:         (cross_attention): IdentityOp()
12:         (cross_attn_bda): IdentityFuncOp()
12:         (pre_mlp_layernorm): IdentityOp()
12:         (mlp): TEFusedMLP(
12:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
12:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
12:         )
12:       )
12:     )
12:     (final_layernorm): RMSNorm()
12:   )
12:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
12: )
 4: GPTModel(
 4:   (embedding): LanguageModelEmbedding(
 4:     (word_embeddings): VocabParallelEmbedding()
 4:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 4:   )
 4:   (rotary_pos_emb): RotaryEmbedding()
 4:   (decoder): TransformerBlock(
 4:     (layers): ModuleList(
 4:       (0-31): 32 x TransformerLayer(
 4:         (input_layernorm): IdentityOp()
 4:         (self_attention): SelfAttention(
 4:           (core_attention): TEDotProductAttention(
 4:             (flash_attention): FlashAttention()
 4:             (fused_attention): FusedAttention()
 4:             (unfused_attention): UnfusedDotProductAttention(
 4:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 4:               (attention_dropout): Dropout(p=0.0, inplace=False)
 4:             )
 4:           )
 4:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 4:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 4:           (q_layernorm): IdentityOp()
 4:           (k_layernorm): IdentityOp()
 4:         )
 4:         (pre_cross_attn_layernorm): IdentityOp()
 4:         (cross_attention): IdentityOp()
 4:         (cross_attn_bda): IdentityFuncOp()
 4:         (pre_mlp_layernorm): IdentityOp()
 4:         (mlp): TEFusedMLP(
 4:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 4:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 4:         )
 4:       )
 4:     )
 4:     (final_layernorm): RMSNorm()
 4:   )
 4:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 4: )
 3: GPTModel(
 3:   (embedding): LanguageModelEmbedding(
 3:     (word_embeddings): VocabParallelEmbedding()
 3:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 3:   )
 3:   (rotary_pos_emb): RotaryEmbedding()
 3:   (decoder): TransformerBlock(
 3:     (layers): ModuleList(
 3:       (0-31): 32 x TransformerLayer(
 3:         (input_layernorm): IdentityOp()
 3:         (self_attention): SelfAttention(
 3:           (core_attention): TEDotProductAttention(
 3:             (flash_attention): FlashAttention()
 3:             (fused_attention): FusedAttention()
 3:             (unfused_attention): UnfusedDotProductAttention(
 3:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 3:               (attention_dropout): Dropout(p=0.0, inplace=False)
 3:             )
 3:           )
 3:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 3:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 3:           (q_layernorm): IdentityOp()
 3:           (k_layernorm): IdentityOp()
 3:         )
 3:         (pre_cross_attn_layernorm): IdentityOp()
 3:         (cross_attention): IdentityOp()
 3:         (cross_attn_bda): IdentityFuncOp()
 3:         (pre_mlp_layernorm): IdentityOp()
 3:         (mlp): TEFusedMLP(
 3:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 3:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 3:         )
 3:       )
 3:     )
 3:     (final_layernorm): RMSNorm()
 3:   )
 3:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 3: )
14: GPTModel(
14:   (embedding): LanguageModelEmbedding(
14:     (word_embeddings): VocabParallelEmbedding()
14:     (embedding_dropout): Dropout(p=0.0, inplace=False)
14:   )
14:   (rotary_pos_emb): RotaryEmbedding()
14:   (decoder): TransformerBlock(
14:     (layers): ModuleList(
14:       (0-31): 32 x TransformerLayer(
14:         (input_layernorm): IdentityOp()
14:         (self_attention): SelfAttention(
14:           (core_attention): TEDotProductAttention(
14:             (flash_attention): FlashAttention()
14:             (fused_attention): FusedAttention()
14:             (unfused_attention): UnfusedDotProductAttention(
14:               (scale_mask_softmax): FusedScaleMaskSoftmax()
14:               (attention_dropout): Dropout(p=0.0, inplace=False)
14:             )
14:           )
14:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
14:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
14:           (q_layernorm): IdentityOp()
14:           (k_layernorm): IdentityOp()
14:         )
14:         (pre_cross_attn_layernorm): IdentityOp()
14:         (cross_attention): IdentityOp()
14:         (cross_attn_bda): IdentityFuncOp()
14:         (pre_mlp_layernorm): IdentityOp()
14:         (mlp): TEFusedMLP(
14:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
14:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
14:         )
14:       )
14:     )
14:     (final_layernorm): RMSNorm()
14:   )
14:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
14: )
 0: Llama31Config8B(tensor_model_parallel_size=1,
 0:                 pipeline_model_parallel_comm_backend=None,
 0:                 pipeline_model_parallel_size=1,
 0:                 virtual_pipeline_model_parallel_size=None,
 0:                 sequence_parallel=False,
 0:                 context_parallel_size=1,
 0:                 hierarchical_context_parallel_sizes=None,
 0:                 expert_model_parallel_size=1,
 0:                 expert_tensor_parallel_size=1,
 0:                 moe_extended_tp=False,
 0:                 perform_initialization=True,
 0:                 use_cpu_initialization=False,
 0:                 fp16=False,
 0:                 bf16=True,
 0:                 params_dtype=torch.bfloat16,
 0:                 timers=<megatron.core.timers.Timers object at 0x87b9f2c55e0>,
 0:                 finalize_model_grads_func=<function MegatronOptimizerModule.on_fit_start.<locals>.finalize_model_grads_func at 0x87afc7756c0>,
 0:                 grad_scale_func=None,
 0:                 no_sync_func=<bound method DistributedDataParallel.no_sync of DDP(
 0:   (module): Float16Module(
 0:     (module): GPTModel(
 0:       (embedding): LanguageModelEmbedding(
 0:         (word_embeddings): VocabParallelEmbedding()
 0:         (embedding_dropout): Dropout(p=0.0, inplace=False)
 0:       )
 0:       (rotary_pos_emb): RotaryEmbedding()
 0:       (decoder): TransformerBlock(
 0:         (layers): ModuleList(
 0:           (0-31): 32 x TransformerLayer(
 0:             (input_layernorm): IdentityOp()
 0:             (self_attention): SelfAttention(
 0:               (core_attention): TEDotProductAttention(
 0:                 (flash_attention): FlashAttention()
 0:                 (fused_attention): FusedAttention()
 0:                 (unfused_attention): UnfusedDotProductAttention(
 0:                   (scale_mask_softmax): FusedScaleMaskSoftmax()
 0:                   (attention_dropout): Dropout(p=0.0, inplace=False)
 0:                 )
 0:               )
 0:               (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 0:               (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 0:               (q_layernorm): IdentityOp()
 0:               (k_layernorm): IdentityOp()
 0:             )
 0:             (pre_cross_attn_layernorm): IdentityOp()
 0:             (cross_attention): IdentityOp()
 0:             (cross_attn_bda): IdentityFuncOp()
 0:             (pre_mlp_layernorm): IdentityOp()
 0:             (mlp): TEFusedMLP(
 0:               (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 0:               (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 0:             )
 0:           )
 0:         )
 0:         (final_layernorm): RMSNorm()
 0:       )
 0:       (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 0:     )
 0:   )
 0: )>,
 0:                 grad_sync_func=None,
 0:                 param_sync_func=None,
 0:                 deterministic_mode=False,
 0:                 enable_autocast=False,
 0:                 autocast_dtype=torch.bfloat16,
 0:                 num_microbatches_with_partial_activation_checkpoints=None,
 0:                 gradient_accumulation_fusion=True,
 0:                 async_tensor_model_parallel_allreduce=False,
 0:                 use_te_rng_tracker=(True,),
 0:                 tp_comm_overlap=False,
 0:                 tp_comm_bulk_wgrad=True,
 0:                 tp_comm_bulk_dgrad=True,
 0:                 tp_comm_overlap_ag=True,
 0:                 tp_comm_overlap_rs=True,
 0:                 tp_comm_overlap_rs_dgrad=False,
 0:                 tp_comm_split_ag=True,
 0:                 tp_comm_atomic_ag=False,
 0:                 tp_comm_split_rs=True,
 0:                 tp_comm_atomic_rs=False,
 0:                 cross_entropy_loss_fusion=True,
 0:                 cross_entropy_fusion_impl='te',
 0:                 tp_comm_overlap_disable_qkv=False,
 0:                 tp_comm_overlap_disable_fc1=False,
 0:                 tp_comm_bootstrap_backend=None,
 0:                 overlap_moe_expert_parallel_comm=False,
 0:                 delay_wgrad_compute=False,
 0:                 pipeline_dtype=torch.bfloat16,
 0:                 variable_seq_lengths=False,
 0:                 overlap_p2p_comm=True,
 0:                 batch_p2p_comm=False,
 0:                 batch_p2p_sync=True,
 0:                 use_ring_exchange_p2p=False,
 0:                 deallocate_pipeline_outputs=True,
 0:                 defer_embedding_wgrad_compute=False,
 0:                 wgrad_deferral_limit=50,
 0:                 overlap_p2p_comm_warmup_flush=False,
 0:                 microbatch_group_size_per_vp_stage=1,
 0:                 cpu_offloading=False,
 0:                 cpu_offloading_num_layers=0,
 0:                 _cpu_offloading_context=None,
 0:                 cpu_offloading_activations=True,
 0:                 cpu_offloading_weights=False,
 0:                 cpu_offloading_double_buffering=False,
 0:                 barrier_with_L1_time=True,
 0:                 num_layers=32,
 0:                 mtp_num_layers=None,
 0:                 mtp_loss_scaling_factor=None,
 0:                 num_layers_in_first_pipeline_stage=None,
 0:                 num_layers_in_last_pipeline_stage=None,
 0:                 pipeline_model_parallel_layout=None,
 0:                 account_for_embedding_in_pipeline_split=False,
 0:                 account_for_loss_in_pipeline_split=False,
 0:                 hidden_size=4096,
 0:                 num_attention_heads=32,
 0:                 attention_backend=<AttnBackend.auto: 5>,
 0:                 softmax_scale=None,
 0:                 softmax_type='vanilla',
 0:                 num_query_groups=8,
 0:                 ffn_hidden_size=14336,
 0:                 kv_channels=128,
 0:                 hidden_dropout=0.0,
 0:                 attention_dropout=0.0,
 0:                 fp32_residual_connection=False,
 0:                 apply_residual_connection_post_layernorm=False,
 0:                 layernorm_epsilon=1e-05,
 0:                 layernorm_zero_centered_gamma=False,
 0:                 add_bias_linear=False,
 0:                 add_qkv_bias=False,
 0:                 gated_linear_unit=True,
 0:                 activation_func=<function silu at 0x87ea414e480>,
 0:                 activation_func_fp8_input_store=False,
 0:                 glu_linear_offset=0.0,
 0:                 activation_func_clamp_value=None,
 0:                 num_moe_experts=None,
 0:                 rotary_interleaved=False,
 0:                 window_size=None,
 0:                 window_attn_skip_freq=None,
 0:                 normalization='RMSNorm',
 0:                 qk_layernorm=False,
 0:                 test_mode=False,
 0:                 calculate_per_token_loss=False,
 0:                 multi_latent_attention=False,
 0:                 no_rope_freq=None,
 0:                 moe_deepep_num_sms=20,
 0:                 init_method=functools.partial(<function normal_ at 0x87e98286de0>, mean=0.0, std=0.02),
 0:                 output_layer_init_method=functools.partial(<function normal_ at 0x87e98286de0>, mean=0.0, std=0.0025),
 0:                 init_method_std=0.02,
 0:                 embedding_init_method=functools.partial(<function normal_ at 0x87e98286de0>, mean=0.0, std=0.02),
 0:                 embedding_init_method_std=0.02,
 0:                 init_model_with_meta_device=False,
 0:                 apply_query_key_layer_scaling=False,
 0:                 attention_softmax_in_fp32=False,
 0:                 disable_bf16_reduced_precision_matmul=False,
 0:                 bias_activation_fusion=True,
 0:                 masked_softmax_fusion=True,
 0:                 persist_layer_norm=True,
 0:                 memory_efficient_layer_norm=False,
 0:                 bias_dropout_fusion=True,
 0:                 apply_rope_fusion=True,
 0:                 use_fused_weighted_squared_relu=False,
 0:                 fused_single_qkv_rope=True,
 0:                 recompute_granularity=None,
 0:                 recompute_method=None,
 0:                 recompute_num_layers=None,
 0:                 distribute_saved_activations=None,
 0:                 recompute_modules=['core_attn'],
 0:                 fp8=None,
 0:                 fp8_recipe='tensorwise',
 0:                 fp8_param=False,
 0:                 fp8_margin=0,
 0:                 fp8_interval=1,
 0:                 fp8_amax_history_len=1,
 0:                 fp8_amax_compute_algo='most_recent',
 0:                 fp8_wgrad=True,
 0:                 fp8_dot_product_attention=True,
 0:                 fp8_multi_head_attention=False,
 0:                 tp_only_amax_red=False,
 0:                 first_last_layers_bf16=False,
 0:                 num_layers_at_start_in_bf16=0,
 0:                 num_layers_at_end_in_bf16=0,
 0:                 use_kitchen=False,
 0:                 fp4='e2m1',
 0:                 fp4_recipe='nvfp4',
 0:                 fp4_param=False,
 0:                 moe_shared_expert_intermediate_size=None,
 0:                 moe_shared_expert_overlap=False,
 0:                 moe_layer_freq=1,
 0:                 moe_ffn_hidden_size=None,
 0:                 moe_router_load_balancing_type='aux_loss',
 0:                 moe_router_topk=2,
 0:                 moe_router_topk_limited_devices=None,
 0:                 moe_router_padding_for_fp8=False,
 0:                 moe_router_num_groups=None,
 0:                 moe_router_group_topk=None,
 0:                 moe_router_pre_softmax=False,
 0:                 moe_router_topk_scaling_factor=None,
 0:                 moe_router_score_function='softmax',
 0:                 moe_router_dtype=None,
 0:                 moe_router_enable_expert_bias=False,
 0:                 moe_router_bias_update_rate=0.001,
 0:                 moe_router_force_load_balancing=False,
 0:                 moe_grouped_gemm=False,
 0:                 moe_use_legacy_grouped_gemm=False,
 0:                 moe_aux_loss_coeff=0.0,
 0:                 moe_z_loss_coeff=None,
 0:                 moe_input_jitter_eps=None,
 0:                 moe_token_dropping=False,
 0:                 moe_token_dispatcher_type='allgather',
 0:                 moe_enable_deepep=False,
 0:                 moe_per_layer_logging=False,
 0:                 moe_expert_capacity_factor=None,
 0:                 moe_pad_expert_input_to_capacity=False,
 0:                 moe_token_drop_policy='probs',
 0:                 moe_layer_recompute=False,
 0:                 moe_permute_fusion=False,
 0:                 moe_router_fusion=False,
 0:                 moe_apply_probs_on_input=False,
 0:                 cp_comm_type=None,
 0:                 enable_cuda_graph=1,
 0:                 cuda_graph_use_single_mempool=False,
 0:                 cuda_graph_retain_backward_graph=False,
 0:                 cuda_graph_warmup_steps=3,
 0:                 external_cuda_graph=False,
 0:                 cuda_graph_scope='full_iteration',
 0:                 clone_scatter_output_in_embedding=True,
 0:                 disable_parameter_transpose_cache=False,
 0:                 config_logger_dir='',
 0:                 flash_decode=False,
 0:                 use_te_activation_func=False,
 0:                 inference_rng_tracker=False,
 0:                 inference_sampling_seed=42,
 0:                 symmetric_ar_type=None,
 0:                 mrope_section=None,
 0:                 is_hybrid_model=False,
 0:                 mamba_state_dim=128,
 0:                 mamba_head_dim=64,
 0:                 mamba_num_groups=8,
 0:                 mamba_num_heads=None,
 0:                 use_mamba_mem_eff_path=True,
 0:                 mlp_chunks_for_prefill=1,
 0:                 heterogeneous_block_specs=False,
 0:                 hetereogenous_dist_checkpoint=False,
 0:                 quant_recipe=None,
 0:                 transformer_impl='transformer_engine',
 0:                 fp16_lm_cross_entropy=False,
 0:                 parallel_output=True,
 0:                 share_embeddings_and_output_weights=False,
 0:                 make_vocab_size_divisible_by=128,
 0:                 position_embedding_type='rope',
 0:                 rotary_base=500000,
 0:                 rotary_percent=1.0,
 0:                 seq_len_interpolation_factor=None,
 0:                 seq_length=8192,
 0:                 scatter_embedding_sequence_parallel=True,
 0:                 use_transformer_engine_full_layer_spec=False,
 0:                 transformer_layer_spec=<function default_layer_spec at 0x87b9ffde340>,
 0:                 forward_step_fn=<function gpt_forward_step at 0x87b9ffdcb80>,
 0:                 data_step_fn=<function gpt_data_step at 0x87b9ffdc900>,
 0:                 generation_config=None,
 0:                 vocab_size=None,
 0:                 tp_comm_overlap_cfg=None,
 0:                 use_transformer_engine_op_fuser=True,
 0:                 scale_factor=8.0,
 0:                 low_freq_factor=1.0,
 0:                 high_freq_factor=4.0,
 0:                 old_context_len=8192)
 0: [AUX I 2025-10-09 05:16:02 data:291] Instantiating MegatronPretrainingSampler with total_samples: 10000000 and consumed_samples: 0
13: [rank13]:[W1009 05:16:02.706507174 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 92 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 5: [rank5]:[W1009 05:16:02.643515578 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 68 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 6: [rank6]:[W1009 05:16:02.644806487 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 71 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 4: [rank4]:[W1009 05:16:02.647891001 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 65 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
12: [rank12]:[W1009 05:16:02.722370227 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 89 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
15: [rank15]:[W1009 05:16:02.731816632 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 98 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 3: [rank3]:[W1009 05:16:02.668240822 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 62 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 2: [rank2]:[W1009 05:16:02.671832679 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 59 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 1: [rank1]:[W1009 05:16:02.676871268 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 56 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
14: [rank14]:[W1009 05:16:02.748355427 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 95 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
10: [rank10]:[W1009 05:16:02.768314908 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 83 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
11: [rank11]:[W1009 05:16:02.769427251 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 86 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 9: [rank9]:[W1009 05:16:02.771149561 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 80 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 8: [rank8]:[W1009 05:16:02.778838314 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 77 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 7: [rank7]:[W1009 05:16:02.713582478 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 74 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 0: [rank0]:[W1009 05:16:02.721356935 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 53 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 0: [AUX I 2025-10-09 05:16:04 custom_callbacks:129] Starting training warmup
 0: [AUX I 2025-10-09 05:16:04 custom_callbacks:133]     Starting warmup step 0
 0: [AUX I 2025-10-09 05:16:27 custom_callbacks:150]     Finished warmup step 0, takes 23.550782203674316 s
 0: [AUX I 2025-10-09 05:16:27 custom_callbacks:133]     Starting warmup step 1
 0: [NeMo I 2025-10-09 05:16:27 full_cuda_graph:164] Capture CUDA graph for training!!!
 0: [NeMo I 2025-10-09 05:16:30 full_cuda_graph:182] CUDA graph capture done!!!
 0: [AUX I 2025-10-09 05:16:31 custom_callbacks:150]     Finished warmup step 1, takes 3.355743169784546 s
 0: [AUX I 2025-10-09 05:16:31 custom_callbacks:157] Finished training warmup: 26.911067485809326 s. 
 0: [AUX I 2025-10-09 05:16:31 custom_callbacks:176] Starting validation warmups
 0: [NeMo I 2025-10-09 05:16:33 full_cuda_graph:164] Capture CUDA graph for validation!!!
 0: [NeMo I 2025-10-09 05:16:40 full_cuda_graph:182] CUDA graph capture done!!!
 0: [AUX I 2025-10-09 05:16:40 custom_callbacks:195] Finished validation warmup: 9.45175552368164 s. 
 0: [AUX I 2025-10-09 05:16:40 custom_callbacks:202] Finished training warmup: 9.452769041061401 s. 
 0: [AUX I 2025-10-09 05:16:40 custom_callbacks:212] Time spent in run_training_warmup: 9.456530570983887s
 0: :::MLLOG {"namespace": "", "time_ms": 1759987000501, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"warmup_time": 97.36658121016808}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987000572, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"init_finished": 0.07102739694528282}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987000573, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987000574, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987000575, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987016029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.47981882095336914, "reduced_train_loss": 8.892356872558594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 31.0, "samples_count": 1024.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987031439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4845573902130127, "reduced_train_loss": 7.382826805114746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 63.0, "samples_count": 2048.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987047101, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.48680901527404785, "reduced_train_loss": 6.977884769439697}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 95.0, "samples_count": 3072.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987062870, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.500190019607544, "reduced_train_loss": 6.736338138580322}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 127.0, "samples_count": 4096.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987078637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4894392490386963, "reduced_train_loss": 6.741047382354736}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 159.0, "samples_count": 5120.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987094477, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49229979515075684, "reduced_train_loss": 6.459859371185303}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 191.0, "samples_count": 6144.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987110294, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4908902645111084, "reduced_train_loss": 6.408869743347168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 223.0, "samples_count": 7168.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987126173, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.494523286819458, "reduced_train_loss": 6.2612504959106445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 255.0, "samples_count": 8192.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987142047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4893062114715576, "reduced_train_loss": 6.030973434448242}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 287.0, "samples_count": 9216.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987157912, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4968235492706299, "reduced_train_loss": 5.784111976623535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 319.0, "samples_count": 10240.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987173758, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49464917182922363, "reduced_train_loss": 5.6078386306762695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 351.0, "samples_count": 11264.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987189626, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4955782890319824, "reduced_train_loss": 5.525217533111572}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 383.0, "samples_count": 12288.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987190145, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49367960245035647}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987190146, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987190147, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 12288, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987190317, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6933491230010986}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 0, "samples_count": 32}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987190469, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15241050720214844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1, "samples_count": 64}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987190621, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15155649185180664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2, "samples_count": 96}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987190775, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15351319313049316}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3, "samples_count": 128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987190932, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15713000297546387}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4, "samples_count": 160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987191093, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16169333457946777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5, "samples_count": 192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987191248, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15456008911132812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6, "samples_count": 224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987191403, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15541863441467285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7, "samples_count": 256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987191562, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1581742763519287}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 8, "samples_count": 288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987191716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1547532081604004}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 9, "samples_count": 320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987191872, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1560354232788086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 10, "samples_count": 352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987192028, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1554863452911377}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 11, "samples_count": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987192184, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15640997886657715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 12, "samples_count": 416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987192339, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15430402755737305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 13, "samples_count": 448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987192497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15801191329956055}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 14, "samples_count": 480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987192653, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15605711936950684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 15, "samples_count": 512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987192806, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15325379371643066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 16, "samples_count": 544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987192961, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15527701377868652}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 17, "samples_count": 576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987193117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15632867813110352}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 18, "samples_count": 608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987193273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15514612197875977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 19, "samples_count": 640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987193429, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15625691413879395}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 20, "samples_count": 672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987193584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.154740571975708}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 21, "samples_count": 704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987193741, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15730500221252441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 22, "samples_count": 736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987193897, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15645933151245117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 23, "samples_count": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987194053, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15574908256530762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 24, "samples_count": 800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987194214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16063952445983887}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 25, "samples_count": 832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987194370, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.156280517578125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 26, "samples_count": 864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987194529, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1586441993713379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 27, "samples_count": 896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987194682, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1538386344909668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 28, "samples_count": 928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987194841, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15866303443908691}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 29, "samples_count": 960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987194995, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15375709533691406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 30, "samples_count": 992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987195152, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15732812881469727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 31, "samples_count": 1024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987195156, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 5.561750888824463, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987195156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 5.011302120052278}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987195156, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 12288, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987195156, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987211017, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4916846752166748, "reduced_train_loss": 5.476857662200928}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 415.0, "samples_count": 13312.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987226873, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49342823028564453, "reduced_train_loss": 5.318819046020508}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 447.0, "samples_count": 14336.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987242731, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5013928413391113, "reduced_train_loss": 5.072396755218506}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 479.0, "samples_count": 15360.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987258599, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4902009963989258, "reduced_train_loss": 5.115015983581543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 511.0, "samples_count": 16384.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987274433, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5036864280700684, "reduced_train_loss": 4.941592216491699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 543.0, "samples_count": 17408.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987290345, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49546289443969727, "reduced_train_loss": 4.798068046569824}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 575.0, "samples_count": 18432.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987306209, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4939093589782715, "reduced_train_loss": 4.7449541091918945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 607.0, "samples_count": 19456.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987322072, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49916982650756836, "reduced_train_loss": 4.633706092834473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 639.0, "samples_count": 20480.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987337902, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4889388084411621, "reduced_train_loss": 4.712308883666992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 671.0, "samples_count": 21504.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987353782, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.490999698638916, "reduced_train_loss": 4.472175598144531}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 703.0, "samples_count": 22528.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987369680, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.503077507019043, "reduced_train_loss": 4.509215831756592}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 735.0, "samples_count": 23552.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987385537, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49338698387145996, "reduced_train_loss": 4.368556022644043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 767.0, "samples_count": 24576.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386068, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4971655921720715}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386069, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386070, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 24576, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386226, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6901721954345703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 32, "samples_count": 1056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386381, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1555159091949463}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 33, "samples_count": 1088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386532, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15124297142028809}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 34, "samples_count": 1120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386684, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1522810459136963}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 35, "samples_count": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386841, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15628719329833984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 36, "samples_count": 1184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987386996, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15562081336975098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 37, "samples_count": 1216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987387156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15963196754455566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 38, "samples_count": 1248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987387310, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15412473678588867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 39, "samples_count": 1280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987387465, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15448594093322754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 40, "samples_count": 1312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987387620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15499424934387207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 41, "samples_count": 1344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987387777, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1578361988067627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 42, "samples_count": 1376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987387935, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15744733810424805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 43, "samples_count": 1408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987388093, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15851998329162598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 44, "samples_count": 1440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987388250, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15621519088745117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 45, "samples_count": 1472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987388404, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15445876121520996}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 46, "samples_count": 1504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987388560, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15613889694213867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 47, "samples_count": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987388717, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15722131729125977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 48, "samples_count": 1568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987388875, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15800833702087402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 49, "samples_count": 1600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987389030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15471124649047852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 50, "samples_count": 1632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987389186, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15625333786010742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 51, "samples_count": 1664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987389341, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15442466735839844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 52, "samples_count": 1696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987389498, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15771722793579102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 53, "samples_count": 1728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987389652, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15362930297851562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 54, "samples_count": 1760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987389809, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1566176414489746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 55, "samples_count": 1792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987389963, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15390539169311523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 56, "samples_count": 1824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987390118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15544962882995605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 57, "samples_count": 1856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987390277, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1593327522277832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 58, "samples_count": 1888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987390432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15468549728393555}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 59, "samples_count": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987390589, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15728211402893066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 60, "samples_count": 1952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987390745, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15558934211730957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 61, "samples_count": 1984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987390899, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15382599830627441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 62, "samples_count": 2016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987391057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15867280960083008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 63, "samples_count": 2048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987391058, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 4.415356159210205, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 24576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987391058, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.990569085814059}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987391058, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 24576, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987391059, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987406945, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49166178703308105, "reduced_train_loss": 4.39068078994751}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 799.0, "samples_count": 25600.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987422827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4946770668029785, "reduced_train_loss": 4.371268272399902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 831.0, "samples_count": 26624.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987438677, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4945070743560791, "reduced_train_loss": 4.297671318054199}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 863.0, "samples_count": 27648.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987454577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4900336265563965, "reduced_train_loss": 4.245981216430664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 895.0, "samples_count": 28672.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987470440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4966754913330078, "reduced_train_loss": 4.274450302124023}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 927.0, "samples_count": 29696.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987486307, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4909474849700928, "reduced_train_loss": 4.229536056518555}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 959.0, "samples_count": 30720.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987502167, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49599790573120117, "reduced_train_loss": 4.167106628417969}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 991.0, "samples_count": 31744.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987518016, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5067453384399414, "reduced_train_loss": 4.137050151824951}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1023.0, "samples_count": 32768.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987533853, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4929819107055664, "reduced_train_loss": 4.057771682739258}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1055.0, "samples_count": 33792.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987549702, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49263453483581543, "reduced_train_loss": 4.100681304931641}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1087.0, "samples_count": 34816.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987565536, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49694347381591797, "reduced_train_loss": 4.063720703125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1119.0, "samples_count": 35840.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987581392, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4966130256652832, "reduced_train_loss": 4.091562271118164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1151.0, "samples_count": 36864.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987581927, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4970531913828988}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987581928, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987581928, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 36864, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987582083, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6929581165313721}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 64, "samples_count": 2080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987582239, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15601515769958496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 65, "samples_count": 2112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987582390, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15149521827697754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 66, "samples_count": 2144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987582542, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15131878852844238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 67, "samples_count": 2176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987582700, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15815234184265137}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 68, "samples_count": 2208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987582858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1578521728515625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 69, "samples_count": 2240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987583014, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1560671329498291}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 70, "samples_count": 2272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987583170, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15668535232543945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 71, "samples_count": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987583324, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15325379371643066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 72, "samples_count": 2336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987583480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15656185150146484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 73, "samples_count": 2368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987583640, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1593778133392334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 74, "samples_count": 2400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987583799, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.159837007522583}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 75, "samples_count": 2432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987583955, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15535640716552734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 76, "samples_count": 2464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987584115, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15987634658813477}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 77, "samples_count": 2496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987584275, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15982437133789062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 78, "samples_count": 2528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987584429, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15490126609802246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 79, "samples_count": 2560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987584584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15473484992980957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 80, "samples_count": 2592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987584743, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1592693328857422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 81, "samples_count": 2624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987584899, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15527701377868652}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 82, "samples_count": 2656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987585059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16047000885009766}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 83, "samples_count": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987585215, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1560819149017334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 84, "samples_count": 2720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987585370, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15447068214416504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 85, "samples_count": 2752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987585524, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15450143814086914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 86, "samples_count": 2784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987585685, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16039538383483887}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 87, "samples_count": 2816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987585840, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15553045272827148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 88, "samples_count": 2848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987585996, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15589094161987305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 89, "samples_count": 2880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15999531745910645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 90, "samples_count": 2912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15539312362670898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 91, "samples_count": 2944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586466, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15468740463256836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 92, "samples_count": 2976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586621, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1548607349395752}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 93, "samples_count": 3008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586781, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15996575355529785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 94, "samples_count": 3040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586936, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15534424781799316}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 95, "samples_count": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586937, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 4.070650577545166, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 36864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586937, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 5.0105405719950795}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586937, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 36864, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987586937, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987602779, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49454283714294434, "reduced_train_loss": 4.073220252990723}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1183.0, "samples_count": 37888.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987618633, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5025360584259033, "reduced_train_loss": 3.995772361755371}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1215.0, "samples_count": 38912.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987634491, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4983029365539551, "reduced_train_loss": 3.9607229232788086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1247.0, "samples_count": 39936.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987650342, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49521708488464355, "reduced_train_loss": 3.9721388816833496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1279.0, "samples_count": 40960.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987666197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4993598461151123, "reduced_train_loss": 4.03365421295166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1311.0, "samples_count": 41984.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987682070, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4957466125488281, "reduced_train_loss": 3.9542181491851807}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1343.0, "samples_count": 43008.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987697938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5004172325134277, "reduced_train_loss": 3.9879636764526367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1375.0, "samples_count": 44032.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987713827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4975428581237793, "reduced_train_loss": 3.909630298614502}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1407.0, "samples_count": 45056.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987729636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4923973083496094, "reduced_train_loss": 3.8977413177490234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1439.0, "samples_count": 46080.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987745525, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49114012718200684, "reduced_train_loss": 3.9456238746643066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1471.0, "samples_count": 47104.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987761341, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.48898959159851074, "reduced_train_loss": 3.9362902641296387}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1503.0, "samples_count": 48128.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987777214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4974977970123291, "reduced_train_loss": 3.924872398376465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1535.0, "samples_count": 49152.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987777751, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49690980860941636}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987777751, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987777752, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 49152, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987777905, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6933810710906982}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 96, "samples_count": 3104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987778059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1540219783782959}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 97, "samples_count": 3136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987778215, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15538311004638672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 98, "samples_count": 3168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987778368, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15297627449035645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 99, "samples_count": 3200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987778524, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15611863136291504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 100, "samples_count": 3232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987778681, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15685582160949707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 101, "samples_count": 3264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987778836, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15496110916137695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 102, "samples_count": 3296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987778992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15636730194091797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 103, "samples_count": 3328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987779146, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15392494201660156}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 104, "samples_count": 3360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987779299, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15334510803222656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 105, "samples_count": 3392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987779455, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1555929183959961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 106, "samples_count": 3424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987779611, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1559615135192871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 107, "samples_count": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987779765, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15422701835632324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 108, "samples_count": 3488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987779919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15442395210266113}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 109, "samples_count": 3520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987780077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15766668319702148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 110, "samples_count": 3552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987780234, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15699505805969238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 111, "samples_count": 3584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987780390, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15619230270385742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 112, "samples_count": 3616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987780546, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15535402297973633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 113, "samples_count": 3648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987780700, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15489864349365234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 114, "samples_count": 3680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987780858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1576700210571289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 115, "samples_count": 3712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987781017, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15882325172424316}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 116, "samples_count": 3744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987781171, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15374755859375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 117, "samples_count": 3776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987781326, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15535593032836914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 118, "samples_count": 3808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987781481, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15511059761047363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 119, "samples_count": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987781638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15661931037902832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 120, "samples_count": 3872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987781795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15703034400939941}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 121, "samples_count": 3904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987781950, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15495657920837402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 122, "samples_count": 3936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782104, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15469741821289062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 123, "samples_count": 3968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782260, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1552903652191162}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 124, "samples_count": 4000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782418, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15819287300109863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 125, "samples_count": 4032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782575, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1573810577392578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 126, "samples_count": 4064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782732, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15660786628723145}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 127, "samples_count": 4096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782733, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.901803970336914, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 49152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782733, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.98217380605638}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782733, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 49152, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987782733, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987798594, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49787211418151855, "reduced_train_loss": 3.8469297885894775}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1567.0, "samples_count": 50176.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987814448, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4994080066680908, "reduced_train_loss": 3.8085930347442627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1599.0, "samples_count": 51200.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987830279, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49132823944091797, "reduced_train_loss": 3.921323299407959}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1631.0, "samples_count": 52224.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987846155, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49995970726013184, "reduced_train_loss": 3.74082088470459}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1663.0, "samples_count": 53248.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987861992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4979417324066162, "reduced_train_loss": 3.784515857696533}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1695.0, "samples_count": 54272.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987877842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49448108673095703, "reduced_train_loss": 3.8460516929626465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1727.0, "samples_count": 55296.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987893696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49320483207702637, "reduced_train_loss": 3.8129780292510986}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1759.0, "samples_count": 56320.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987909519, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49588751792907715, "reduced_train_loss": 3.7450952529907227}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1791.0, "samples_count": 57344.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987925361, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.494797945022583, "reduced_train_loss": 3.7227931022644043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1823.0, "samples_count": 58368.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987941239, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49754929542541504, "reduced_train_loss": 3.85512113571167}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1855.0, "samples_count": 59392.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987957097, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49706578254699707, "reduced_train_loss": 3.8376150131225586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1887.0, "samples_count": 60416.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987972908, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49274682998657227, "reduced_train_loss": 3.6820731163024902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1919.0, "samples_count": 61440.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987973433, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4966154549086544}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987973435, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987973435, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 61440, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987973590, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6832871437072754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 128, "samples_count": 4128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987973745, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15600967407226562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 129, "samples_count": 4160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987973897, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1519629955291748}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 130, "samples_count": 4192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987974050, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15281009674072266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 131, "samples_count": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987974204, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15356898307800293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 132, "samples_count": 4256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987974362, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1587691307067871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 133, "samples_count": 4288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987974517, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15477442741394043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 134, "samples_count": 4320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987974675, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15777969360351562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 135, "samples_count": 4352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987974832, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15676331520080566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 136, "samples_count": 4384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987974987, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1554112434387207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 137, "samples_count": 4416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987975144, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15679311752319336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 138, "samples_count": 4448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987975298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1539478302001953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 139, "samples_count": 4480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987975459, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16112256050109863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 140, "samples_count": 4512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987975615, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1555466651916504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 141, "samples_count": 4544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987975771, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15590858459472656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 142, "samples_count": 4576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987975924, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1530895233154297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 143, "samples_count": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987976080, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15644454956054688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 144, "samples_count": 4640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987976235, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15543413162231445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 145, "samples_count": 4672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987976391, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1553666591644287}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 146, "samples_count": 4704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987976544, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15346837043762207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 147, "samples_count": 4736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987976700, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15535521507263184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 148, "samples_count": 4768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987976857, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1571183204650879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 149, "samples_count": 4800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987977011, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15471529960632324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 150, "samples_count": 4832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987977169, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15713882446289062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 151, "samples_count": 4864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987977323, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1540999412536621}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 152, "samples_count": 4896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987977480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15690326690673828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 153, "samples_count": 4928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987977637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1569690704345703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 154, "samples_count": 4960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987977791, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15394091606140137}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 155, "samples_count": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987977946, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15555310249328613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 156, "samples_count": 5024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987978102, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15547752380371094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 157, "samples_count": 5056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987978257, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1552720069885254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 158, "samples_count": 5088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987978411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15375876426696777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 159, "samples_count": 5120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987978411, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.7676076889038086, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 61440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987978412, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.978298186091706}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987978412, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 61440, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987978412, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759987994284, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4943115711212158, "reduced_train_loss": 3.7467079162597656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1951.0, "samples_count": 62464.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988010142, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5000832080841064, "reduced_train_loss": 3.629324197769165}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1983.0, "samples_count": 63488.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988026003, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4888603687286377, "reduced_train_loss": 3.7496042251586914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2015.0, "samples_count": 64512.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988041868, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4905717372894287, "reduced_train_loss": 3.6773414611816406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2047.0, "samples_count": 65536.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988057744, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49848294258117676, "reduced_train_loss": 3.6842689514160156}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2079.0, "samples_count": 66560.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988073591, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49756407737731934, "reduced_train_loss": 3.753467321395874}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2111.0, "samples_count": 67584.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988089438, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49762916564941406, "reduced_train_loss": 3.722073554992676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2143.0, "samples_count": 68608.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988105312, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49958062171936035, "reduced_train_loss": 3.6654629707336426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2175.0, "samples_count": 69632.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988121131, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49695253372192383, "reduced_train_loss": 3.6992499828338623}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2207.0, "samples_count": 70656.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988136976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4920182228088379, "reduced_train_loss": 3.7771124839782715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2239.0, "samples_count": 71680.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988152877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49882984161376953, "reduced_train_loss": 3.6701903343200684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2271.0, "samples_count": 72704.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988168771, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.508894681930542, "reduced_train_loss": 3.618785858154297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2303.0, "samples_count": 73728.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988169302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49711054168195307}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988169303, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988169303, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 73728, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988169457, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6875665187835693}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 160, "samples_count": 5152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988169609, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15260577201843262}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 161, "samples_count": 5184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988169761, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15160012245178223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 162, "samples_count": 5216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988169915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15368127822875977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 163, "samples_count": 5248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988170076, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16108059883117676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 164, "samples_count": 5280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988170230, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15473294258117676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 165, "samples_count": 5312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988170387, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15650367736816406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 166, "samples_count": 5344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988170542, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15463924407958984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 167, "samples_count": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988170701, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1591043472290039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 168, "samples_count": 5408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988170855, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15435791015625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 169, "samples_count": 5440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988171013, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15783452987670898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 170, "samples_count": 5472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988171168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15461301803588867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 171, "samples_count": 5504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988171323, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15512371063232422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 172, "samples_count": 5536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988171479, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15653777122497559}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 173, "samples_count": 5568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988171638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15906524658203125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 174, "samples_count": 5600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988171796, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15767216682434082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 175, "samples_count": 5632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988171954, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15758156776428223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 176, "samples_count": 5664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988172113, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15912628173828125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 177, "samples_count": 5696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988172268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15517640113830566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 178, "samples_count": 5728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988172422, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15415024757385254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 179, "samples_count": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988172577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1547689437866211}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 180, "samples_count": 5792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988172736, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15917301177978516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 181, "samples_count": 5824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988172891, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15554451942443848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 182, "samples_count": 5856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988173046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15500640869140625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 183, "samples_count": 5888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988173202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15516972541809082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 184, "samples_count": 5920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988173360, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15837669372558594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 185, "samples_count": 5952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988173518, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15770173072814941}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 186, "samples_count": 5984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988173676, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1583845615386963}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 187, "samples_count": 6016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988173830, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15345525741577148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 188, "samples_count": 6048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988173984, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15419435501098633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 189, "samples_count": 6080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988174143, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15895867347717285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 190, "samples_count": 6112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988174297, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15413784980773926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 191, "samples_count": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988174298, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.6717472076416016, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 73728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988174298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.99581790715456}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988174298, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 73728, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988174298, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988190177, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49785494804382324, "reduced_train_loss": 3.6756298542022705}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2335.0, "samples_count": 74752.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988206045, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5041821002960205, "reduced_train_loss": 3.620100975036621}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2367.0, "samples_count": 75776.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988221907, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49576568603515625, "reduced_train_loss": 3.6444926261901855}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2399.0, "samples_count": 76800.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988237755, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4966559410095215, "reduced_train_loss": 3.5725982189178467}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2431.0, "samples_count": 77824.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988253581, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4883253574371338, "reduced_train_loss": 3.539480209350586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2463.0, "samples_count": 78848.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988269410, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5027408599853516, "reduced_train_loss": 3.576451301574707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2495.0, "samples_count": 79872.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988285255, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49129223823547363, "reduced_train_loss": 3.5702147483825684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2527.0, "samples_count": 80896.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988301104, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49187517166137695, "reduced_train_loss": 3.6230409145355225}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2559.0, "samples_count": 81920.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988316973, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49838685989379883, "reduced_train_loss": 3.634000539779663}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2591.0, "samples_count": 82944.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988332803, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4898655414581299, "reduced_train_loss": 3.5800578594207764}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2623.0, "samples_count": 83968.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988348673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49642252922058105, "reduced_train_loss": 3.558417320251465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2655.0, "samples_count": 84992.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988364537, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4908268451690674, "reduced_train_loss": 3.568223714828491}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2687.0, "samples_count": 86016.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365071, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49680626547099865}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365072, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365072, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 86016, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365229, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6940760612487793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 192, "samples_count": 6176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365381, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15197038650512695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 193, "samples_count": 6208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365534, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15288853645324707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 194, "samples_count": 6240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365687, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15276217460632324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 195, "samples_count": 6272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365841, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1541430950164795}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 196, "samples_count": 6304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988365997, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15652775764465332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 197, "samples_count": 6336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988366158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1607646942138672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 198, "samples_count": 6368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988366317, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15939855575561523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 199, "samples_count": 6400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988366471, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15352630615234375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 200, "samples_count": 6432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988366625, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.153883695602417}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 201, "samples_count": 6464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988366784, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.159104585647583}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 202, "samples_count": 6496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988366938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15439891815185547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 203, "samples_count": 6528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988367095, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15705037117004395}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 204, "samples_count": 6560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988367253, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1575019359588623}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 205, "samples_count": 6592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988367410, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1571056842803955}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 206, "samples_count": 6624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988367564, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15402889251708984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 207, "samples_count": 6656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988367719, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15525221824645996}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 208, "samples_count": 6688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988367878, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1588594913482666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 209, "samples_count": 6720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988368033, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15456175804138184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 210, "samples_count": 6752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988368187, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15466856956481934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 211, "samples_count": 6784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988368343, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15555262565612793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 212, "samples_count": 6816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988368498, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15502262115478516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 213, "samples_count": 6848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988368656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15767335891723633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 214, "samples_count": 6880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988368809, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15390753746032715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 215, "samples_count": 6912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988368965, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15564632415771484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 216, "samples_count": 6944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988369120, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15483641624450684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 217, "samples_count": 6976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988369276, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15561914443969727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 218, "samples_count": 7008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988369432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15652775764465332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 219, "samples_count": 7040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988369589, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1565549373626709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 220, "samples_count": 7072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988369743, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15474247932434082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 221, "samples_count": 7104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988369901, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1574997901916504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 222, "samples_count": 7136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988370057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15565061569213867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 223, "samples_count": 7168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988370057, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.594019889831543, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 86016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988370057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.986030717147514}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988370058, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 86016, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988370058, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988385913, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4914584159851074, "reduced_train_loss": 3.5178611278533936}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2719.0, "samples_count": 87040.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988401760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.48909902572631836, "reduced_train_loss": 3.614614725112915}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2751.0, "samples_count": 88064.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988417612, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4942033290863037, "reduced_train_loss": 3.5983989238739014}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2783.0, "samples_count": 89088.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988433476, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49766969680786133, "reduced_train_loss": 3.5113301277160645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2815.0, "samples_count": 90112.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988449335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4955000877380371, "reduced_train_loss": 3.598539352416992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2847.0, "samples_count": 91136.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988465215, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49460434913635254, "reduced_train_loss": 3.5862817764282227}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2879.0, "samples_count": 92160.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988481055, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4964144229888916, "reduced_train_loss": 3.5291824340820312}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2911.0, "samples_count": 93184.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988496882, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4925963878631592, "reduced_train_loss": 3.5033059120178223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2943.0, "samples_count": 94208.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988512727, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49117255210876465, "reduced_train_loss": 3.5664494037628174}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2975.0, "samples_count": 95232.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988528537, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49204301834106445, "reduced_train_loss": 3.5043201446533203}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3007.0, "samples_count": 96256.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988544333, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4956328868865967, "reduced_train_loss": 3.636525869369507}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3039.0, "samples_count": 97280.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988560169, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49651551246643066, "reduced_train_loss": 3.54286527633667}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3071.0, "samples_count": 98304.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988560711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4964927441014879}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988560711, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988560712, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 98304, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988560867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6991431713104248}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 224, "samples_count": 7200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988561019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15219354629516602}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 225, "samples_count": 7232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988561173, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15470123291015625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 226, "samples_count": 7264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988561325, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.151153564453125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 227, "samples_count": 7296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988561480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15508484840393066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 228, "samples_count": 7328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988561642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16231346130371094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 229, "samples_count": 7360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988561799, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15728092193603516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 230, "samples_count": 7392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988561956, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15636539459228516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 231, "samples_count": 7424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988562112, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15639305114746094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 232, "samples_count": 7456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988562270, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15821623802185059}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 233, "samples_count": 7488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988562424, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15342378616333008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 234, "samples_count": 7520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988562581, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15719914436340332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 235, "samples_count": 7552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988562738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1574416160583496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 236, "samples_count": 7584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988562896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1573491096496582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 237, "samples_count": 7616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988563053, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15700984001159668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 238, "samples_count": 7648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988563213, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16041994094848633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 239, "samples_count": 7680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988563370, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15687823295593262}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 240, "samples_count": 7712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988563524, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1540355682373047}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 241, "samples_count": 7744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988563681, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15720796585083008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 242, "samples_count": 7776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988563838, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15656065940856934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 243, "samples_count": 7808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988563995, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15716338157653809}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 244, "samples_count": 7840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988564154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15897369384765625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 245, "samples_count": 7872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988564308, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1540508270263672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 246, "samples_count": 7904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988564463, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15512442588806152}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 247, "samples_count": 7936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988564618, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15497303009033203}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 248, "samples_count": 7968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988564776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15779495239257812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 249, "samples_count": 8000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988564932, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15639686584472656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 250, "samples_count": 8032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565086, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15381693840026855}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 251, "samples_count": 8064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565242, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1558835506439209}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 252, "samples_count": 8096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565400, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15783452987670898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 253, "samples_count": 8128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565555, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15516901016235352}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 254, "samples_count": 8160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565714, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15886187553405762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 255, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565715, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.53414249420166, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 98304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 5.004162832861766}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565715, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 98304, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988565715, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988581598, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49721431732177734, "reduced_train_loss": 3.544896125793457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3103.0, "samples_count": 99328.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988597458, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49697208404541016, "reduced_train_loss": 3.4868714809417725}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3135.0, "samples_count": 100352.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988613329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5075554847717285, "reduced_train_loss": 3.511483669281006}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3167.0, "samples_count": 101376.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988629202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49385881423950195, "reduced_train_loss": 3.527388095855713}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3199.0, "samples_count": 102400.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988645065, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4913816452026367, "reduced_train_loss": 3.510697603225708}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3231.0, "samples_count": 103424.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988660930, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49362826347351074, "reduced_train_loss": 3.586026906967163}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3263.0, "samples_count": 104448.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988676806, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49283456802368164, "reduced_train_loss": 3.516648292541504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3295.0, "samples_count": 105472.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988692637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49465203285217285, "reduced_train_loss": 3.5086708068847656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3327.0, "samples_count": 106496.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988708500, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49454331398010254, "reduced_train_loss": 3.5366764068603516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3359.0, "samples_count": 107520.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988724352, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4953784942626953, "reduced_train_loss": 3.3828489780426025}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3391.0, "samples_count": 108544.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988740218, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4920687675476074, "reduced_train_loss": 3.5081892013549805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3423.0, "samples_count": 109568.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988756030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5007853507995605, "reduced_train_loss": 3.4789299964904785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3455.0, "samples_count": 110592.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988756582, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49704883015632123}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988756583, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988756583, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 110592, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988756738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.7091834545135498}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 256, "samples_count": 8224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988756893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15564250946044922}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 257, "samples_count": 8256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988757046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15311384201049805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 258, "samples_count": 8288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988757199, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15261340141296387}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 259, "samples_count": 8320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988757358, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15964818000793457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 260, "samples_count": 8352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988757514, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15601420402526855}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 261, "samples_count": 8384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988757675, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16007208824157715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 262, "samples_count": 8416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988757827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15272140502929688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 263, "samples_count": 8448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988757980, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15263795852661133}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 264, "samples_count": 8480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988758138, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15835332870483398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 265, "samples_count": 8512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988758294, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15583086013793945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 266, "samples_count": 8544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988758449, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15535640716552734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 267, "samples_count": 8576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988758607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1574389934539795}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 268, "samples_count": 8608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988758760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15331411361694336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 269, "samples_count": 8640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988758918, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1581730842590332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 270, "samples_count": 8672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988759073, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1544361114501953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 271, "samples_count": 8704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988759232, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15907049179077148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 272, "samples_count": 8736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988759387, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1548933982849121}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 273, "samples_count": 8768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988759543, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15592455863952637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 274, "samples_count": 8800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988759703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1605393886566162}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 275, "samples_count": 8832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988759857, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15419435501098633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 276, "samples_count": 8864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988760017, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15940451622009277}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 277, "samples_count": 8896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988760173, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15619301795959473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 278, "samples_count": 8928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988760330, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15702509880065918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 279, "samples_count": 8960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988760489, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1587977409362793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 280, "samples_count": 8992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988760643, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15439558029174805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 281, "samples_count": 9024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988760799, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1559896469116211}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 282, "samples_count": 9056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988760956, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15654230117797852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 283, "samples_count": 9088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988761114, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15790128707885742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 284, "samples_count": 9120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988761274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16005921363830566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 285, "samples_count": 9152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988761428, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15453171730041504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 286, "samples_count": 9184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988761583, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1546633243560791}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 287, "samples_count": 9216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988761584, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.4853086471557617, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 110592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988761584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 5.002252098172903}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988761584, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 110592, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988761584, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988777439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49175596237182617, "reduced_train_loss": 3.4925389289855957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3487.0, "samples_count": 111616.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988793276, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4923243522644043, "reduced_train_loss": 3.494152545928955}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3519.0, "samples_count": 112640.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988809156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49779343605041504, "reduced_train_loss": 3.407357692718506}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3551.0, "samples_count": 113664.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988825020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.48566532135009766, "reduced_train_loss": 3.491095781326294}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3583.0, "samples_count": 114688.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988840939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4928610324859619, "reduced_train_loss": 3.4440574645996094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3615.0, "samples_count": 115712.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988856810, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49326491355895996, "reduced_train_loss": 3.462057113647461}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3647.0, "samples_count": 116736.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988872647, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49712204933166504, "reduced_train_loss": 3.4053378105163574}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3679.0, "samples_count": 117760.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988888522, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4845852851867676, "reduced_train_loss": 3.4135897159576416}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3711.0, "samples_count": 118784.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988904374, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49341845512390137, "reduced_train_loss": 3.3943943977355957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3743.0, "samples_count": 119808.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988920247, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4991416931152344, "reduced_train_loss": 3.4368505477905273}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3775.0, "samples_count": 120832.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988936076, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49678850173950195, "reduced_train_loss": 3.3670053482055664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3807.0, "samples_count": 121856.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988951933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4947032928466797, "reduced_train_loss": 3.4623684883117676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3839.0, "samples_count": 122880.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988952474, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4971101168563716}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988952476, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988952476, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 122880, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988952632, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.7004883289337158}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 288, "samples_count": 9248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988952783, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15153241157531738}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 289, "samples_count": 9280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988952936, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1529853343963623}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 290, "samples_count": 9312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988953089, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15230011940002441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 291, "samples_count": 9344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988953243, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15402770042419434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 292, "samples_count": 9376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988953401, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15873432159423828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 293, "samples_count": 9408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988953558, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15640664100646973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 294, "samples_count": 9440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988953712, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15418696403503418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 295, "samples_count": 9472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988953867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15540814399719238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 296, "samples_count": 9504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988954022, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15448331832885742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 297, "samples_count": 9536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988954179, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1567072868347168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 298, "samples_count": 9568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988954335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15663409233093262}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 299, "samples_count": 9600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988954490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1551196575164795}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 300, "samples_count": 9632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988954645, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15476703643798828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 301, "samples_count": 9664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988954801, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1560676097869873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 302, "samples_count": 9696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988954960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1588602066040039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 303, "samples_count": 9728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988955118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15792202949523926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 304, "samples_count": 9760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988955273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15518879890441895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 305, "samples_count": 9792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988955430, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1567673683166504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 306, "samples_count": 9824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988955587, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15712642669677734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 307, "samples_count": 9856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988955746, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15866637229919434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 308, "samples_count": 9888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988955901, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15558099746704102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 309, "samples_count": 9920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988956059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15789580345153809}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 310, "samples_count": 9952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988956216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1566791534423828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 311, "samples_count": 9984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988956373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15722274780273438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 312, "samples_count": 10016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988956533, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16013717651367188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 313, "samples_count": 10048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988956690, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15636253356933594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 314, "samples_count": 10080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988956844, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15413188934326172}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 315, "samples_count": 10112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988957001, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1577925682067871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 316, "samples_count": 10144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988957160, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15804743766784668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 317, "samples_count": 10176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988957317, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1571342945098877}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 318, "samples_count": 10208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988957473, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15666437149047852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 319, "samples_count": 10240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988957474, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.4418442249298096, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 122880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988957474, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 5.000186439137906}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988957474, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 122880, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988957474, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988973355, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49512243270874023, "reduced_train_loss": 3.442718029022217}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3871.0, "samples_count": 123904.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759988989245, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49414801597595215, "reduced_train_loss": 3.426034450531006}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3903.0, "samples_count": 124928.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989005096, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.48909640312194824, "reduced_train_loss": 3.4673726558685303}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3935.0, "samples_count": 125952.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989020961, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.498760461807251, "reduced_train_loss": 3.464773654937744}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3967.0, "samples_count": 126976.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989036776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4887406826019287, "reduced_train_loss": 3.386425018310547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3999.0, "samples_count": 128000.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989052646, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49939608573913574, "reduced_train_loss": 3.425581455230713}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4031.0, "samples_count": 129024.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989068494, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4951910972595215, "reduced_train_loss": 3.3523924350738525}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4063.0, "samples_count": 130048.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989084333, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4973771572113037, "reduced_train_loss": 3.428676128387451}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4095.0, "samples_count": 131072.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989100175, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.494246244430542, "reduced_train_loss": 3.4600141048431396}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4127.0, "samples_count": 132096.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989116050, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4953150749206543, "reduced_train_loss": 3.3727898597717285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4159.0, "samples_count": 133120.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989131895, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49559450149536133, "reduced_train_loss": 3.3254966735839844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4191.0, "samples_count": 134144.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989147736, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4909348487854004, "reduced_train_loss": 3.370748519897461}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4223.0, "samples_count": 135168.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989148271, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4968672124814475}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989148272, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989148272, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 135168, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989148427, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6925468444824219}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 320, "samples_count": 10272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989148579, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1523752212524414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 321, "samples_count": 10304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989148732, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1530756950378418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 322, "samples_count": 10336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989148884, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1520366668701172}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 323, "samples_count": 10368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989149046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16138672828674316}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 324, "samples_count": 10400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989149202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15648722648620605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 325, "samples_count": 10432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989149358, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15636420249938965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 326, "samples_count": 10464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989149514, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1553182601928711}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 327, "samples_count": 10496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989149674, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16007018089294434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 328, "samples_count": 10528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989149829, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15514087677001953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 329, "samples_count": 10560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989149984, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15475130081176758}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 330, "samples_count": 10592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989150140, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15584444999694824}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 331, "samples_count": 10624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989150297, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15731215476989746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 332, "samples_count": 10656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989150452, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1549673080444336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 333, "samples_count": 10688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989150607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15507125854492188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 334, "samples_count": 10720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989150761, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1543726921081543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 335, "samples_count": 10752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989150917, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15568900108337402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 336, "samples_count": 10784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989151074, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15719985961914062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 337, "samples_count": 10816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989151229, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15495562553405762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 338, "samples_count": 10848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989151383, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15350723266601562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 339, "samples_count": 10880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989151541, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15873026847839355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 340, "samples_count": 10912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989151697, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15553045272827148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 341, "samples_count": 10944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989151855, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15760159492492676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 342, "samples_count": 10976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989152013, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15838146209716797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 343, "samples_count": 11008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989152170, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15740156173706055}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 344, "samples_count": 11040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989152326, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1558842658996582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 345, "samples_count": 11072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989152480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1541280746459961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 346, "samples_count": 11104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989152638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1574723720550537}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 347, "samples_count": 11136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989152795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15735983848571777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 348, "samples_count": 11168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989152954, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1585557460784912}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 349, "samples_count": 11200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989153111, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15738964080810547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 350, "samples_count": 11232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989153274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16275835037231445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 351, "samples_count": 11264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989153275, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.4264578819274902, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 135168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989153275, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 5.0036502201110125}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989153275, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 135168, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989153275, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989169126, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49849867820739746, "reduced_train_loss": 3.365391254425049}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4255.0, "samples_count": 136192.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989184973, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49808669090270996, "reduced_train_loss": 3.425161838531494}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4287.0, "samples_count": 137216.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989200827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4970967769622803, "reduced_train_loss": 3.3679425716400146}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4319.0, "samples_count": 138240.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989216704, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4995546340942383, "reduced_train_loss": 3.4274563789367676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4351.0, "samples_count": 139264.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989232544, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4977891445159912, "reduced_train_loss": 3.356541156768799}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4383.0, "samples_count": 140288.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989248389, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.497356653213501, "reduced_train_loss": 3.4146106243133545}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4415.0, "samples_count": 141312.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989264233, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49966955184936523, "reduced_train_loss": 3.382047176361084}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4447.0, "samples_count": 142336.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989280054, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5031275749206543, "reduced_train_loss": 3.4177193641662598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4479.0, "samples_count": 143360.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989295934, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49829840660095215, "reduced_train_loss": 3.413051128387451}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4511.0, "samples_count": 144384.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989311838, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5004477500915527, "reduced_train_loss": 3.391672134399414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4543.0, "samples_count": 145408.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989327733, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4967036247253418, "reduced_train_loss": 3.382513999938965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4575.0, "samples_count": 146432.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989343583, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4916958808898926, "reduced_train_loss": 3.374735116958618}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4607.0, "samples_count": 147456.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989344121, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49699473950992495}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989344122, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989344122, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 147456, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989344288, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.7075035572052002}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 352, "samples_count": 11296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989344439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15119552612304688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 353, "samples_count": 11328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989344593, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15372991561889648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 354, "samples_count": 11360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989344749, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15611839294433594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 355, "samples_count": 11392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989344904, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15450572967529297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 356, "samples_count": 11424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989345059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15508794784545898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 357, "samples_count": 11456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989345215, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15666532516479492}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 358, "samples_count": 11488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989345372, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1566922664642334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 359, "samples_count": 11520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989345535, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16293621063232422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 360, "samples_count": 11552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989345690, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15456938743591309}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 361, "samples_count": 11584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989345843, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15367388725280762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 362, "samples_count": 11616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989346000, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1572589874267578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 363, "samples_count": 11648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989346157, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15648841857910156}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 364, "samples_count": 11680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989346316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15872907638549805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 365, "samples_count": 11712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989346469, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15288901329040527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 366, "samples_count": 11744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989346624, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15508556365966797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 367, "samples_count": 11776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989346780, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15654850006103516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 368, "samples_count": 11808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989346936, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15614986419677734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 369, "samples_count": 11840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989347093, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15631675720214844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 370, "samples_count": 11872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989347247, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15432024002075195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 371, "samples_count": 11904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989347406, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1590867042541504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 372, "samples_count": 11936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989347565, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1586599349975586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 373, "samples_count": 11968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989347720, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15515518188476562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 374, "samples_count": 12000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989347876, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15604352951049805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 375, "samples_count": 12032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989348032, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15608716011047363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 376, "samples_count": 12064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989348190, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15783095359802246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 377, "samples_count": 12096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989348346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15623092651367188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 378, "samples_count": 12128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989348501, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15496087074279785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 379, "samples_count": 12160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989348660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1585700511932373}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 380, "samples_count": 12192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989348817, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15694761276245117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 381, "samples_count": 12224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989348973, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15642619132995605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 382, "samples_count": 12256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989349132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1585373878479004}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 383, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989349132, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.377814769744873, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 147456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989349132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 5.011532345088199}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989349133, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 147456, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989349133, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989364996, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49561095237731934, "reduced_train_loss": 3.3226566314697266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4639.0, "samples_count": 148480.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989380868, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4948842525482178, "reduced_train_loss": 3.3961801528930664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4671.0, "samples_count": 149504.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989396747, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49624204635620117, "reduced_train_loss": 3.363654136657715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4703.0, "samples_count": 150528.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989412617, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5054235458374023, "reduced_train_loss": 3.2618415355682373}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4735.0, "samples_count": 151552.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989428482, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5037238597869873, "reduced_train_loss": 3.3216171264648438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4767.0, "samples_count": 152576.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989444312, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4944734573364258, "reduced_train_loss": 3.293600559234619}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4799.0, "samples_count": 153600.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989460162, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49122166633605957, "reduced_train_loss": 3.3815197944641113}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4831.0, "samples_count": 154624.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989476047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49430084228515625, "reduced_train_loss": 3.3838963508605957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4863.0, "samples_count": 155648.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989491887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49436402320861816, "reduced_train_loss": 3.3244051933288574}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4895.0, "samples_count": 156672.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989507743, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49506330490112305, "reduced_train_loss": 3.357412815093994}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4927.0, "samples_count": 157696.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989523594, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49985480308532715, "reduced_train_loss": 3.3769803047180176}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4959.0, "samples_count": 158720.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989539464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49796485900878906, "reduced_train_loss": 3.2985968589782715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4991.0, "samples_count": 159744.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989539998, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49704570818479016}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989539999, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989539999, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 159744, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989540154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.69193434715271}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 384, "samples_count": 12320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989540307, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15254569053649902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 385, "samples_count": 12352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989540458, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15169668197631836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 386, "samples_count": 12384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989540613, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15478229522705078}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 387, "samples_count": 12416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989540772, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1593179702758789}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 388, "samples_count": 12448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989540931, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15829157829284668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 389, "samples_count": 12480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989541086, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1557002067565918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 390, "samples_count": 12512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989541241, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15443038940429688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 391, "samples_count": 12544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989541396, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15552473068237305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 392, "samples_count": 12576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989541554, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15772795677185059}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 393, "samples_count": 12608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989541710, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15624070167541504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 394, "samples_count": 12640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989541870, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15955305099487305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 395, "samples_count": 12672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989542026, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15570926666259766}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 396, "samples_count": 12704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989542182, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1564323902130127}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 397, "samples_count": 12736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989542336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15441632270812988}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 398, "samples_count": 12768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989542492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15598630905151367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 399, "samples_count": 12800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989542647, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15449261665344238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 400, "samples_count": 12832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989542802, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15475678443908691}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 401, "samples_count": 12864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989542959, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15697598457336426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 402, "samples_count": 12896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989543116, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15787410736083984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 403, "samples_count": 12928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989543270, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15326642990112305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 404, "samples_count": 12960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989543425, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1554276943206787}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 405, "samples_count": 12992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989543582, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1565690040588379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 406, "samples_count": 13024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989543739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15677571296691895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 407, "samples_count": 13056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989543896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15750384330749512}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 408, "samples_count": 13088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1558225154876709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 409, "samples_count": 13120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544209, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15671396255493164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 410, "samples_count": 13152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544367, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1588449478149414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 411, "samples_count": 13184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544522, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15437722206115723}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 412, "samples_count": 13216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544678, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15584683418273926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 413, "samples_count": 13248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544837, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1589527130126953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 414, "samples_count": 13280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15592336654663086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 415, "samples_count": 13312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544993, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.352599859237671, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 159744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544993, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.995387136004865}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544993, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 159744, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989544994, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989560827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49756455421447754, "reduced_train_loss": 3.3707797527313232}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5023.0, "samples_count": 160768.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989576680, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49631381034851074, "reduced_train_loss": 3.4146509170532227}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5055.0, "samples_count": 161792.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989592552, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49537205696105957, "reduced_train_loss": 3.4067115783691406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5087.0, "samples_count": 162816.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989608406, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.494213342666626, "reduced_train_loss": 3.3538026809692383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5119.0, "samples_count": 163840.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989624258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4971141815185547, "reduced_train_loss": 3.2938027381896973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5151.0, "samples_count": 164864.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989640090, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49228954315185547, "reduced_train_loss": 3.2813780307769775}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5183.0, "samples_count": 165888.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989655930, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49080419540405273, "reduced_train_loss": 3.3515710830688477}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5215.0, "samples_count": 166912.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989671772, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5004510879516602, "reduced_train_loss": 3.3787803649902344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5247.0, "samples_count": 167936.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989687578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4933137893676758, "reduced_train_loss": 3.3163156509399414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5279.0, "samples_count": 168960.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989703448, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49635744094848633, "reduced_train_loss": 3.269770622253418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5311.0, "samples_count": 169984.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989719288, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49570608139038086, "reduced_train_loss": 3.2783150672912598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5343.0, "samples_count": 171008.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989735107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4923107624053955, "reduced_train_loss": 3.2948150634765625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5375.0, "samples_count": 172032.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989735640, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4964755410862078}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989735641, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989735641, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 172032, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989735795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6900546550750732}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 416, "samples_count": 13344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989735946, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1512148380279541}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 417, "samples_count": 13376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989736099, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15274429321289062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 418, "samples_count": 13408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989736253, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15374326705932617}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 419, "samples_count": 13440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989736414, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16139626502990723}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 420, "samples_count": 13472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989736573, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15902256965637207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 421, "samples_count": 13504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989736730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1573951244354248}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 422, "samples_count": 13536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989736885, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1544041633605957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 423, "samples_count": 13568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989737043, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15781283378601074}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 424, "samples_count": 13600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989737197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15416622161865234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 425, "samples_count": 13632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989737353, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15574073791503906}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 426, "samples_count": 13664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989737509, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1561894416809082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 427, "samples_count": 13696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989737664, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15562891960144043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 428, "samples_count": 13728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989737823, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15886664390563965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 429, "samples_count": 13760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989737979, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.155503511428833}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 430, "samples_count": 13792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989738135, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15623998641967773}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 431, "samples_count": 13824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989738289, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15447115898132324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 432, "samples_count": 13856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989738450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16074800491333008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 433, "samples_count": 13888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989738607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15658259391784668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 434, "samples_count": 13920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989738762, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1549360752105713}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 435, "samples_count": 13952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989738917, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15546488761901855}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 436, "samples_count": 13984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989739073, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15606117248535156}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 437, "samples_count": 14016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989739229, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15529489517211914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 438, "samples_count": 14048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989739385, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15669918060302734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 439, "samples_count": 14080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989739542, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15687131881713867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 440, "samples_count": 14112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989739701, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15861058235168457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 441, "samples_count": 14144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989739855, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1544506549835205}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 442, "samples_count": 14176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740010, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15523982048034668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 443, "samples_count": 14208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740171, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16019701957702637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 444, "samples_count": 14240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740324, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1536390781402588}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 445, "samples_count": 14272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740479, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15516161918640137}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 446, "samples_count": 14304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740635, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15599656105041504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 447, "samples_count": 14336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740636, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.32218074798584, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 172032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.996277234982699}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740636, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 172032, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989740636, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989756477, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49959468841552734, "reduced_train_loss": 3.2980594635009766}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5407.0, "samples_count": 173056.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989772335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5028808116912842, "reduced_train_loss": 3.3412208557128906}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5439.0, "samples_count": 174080.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989788206, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4992232322692871, "reduced_train_loss": 3.3924155235290527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5471.0, "samples_count": 175104.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989804028, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4968576431274414, "reduced_train_loss": 3.32653546333313}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5503.0, "samples_count": 176128.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989819888, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4984467029571533, "reduced_train_loss": 3.3568572998046875}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5535.0, "samples_count": 177152.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989835694, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4849684238433838, "reduced_train_loss": 3.3218162059783936}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5567.0, "samples_count": 178176.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989851505, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.48960041999816895, "reduced_train_loss": 3.31459903717041}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5599.0, "samples_count": 179200.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989867350, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49602484703063965, "reduced_train_loss": 3.374464988708496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5631.0, "samples_count": 180224.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989883207, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49292898178100586, "reduced_train_loss": 3.2059426307678223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5663.0, "samples_count": 181248.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989899047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49669599533081055, "reduced_train_loss": 3.2827839851379395}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5695.0, "samples_count": 182272.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989914899, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4962458610534668, "reduced_train_loss": 3.3397574424743652}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5727.0, "samples_count": 183296.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989930761, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5002288818359375, "reduced_train_loss": 3.338597297668457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5759.0, "samples_count": 184320.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989931300, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49652104590616847}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989931301, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989931301, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 184320, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989931457, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6980583667755127}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 448, "samples_count": 14368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989931612, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15541386604309082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 449, "samples_count": 14400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989931765, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15332341194152832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 450, "samples_count": 14432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989931917, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1515519618988037}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 451, "samples_count": 14464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989932075, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15805459022521973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 452, "samples_count": 14496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989932229, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15439891815185547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 453, "samples_count": 14528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989932386, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15614056587219238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 454, "samples_count": 14560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989932540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15435504913330078}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 455, "samples_count": 14592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989932697, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15667295455932617}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 456, "samples_count": 14624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989932851, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15408825874328613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 457, "samples_count": 14656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989933006, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15517807006835938}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 458, "samples_count": 14688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989933163, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1566629409790039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 459, "samples_count": 14720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989933319, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15648174285888672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 460, "samples_count": 14752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989933474, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15496373176574707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 461, "samples_count": 14784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989933631, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15676569938659668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 462, "samples_count": 14816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989933786, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1551513671875}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 463, "samples_count": 14848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989933941, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15525507926940918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 464, "samples_count": 14880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989934098, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15656685829162598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 465, "samples_count": 14912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989934254, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15603089332580566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 466, "samples_count": 14944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989934408, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15398693084716797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 467, "samples_count": 14976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989934563, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15491843223571777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 468, "samples_count": 15008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989934721, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15807819366455078}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 469, "samples_count": 15040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989934875, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1542799472808838}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 470, "samples_count": 15072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989935029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1539931297302246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 471, "samples_count": 15104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989935187, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15798044204711914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 472, "samples_count": 15136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989935347, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1599733829498291}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 473, "samples_count": 15168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989935504, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15661144256591797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 474, "samples_count": 15200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989935660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1567239761352539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 475, "samples_count": 15232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989935818, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15769219398498535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 476, "samples_count": 15264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989935976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15775823593139648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 477, "samples_count": 15296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989936132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15609025955200195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 478, "samples_count": 15328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989936290, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15774893760681152}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 479, "samples_count": 15360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989936290, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.305320978164673, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 184320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989936291, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.990297507960349}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989936291, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 184320, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989936291, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989952163, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49930238723754883, "reduced_train_loss": 3.3345658779144287}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5791.0, "samples_count": 185344.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989968002, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4950559139251709, "reduced_train_loss": 3.3442225456237793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5823.0, "samples_count": 186368.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989983858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4850044250488281, "reduced_train_loss": 3.265900135040283}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5855.0, "samples_count": 187392.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759989999727, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4918992519378662, "reduced_train_loss": 3.2966489791870117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5887.0, "samples_count": 188416.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990015595, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49352526664733887, "reduced_train_loss": 3.2596182823181152}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5919.0, "samples_count": 189440.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990031477, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49846696853637695, "reduced_train_loss": 3.2336621284484863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5951.0, "samples_count": 190464.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990047335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49204492568969727, "reduced_train_loss": 3.2780418395996094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5983.0, "samples_count": 191488.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990063181, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.491929292678833, "reduced_train_loss": 3.212451934814453}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6015.0, "samples_count": 192512.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990079038, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.5022919178009033, "reduced_train_loss": 3.252462148666382}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6047.0, "samples_count": 193536.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990094862, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49659204483032227, "reduced_train_loss": 3.310356378555298}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6079.0, "samples_count": 194560.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990110696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.4942619800567627, "reduced_train_loss": 3.2613821029663086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6111.0, "samples_count": 195584.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990126568, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49995946884155273, "reduced_train_loss": 3.342073440551758}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6143.0, "samples_count": 196608.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990127117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.49694450951028557}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990127118, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990127118, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 196608, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990127274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.7073986530303955}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 480, "samples_count": 15392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990127427, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15396952629089355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 481, "samples_count": 15424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990127583, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15533971786499023}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 482, "samples_count": 15456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990127734, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15172100067138672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 483, "samples_count": 15488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990127889, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15418577194213867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 484, "samples_count": 15520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990128046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15729570388793945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 485, "samples_count": 15552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990128202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15580296516418457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 486, "samples_count": 15584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990128358, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15623831748962402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 487, "samples_count": 15616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990128512, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15388250350952148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 488, "samples_count": 15648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990128673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16061997413635254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 489, "samples_count": 15680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990128827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.154343843460083}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 490, "samples_count": 15712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990128983, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15638995170593262}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 491, "samples_count": 15744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990129139, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15576910972595215}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 492, "samples_count": 15776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990129296, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15682697296142578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 493, "samples_count": 15808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990129450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15429210662841797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 494, "samples_count": 15840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990129605, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15499162673950195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 495, "samples_count": 15872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990129763, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15783238410949707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 496, "samples_count": 15904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990129919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15569686889648438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 497, "samples_count": 15936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990130075, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1568455696105957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 498, "samples_count": 15968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990130229, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15349316596984863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 499, "samples_count": 16000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990130385, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15606355667114258}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 500, "samples_count": 16032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990130540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1545848846435547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 501, "samples_count": 16064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990130697, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15698575973510742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 502, "samples_count": 16096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990130853, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15591740608215332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 503, "samples_count": 16128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990131007, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15453100204467773}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 504, "samples_count": 16160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990131168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.16067075729370117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 505, "samples_count": 16192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990131323, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15572261810302734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 506, "samples_count": 16224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990131478, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15463876724243164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 507, "samples_count": 16256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990131634, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1560673713684082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 508, "samples_count": 16288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990131790, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15568852424621582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 509, "samples_count": 16320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990131944, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15447616577148438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 510, "samples_count": 16352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990132099, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.15467190742492676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 511, "samples_count": 16384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990132100, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.285334587097168, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 196608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990132100, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 4.982733050128445}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759990132100, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 196608, "step": 6144}}
 0: Average train_step_time 0.4952910025604069
 0: :::MLLOG {"namespace": "", "time_ms": 1759990132180, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 106, "step": 6144, "samples_count": 196608, "status": "success"}}
++ date +%s
+ echo 'RUNANDTIME_STOP 1759990188'
RUNANDTIME_STOP 1759990188
+ set -e
