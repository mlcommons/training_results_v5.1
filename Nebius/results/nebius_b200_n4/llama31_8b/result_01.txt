+ echo 'Beginning trial 01 of 10'
Beginning trial 01 of 10
+ echo ':::DLPAL /mnt/data/images/20251006/llama31_8b_20251006.sqsh 635 4 worker-[3,1-2,0] '\''unknown'\'' DGXB200_4x8x1xtp1pp1cp1_8b'
:::DLPAL /mnt/data/images/20251006/llama31_8b_20251006.sqsh 635 4 worker-[3,1-2,0] 'unknown' DGXB200_4x8x1xtp1pp1cp1_8b
++ srun -N1 -n1 --container-name=llama31_8b_635 --no-container-mount-home --container-remap-root --container-writable mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"4","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8580","host_processor_core_count":"40","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"1.7 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.09","framework_name":"","other_software_stack":{"cuda_version":"13.0.1.012","cuda_driver_version":"580.82.07","nccl_version":"v2.28.3-1","cublas_version":"13.0.2.14","cudnn_version":"9.13.1.26","trt_version":"10.13.3.9","dali_version":"1.51.2","mofed_version":"5.4-rdmacore56.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.11.0-1013-nvidia","nvidia_kernel_driver":"570.148.08"},"operating_system":"Ubuntu 24.04.3 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"4","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8580","host_processor_core_count":"40","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"1.7 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.09","framework_name":"","other_software_stack":{"cuda_version":"13.0.1.012","cuda_driver_version":"580.82.07","nccl_version":"v2.28.3-1","cublas_version":"13.0.2.14","cudnn_version":"9.13.1.26","trt_version":"10.13.3.9","dali_version":"1.51.2","mofed_version":"5.4-rdmacore56.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.11.0-1013-nvidia","nvidia_kernel_driver":"570.148.08"},"operating_system":"Ubuntu 24.04.3 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=llama31_8b_635 --no-container-mount-home --container-remap-root --container-writable bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID 06e7cd0aecce201e08e1cdaf9f598f58713ac6bc 
+ export SEED=11531
+ SEED=11531
+ '[' 1 -eq 1 ']'
+ srun --ntasks-per-node=1 bash -c '
                 host=$(hostname)
                 echo "$host sync_start"
                 sync && echo "$host sync_done"
                 cache_before=$(awk "/^Cached:/ {print \$2}" /proc/meminfo)
                 sudo /sbin/sysctl vm.drop_caches=3
                 cache_after=$(awk "/^Cached:/ {print \$2}" /proc/meminfo)
                 echo "$host cache_cleared ${cache_before}kB to ${cache_after}kB"
            '
worker-1 sync_start
worker-3 sync_start
worker-3 sync_done
worker-1 sync_done
worker-2 sync_start
worker-2 sync_done
worker-0 sync_start
worker-0 sync_done
vm.drop_caches = 3
worker-3 cache_cleared 146280632kB to 16554096kB
vm.drop_caches = 3
worker-2 cache_cleared 146423276kB to 16509972kB
vm.drop_caches = 3
worker-0 cache_cleared 147565600kB to 17710292kB
vm.drop_caches = 3
worker-1 cache_cleared 230765940kB to 100847224kB
+ srun --ntasks-per-node=1 --container-name=llama31_8b_635 --no-container-mount-home --container-remap-root --container-writable python -c '
from mlperf_common.callbacks import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
:::MLLOG {"namespace": "", "time_ms": 1759898627374, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1759898628018, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1759898628024, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1759898629009, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1759898631'
RUNANDTIME_START 1759898631
+ SLURM_HOSTFILE=/mnt/data/runs/b200n4/llama31_8b/logs/hostfile.635.1RtF
+ NV_MLPERF_DEBUG=1
+ srun -l --mpi=pmi2 --ntasks-per-node=8 --distribution=arbitrary --time=60 --container-name=llama31_8b_635 --no-container-mount-home --container-remap-root --container-writable --container-mounts=/mnt/data/runs/b200n4/llama31_8b/logs:/results,/mnt/data/runs/b200n4/llama31_8b/logs/251008044035907084932_npy_index:/npy_index,/mnt/data/runs/b200n4/llama31_8b/logs/mem_dump:/mem_dump,/mnt/data/datasets/llama31_8b/8b/tokenizer:/workspace/llm/nemo_tokenizer:ro,/mnt/data/datasets/llama31_8b/8b:/preproc_data:ro --container-workdir=/workspace/llm --container-env=MASTER_PORT,MASTER_ADDR,NCCL_SHARP_GROUP_SIZE_THRESH,NCCL_NVLS_ENABLE slurm2pytorch ./run_and_time.sh
 0: slurm2pytorch: MASTER_ADDR=worker-0 MASTER_PORT=29500 WORLD_SIZE=32
11: LOAD_CHECKPOINT=
 8: LOAD_CHECKPOINT=
 8: Hello from: worker-1
12: LOAD_CHECKPOINT=
15: LOAD_CHECKPOINT=
10: LOAD_CHECKPOINT=
14: LOAD_CHECKPOINT=
13: LOAD_CHECKPOINT=
 9: LOAD_CHECKPOINT=
 3: LOAD_CHECKPOINT=
 0: LOAD_CHECKPOINT=
 2: LOAD_CHECKPOINT=
 0: Hello from: worker-0
 0: running LLM benchmark
 0: Extra args:  exp_manager.explicit_log_dir="/results/251008044035907084932"
 7: LOAD_CHECKPOINT=
 4: LOAD_CHECKPOINT=
 6: LOAD_CHECKPOINT=
 1: LOAD_CHECKPOINT=
 5: LOAD_CHECKPOINT=
30: LOAD_CHECKPOINT=
27: LOAD_CHECKPOINT=
24: LOAD_CHECKPOINT=
24: Hello from: worker-3
25: LOAD_CHECKPOINT=
29: LOAD_CHECKPOINT=
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
28: LOAD_CHECKPOINT=
26: LOAD_CHECKPOINT=
31: LOAD_CHECKPOINT=
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
18: LOAD_CHECKPOINT=
19: LOAD_CHECKPOINT=
16: LOAD_CHECKPOINT=
16: Hello from: worker-2
17: LOAD_CHECKPOINT=
23: LOAD_CHECKPOINT=
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
21: LOAD_CHECKPOINT=
20: LOAD_CHECKPOINT=
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
10: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
10:   import pynvml  # type: ignore[import]
11: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
11:   import pynvml  # type: ignore[import]
 8: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 8:   import pynvml  # type: ignore[import]
15: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
15:   import pynvml  # type: ignore[import]
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
22: LOAD_CHECKPOINT=
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
14: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
14:   import pynvml  # type: ignore[import]
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 9: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 9:   import pynvml  # type: ignore[import]
13: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
13:   import pynvml  # type: ignore[import]
12: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
12:   import pynvml  # type: ignore[import]
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
28: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
18: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
31: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 2: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 2:   import pynvml  # type: ignore[import]
 3: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 3:   import pynvml  # type: ignore[import]
 0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 0:   import pynvml  # type: ignore[import]
 7: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 7:   import pynvml  # type: ignore[import]
24: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
 1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 1:   import pynvml  # type: ignore[import]
 6: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 6:   import pynvml  # type: ignore[import]
 4: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 4:   import pynvml  # type: ignore[import]
 5: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
 5:   import pynvml  # type: ignore[import]
23: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
27: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
25: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
26: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
29: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
30: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
17: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
21: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
20: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
19: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
16: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
22: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=40
28: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
28:   import pynvml  # type: ignore[import]
31: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
31:   import pynvml  # type: ignore[import]
18: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
18:   import pynvml  # type: ignore[import]
24: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
24:   import pynvml  # type: ignore[import]
25: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
25:   import pynvml  # type: ignore[import]
23: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
23:   import pynvml  # type: ignore[import]
26: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
26:   import pynvml  # type: ignore[import]
17: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
17:   import pynvml  # type: ignore[import]
27: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
27:   import pynvml  # type: ignore[import]
30: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
30:   import pynvml  # type: ignore[import]
29: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
29:   import pynvml  # type: ignore[import]
19: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
19:   import pynvml  # type: ignore[import]
16: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
16:   import pynvml  # type: ignore[import]
20: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
20:   import pynvml  # type: ignore[import]
22: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
22:   import pynvml  # type: ignore[import]
21: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
21:   import pynvml  # type: ignore[import]
17: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
20: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
19: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
18: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
22: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
21: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
16: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
23: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 8: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
12: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 9: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
13: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
11: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
15: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
10: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
14: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 0: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 3: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 1: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 7: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 4: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 2: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 6: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 5: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
28: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
26: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
24: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
30: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
31: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
29: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
25: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
27: fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 0: :::MLLOG {"namespace": "", "time_ms": 1759898676735, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 750}}
 0: [NeMo I 2025-10-08 04:44:36 nemo_logging:393] 
 0:     
 0:     **************** Experiment configuration ****************
 0: [NeMo I 2025-10-08 04:44:36 nemo_logging:393] 
 0:     model:
 0:       data:
 0:         data_prefix:
 0:           train:
 0:           - 0.5
 0:           - /preproc_data/c4_en_6_c4_spm_text_document
 0:           - 0.5
 0:           - /preproc_data/c4_en_7_c4_spm_text_document
 0:           validation:
 0:           - /preproc_data/c4_en_validation_subset_c4_spm_text_document
 0:           test:
 0:           - /preproc_data/c4_en_validation_subset_c4_spm_text_document
 0:         index_mapping_dir: /npy_index
 0:         splits_string: null
 0:         validation_drop_last: false
 0:         pad_samples_to_global_batch_size: true
 0:         shuffle_documents: false
 0:         legacy_dataset: true
 0:         delay_data_init: true
 0:         delay_data_mmap: true
 0:         no_seqlen_plus_one_input_tokens: true
 0:         exchange_indices_distributed: true
 0:         mock_dataset: false
 0:         mock_tokenizer_vocab_size: 32000
 0:       mcore_gpt: true
 0:       name: megatron_gpt_full_te_layer_autocast
 0:       micro_batch_size: 1
 0:       tensor_model_parallel_size: 1
 0:       pipeline_model_parallel_size: 1
 0:       virtual_pipeline_model_parallel_size: null
 0:       context_parallel_size: 1
 0:       expert_model_parallel_size: 1
 0:       global_batch_size: 32
 0:       use_tp_pp_dp_mapping: true
 0:       base_config: 8b
 0:       overwritten_attributes:
 0:         num_layers: 32
 0:         enable_cuda_graph: 1
 0:         cuda_graph_scope: full_iteration
 0:       encoder_seq_length: 8192
 0:       overlap_p2p_comm: true
 0:       batch_p2p_comm: false
 0:       account_for_embedding_in_pipeline_split: false
 0:       account_for_loss_in_pipeline_split: false
 0:       external_cuda_graph: false
 0:       defer_embedding_wgrad_compute: false
 0:       wgrad_deferral_limit: 50
 0:       tokenizer:
 0:         model: /workspace/llm/nemo_tokenizer
 0:       gradient_accumulation_fusion: true
 0:       fused_single_qkv_rope: true
 0:       cross_entropy_loss_fusion: true
 0:       deterministic_mode: false
 0:       seed: 11531
 0:       resume_from_checkpoint: null
 0:       dist_ckpt_format: torch_dist
 0:       dist_ckpt_parallel_load: true
 0:       sync_batch_comm: false
 0:       activations_checkpoint_granularity: null
 0:       activations_checkpoint_method: null
 0:       activations_checkpoint_num_layers: null
 0:       sequence_parallel: false
 0:       transformer_engine: true
 0:       fp8: false
 0:       fp8_hybrid: true
 0:       fp8_recipe: tensorwise
 0:       fp8_amax_history_len: 1
 0:       fp8_amax_compute_algo: most_recent
 0:       fp4: true
 0:       fp4_recipe: nvfp4
 0:       reduce_amax: true
 0:       tp_only_amax_red: true
 0:       first_last_layers_bf16: false
 0:       num_layers_at_start_in_bf16: 0
 0:       num_layers_at_end_in_bf16: 0
 0:       fp8_dot_product_attention: true
 0:       use_te_rng_tracker: true
 0:       use_transformer_engine_op_fuser: true
 0:       cross_entropy_fusion_impl: te
 0:       ub_tp_comm_overlap: false
 0:       tp_comm_overlap_ag: true
 0:       tp_comm_overlap_rs: true
 0:       nccl_communicator_config_path: /workspace/llm/conf/nccl/custom_communicator_cta.yaml
 0:       sharp: false
 0:       optim:
 0:         overlap_grad_reduce: true
 0:         overlap_param_gather: true
 0:         align_param_gather: false
 0:         use_distributed_optimizer: true
 0:         bucket_size: 134217728
 0:         fp8_param_gather: false
 0:         overlap_param_gather_with_optim_step: false
 0:         lr: 0.0008
 0:         sched:
 0:           min_lr: 8.0e-05
 0:           warmup_steps: 96
 0:           max_steps_for_lr_sched: 43200000.0
 0:         lock_timeout: null
 0:       gc_interval_train: 10000
 0:       gc_interval_valid: 10000
 0:       nsys_profile:
 0:         enabled: false
 0:         start_step: 10
 0:         end_step: 10
 0:         ranks:
 0:         - 0
 0:         gen_shape: false
 0:         nvtx_ranges: false
 0:       custom:
 0:         log_metrics: NEMO
 0:         init_global_step: 0
 0:         target_log_ppl: 3.3
 0:         use_distributed_checkpointing: 1
 0:         run_warmup_on_synth_data: 1
 0:         reset_fp8_stats_after_warmup: 1
 0:         pre_validate: 0
 0:         override_zero_consumed_samples: 1
 0:         force_success_status: 0
 0:         warmup_train_steps: 2
 0:         warmup_validation_steps: 2
 0:         extend_run_evals: 0
 0:         disable_nemo_logs: true
 0:     proxy_gbs: 32
 0:     is_proxy_run: false
 0:     skip_evals: 12
 0:     default_val_check_interval: 384
 0:     trainer:
 0:       devices: 8
 0:       num_nodes: 4
 0:       precision: bf16
 0:       max_steps: 1200000
 0:       max_epochs: 1
 0:       log_every_n_steps: 32
 0:       val_check_interval: 384
 0:       limit_val_batches: 32
 0:       limit_test_batches: 1
 0:       limit_train_batches: null
 0:       enable_progress_bar: false
 0:       num_sanity_val_steps: 0
 0:     exp_manager:
 0:       explicit_log_dir: /results/251008044035907084932
 0:       resume_if_exists: 0
 0:       create_checkpoint_callback: 0
 0:       checkpoint_callback_params:
 0:         save_top_k: 1
 0:         mode: max
 0:         every_n_epochs: 0
 0:         save_last: true
 0:       log_step_timing: true
 0:       create_tensorboard_logger: false
 0:       log_global_rank_0_only: true
 0:     misc:
 0:       print_config: false
 0:       memory_profiler:
 0:         enable: false
 0:         file_prefix: memdump
 0:         max_entries: 1000000
 0:         rank_0_only: true
 0:         start_location: init
 0:         end_location: train_start
 0:         force_oom_before_stop: false
 0:         possible_oom: false
 0:     
 0: [NeMo I 2025-10-08 04:44:36 nemo_logging:393] 
 0:     TP: 1; PP: 1; VP: None; CP: 1
 0: [NeMo I 2025-10-08 04:44:36 nemo_logging:393] ======== Benchmarked setups ========
 0: GPU available: True (cuda), used: True
 0: TPU available: False, using: 0 TPU cores
 0: HPU available: False, using: 0 HPUs
 0: `Trainer(limit_test_batches=1)` was configured so 1 batch will be used.
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677739, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama31_8b", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677740, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677740, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677740, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677740, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "4xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 566}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677740, "event_type": "POINT_IN_TIME", "key": "seed", "value": 11531, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677740, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 32, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677740, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1.0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677741, "event_type": "POINT_IN_TIME", "key": "max_sequence_length", "value": 8192, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677741, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 1024, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677741, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1574207408, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677741, "event_type": "POINT_IN_TIME", "key": "init_checkpoint_step", "value": 0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677741, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677741, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0008, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677741, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677741, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.95, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677742, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-05, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677742, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.1, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677742, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 1.0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677742, "event_type": "POINT_IN_TIME", "key": "opt_end_learning_rate", "value": 8e-05, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677742, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 96, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677742, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_steps", "value": 1199904, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677742, "event_type": "POINT_IN_TIME", "key": "max_steps", "value": 1200000, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677743, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_schedule", "value": "cosine with linear warmup", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898677743, "event_type": "POINT_IN_TIME", "key": "target_accuracy", "value": 3.3, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 601}}
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] ======== Benchmarked fit ========
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Experiments will be logged at /workspace/llm/nemo_experiments/default/2025-10-08_04-44-37
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has data parallel group : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Ranks 0 has data parallel rank: 0
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has context parallel group: [0]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Ranks 0 has context parallel rank: 0
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has model parallel group: [0]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] All model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has tensor model parallel group: [0]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] All tensor model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has tensor model parallel rank: 0
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has embedding group: [0]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has pipeline model parallel rank 0
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31]]
 0: [NeMo I 2025-10-08 04:44:37 nemo_logging:393] Rank 0 has embedding rank: 0
 0: [AUX I 2025-10-08 04:44:37 megatron_strategy:607] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
22: [W1008 04:44:38.975781886 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 6: [W1008 04:44:38.876197041 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 8: [W1008 04:44:38.995778538 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 9: [W1008 04:44:38.995777684 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
10: [W1008 04:44:38.995776301 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
11: [W1008 04:44:38.995782411 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
12: [W1008 04:44:38.995800585 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
13: [W1008 04:44:38.995800337 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
14: [W1008 04:44:38.995800765 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
15: [W1008 04:44:38.001382639 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
19: [W1008 04:44:38.093345364 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 5: [W1008 04:44:38.013840581 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
25: [W1008 04:44:38.048531102 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
27: [W1008 04:44:38.052485284 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
28: [W1008 04:44:38.052539743 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
30: [W1008 04:44:38.052539058 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
31: [W1008 04:44:38.052482454 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
24: [W1008 04:44:38.054675052 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
29: [W1008 04:44:38.068075093 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
26: [W1008 04:44:38.070167521 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
21: [W1008 04:44:38.202038853 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
23: [W1008 04:44:38.233989334 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
18: [W1008 04:44:38.235677064 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
16: [W1008 04:44:38.263955079 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 1: [W1008 04:44:38.198147518 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 4: [W1008 04:44:38.210452668 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 3: [W1008 04:44:38.230589727 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 2: [W1008 04:44:38.251087591 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
17: [W1008 04:44:38.426611594 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
20: [W1008 04:44:38.426561611 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 7: [W1008 04:44:38.316922246 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 0: [W1008 04:44:38.317602705 ProcessGroupNCCL.cpp:927] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 0: ----------------------------------------------------------------------------------------------------
 0: distributed_backend=nccl
 0: All distributed processes registered. Starting with 32 processes
 0: ----------------------------------------------------------------------------------------------------
 0: 
12: [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 0: [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
10: [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 1: [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 2: [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 8: [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 6: [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 5: [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 3: [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 4: [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
17: [Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
18: [Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
21: [Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
23: [Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
14: [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
22: [Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
27: [Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 9: [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
16: [Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
15: [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
11: [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 7: [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
19: [Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
20: [Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
13: [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
24: [Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
25: [Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
26: [Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
28: [Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
29: [Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
30: [Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
31: [Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
12: [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
16: [Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 2: [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 0: [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 3: [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 1: [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
18: [Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 6: [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
21: [Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 8: [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
19: [Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
13: [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
15: [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 4: [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 5: [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
10: [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
23: [Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
14: [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
20: [Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
17: [Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 9: [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 7: [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
22: [Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
24: [Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
11: [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
25: [Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
26: [Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
28: [Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
30: [Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
29: [Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
27: [Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
31: [Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 0: [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 2: [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
15: [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 1: [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 3: [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 6: [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 4: [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
17: [Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 8: [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
10: [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
14: [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
20: [Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
24: [Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
26: [Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
13: [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
19: [Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
12: [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
27: [Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
18: [Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
11: [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 5: [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
16: [Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
28: [Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
25: [Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
29: [Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
23: [Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 9: [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 7: [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
22: [Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
21: [Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
31: [Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
30: [Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 0: [NeMo I 2025-10-08 04:44:44 utils:662] Building GPTDataset splits with sizes=[38400000, 3201024, 32] and config=GPTDatasetConfig(random_seed=11531, sequence_length=8192, blend=None, blend_per_split=[(['/preproc_data/c4-train.en_6_text_document'], [50.0]), (['/preproc_data/c4-validation-91205-samples.en_text_document'], None), (['/preproc_data/c4-validation-91205-samples.en_text_document'], None)], multiple_validation_sets=None, full_validation=None, split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache='/npy_index', mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.huggingface.auto_tokenizer.AutoTokenizer object at 0xda73be627b0>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)
 0: [NeMo I 2025-10-08 04:44:44 utils:662] Load the _IndexReader from /preproc_data/c4-train.en_6_text_document.idx
 0: [NeMo I 2025-10-08 04:44:44 utils:662] 	Extract the sequence lengths
 0: [NeMo I 2025-10-08 04:44:44 utils:662] 	Extract the sequence pointers
 0: [NeMo I 2025-10-08 04:44:44 utils:662] 	Extract the document indices
 0: [NeMo I 2025-10-08 04:44:44 utils:662] > total number of sequences: 45608611
 0: [NeMo I 2025-10-08 04:44:44 utils:662] > total number of documents: 45608611
 0: [NeMo I 2025-10-08 04:44:44 utils:662] Build and save the GPTDataset train indices
 0: [NeMo I 2025-10-08 04:45:32 utils:662] > total number of samples: 38441516
 0: [NeMo I 2025-10-08 04:45:32 utils:662] > total number of epochs: 15
 0: [NeMo I 2025-10-08 04:45:32 utils:662] Load the _IndexReader from /preproc_data/c4-validation-91205-samples.en_text_document.idx
 0: [NeMo I 2025-10-08 04:45:32 utils:662] 	Extract the sequence lengths
 0: [NeMo I 2025-10-08 04:45:32 utils:662] 	Extract the sequence pointers
 0: [NeMo I 2025-10-08 04:45:32 utils:662] 	Extract the document indices
 0: [NeMo I 2025-10-08 04:45:32 utils:662] > total number of sequences: 91205
 0: [NeMo I 2025-10-08 04:45:32 utils:662] > total number of documents: 91205
 0: [NeMo I 2025-10-08 04:45:32 utils:662] Build and save the GPTDataset valid indices
 0: [NeMo I 2025-10-08 04:45:35 utils:662] > total number of samples: 3202455
 0: [NeMo I 2025-10-08 04:45:35 utils:662] > total number of epochs: 630
 0: [NeMo I 2025-10-08 04:45:35 utils:662] Load the _IndexReader from /preproc_data/c4-validation-91205-samples.en_text_document.idx
 0: [NeMo I 2025-10-08 04:45:35 utils:662] 	Extract the sequence lengths
 0: [NeMo I 2025-10-08 04:45:35 utils:662] 	Extract the sequence pointers
 0: [NeMo I 2025-10-08 04:45:35 utils:662] 	Extract the document indices
 0: [NeMo I 2025-10-08 04:45:35 utils:662] > total number of sequences: 91205
 0: [NeMo I 2025-10-08 04:45:35 utils:662] > total number of documents: 91205
 0: [NeMo I 2025-10-08 04:45:35 utils:662] Build and save the GPTDataset test indices
 0: [NeMo I 2025-10-08 04:45:35 utils:662] > total number of samples: 5083
 0: [NeMo I 2025-10-08 04:45:35 utils:662] > total number of epochs: 1
 0: [NeMo W 2025-10-08 04:45:35 nemo_logging:405] Recommend unsetting CUDA_DEVICE_MAX_CONNECTIONS for best performance                         but get 1
 0: [NeMo I 2025-10-08 04:45:35 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.
 0: [NeMo I 2025-10-08 04:45:35 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.
 0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 3: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 4: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 6: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 5: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
16: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 2: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
21: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 7: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
23: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-08 04:45:35 nemo_logging:393] Copying Trainer's 'max_steps' (1200000) to LR scheduler's 'max_steps'.
22: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
18: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
19: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
20: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
17: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-08 04:45:35 num_microbatches_calculator:228] setting number of microbatches to constant 1
 0: [NeMo I 2025-10-08 04:45:35 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 8030261248
 0: [NeMo I 2025-10-08 04:45:35 utils:662] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=False, check_for_large_grads=False, bucket_size=134217728, pad_buckets_for_high_nccl_busbw=False, average_in_collective=True, fp8_param_gather=False, reuse_grad_buf_for_mxfp8_param_ag=False, use_megatron_fsdp=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache=False, nccl_ub=False, fsdp_double_buffer=False, outer_dp_sharding_strategy='no_shard', disable_symmetric_registration=False, delay_wgrad_compute=False)
28: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
29: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
26: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
30: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
31: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
24: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
25: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
27: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
13: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
14: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
15: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
12: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 8: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 9: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
10: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
11: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-08 04:45:36 utils:695] Number of buckets for gradient all-reduce / reduce-scatter: 34
 0:     Params for bucket 1 (525336576 elements, 525336576 padded size):
 0:     	module.output_layer.weight
 0:     Params for bucket 2 (176164864 elements, 176164864 padded size):
 0:     	module.decoder.final_layernorm.weight
 0:     	module.decoder.layers.31.mlp.linear_fc1.weight
 0:     	module.decoder.layers.31.mlp.linear_fc2.weight
 0:     Params for bucket 3 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.31.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.30.mlp.linear_fc1.weight
 0:     	module.decoder.layers.31.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.31.self_attention.linear_proj.weight
 0:     	module.decoder.layers.31.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.30.mlp.linear_fc2.weight
 0:     Params for bucket 4 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.30.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.29.mlp.linear_fc1.weight
 0:     	module.decoder.layers.30.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.30.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.29.mlp.linear_fc2.weight
 0:     	module.decoder.layers.30.self_attention.linear_proj.weight
 0:     Params for bucket 5 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.29.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.28.mlp.linear_fc1.weight
 0:     	module.decoder.layers.29.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.29.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.28.mlp.linear_fc2.weight
 0:     	module.decoder.layers.29.self_attention.linear_proj.weight
 0:     Params for bucket 6 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.28.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.27.mlp.linear_fc1.weight
 0:     	module.decoder.layers.28.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.28.self_attention.linear_proj.weight
 0:     	module.decoder.layers.28.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.27.mlp.linear_fc2.weight
 0:     Params for bucket 7 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.27.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.26.mlp.linear_fc1.weight
 0:     	module.decoder.layers.27.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.26.mlp.linear_fc2.weight
 0:     	module.decoder.layers.27.self_attention.linear_proj.weight
 0:     	module.decoder.layers.27.self_attention.linear_qkv.weight
 0:     Params for bucket 8 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.26.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.25.mlp.linear_fc1.weight
 0:     	module.decoder.layers.26.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.26.self_attention.linear_proj.weight
 0:     	module.decoder.layers.26.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.25.mlp.linear_fc2.weight
 0:     Params for bucket 9 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.25.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.24.mlp.linear_fc1.weight
 0:     	module.decoder.layers.25.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.24.mlp.linear_fc2.weight
 0:     	module.decoder.layers.25.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.25.self_attention.linear_proj.weight
 0:     Params for bucket 10 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.23.mlp.linear_fc1.weight
 0:     	module.decoder.layers.24.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.24.self_attention.linear_proj.weight
 0:     	module.decoder.layers.24.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.23.mlp.linear_fc2.weight
 0:     Params for bucket 11 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.22.mlp.linear_fc1.weight
 0:     	module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.23.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.23.self_attention.linear_proj.weight
 0:     	module.decoder.layers.22.mlp.linear_fc2.weight
 0:     Params for bucket 12 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.21.mlp.linear_fc1.weight
 0:     	module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.21.mlp.linear_fc2.weight
 0:     	module.decoder.layers.22.self_attention.linear_proj.weight
 0:     	module.decoder.layers.22.self_attention.linear_qkv.weight
 0:     Params for bucket 13 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.20.mlp.linear_fc1.weight
 0:     	module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.20.mlp.linear_fc2.weight
 0:     	module.decoder.layers.21.self_attention.linear_proj.weight
 0:     	module.decoder.layers.21.self_attention.linear_qkv.weight
 0:     Params for bucket 14 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.19.mlp.linear_fc1.weight
 0:     	module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.20.self_attention.linear_proj.weight
 0:     	module.decoder.layers.20.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.19.mlp.linear_fc2.weight
 0:     Params for bucket 15 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.18.mlp.linear_fc1.weight
 0:     	module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.19.self_attention.linear_proj.weight
 0:     	module.decoder.layers.19.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.18.mlp.linear_fc2.weight
 0:     Params for bucket 16 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.17.mlp.linear_fc1.weight
 0:     	module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.18.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.18.self_attention.linear_proj.weight
 0:     	module.decoder.layers.17.mlp.linear_fc2.weight
 0:     Params for bucket 17 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.16.mlp.linear_fc1.weight
 0:     	module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.17.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.16.mlp.linear_fc2.weight
 0:     	module.decoder.layers.17.self_attention.linear_proj.weight
 0:     Params for bucket 18 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.15.mlp.linear_fc2.weight
 0:     	module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.16.self_attention.linear_proj.weight
 0:     	module.decoder.layers.16.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.15.mlp.linear_fc1.weight
 0:     Params for bucket 19 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.15.self_attention.linear_proj.weight
 0:     	module.decoder.layers.15.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.14.mlp.linear_fc2.weight
 0:     	module.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.14.mlp.linear_fc1.weight
 0:     Params for bucket 20 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.14.self_attention.linear_proj.weight
 0:     	module.decoder.layers.14.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.13.mlp.linear_fc1.weight
 0:     	module.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.13.mlp.linear_fc2.weight
 0:     Params for bucket 21 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.12.mlp.linear_fc1.weight
 0:     	module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.13.self_attention.linear_proj.weight
 0:     	module.decoder.layers.12.mlp.linear_fc2.weight
 0:     	module.decoder.layers.13.self_attention.linear_qkv.weight
 0:     Params for bucket 22 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.11.mlp.linear_fc1.weight
 0:     	module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.12.self_attention.linear_proj.weight
 0:     	module.decoder.layers.12.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.11.mlp.linear_fc2.weight
 0:     Params for bucket 23 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.10.mlp.linear_fc1.weight
 0:     	module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.11.self_attention.linear_proj.weight
 0:     	module.decoder.layers.11.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.10.mlp.linear_fc2.weight
 0:     Params for bucket 24 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.9.mlp.linear_fc1.weight
 0:     	module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.10.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.9.mlp.linear_fc2.weight
 0:     	module.decoder.layers.10.self_attention.linear_proj.weight
 0:     Params for bucket 25 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.8.mlp.linear_fc1.weight
 0:     	module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.9.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.8.mlp.linear_fc2.weight
 0:     	module.decoder.layers.9.self_attention.linear_proj.weight
 0:     Params for bucket 26 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.7.mlp.linear_fc1.weight
 0:     	module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.8.self_attention.linear_proj.weight
 0:     	module.decoder.layers.8.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.7.mlp.linear_fc2.weight
 0:     Params for bucket 27 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.6.mlp.linear_fc1.weight
 0:     	module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.7.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.6.mlp.linear_fc2.weight
 0:     	module.decoder.layers.7.self_attention.linear_proj.weight
 0:     Params for bucket 28 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.5.mlp.linear_fc1.weight
 0:     	module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.5.mlp.linear_fc2.weight
 0:     	module.decoder.layers.6.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.6.self_attention.linear_proj.weight
 0:     Params for bucket 29 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.5.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.4.mlp.linear_fc1.weight
 0:     	module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.5.self_attention.linear_proj.weight
 0:     	module.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.4.mlp.linear_fc2.weight
 0:     Params for bucket 30 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.3.mlp.linear_fc2.weight
 0:     	module.decoder.layers.4.self_attention.linear_proj.weight
 0:     	module.decoder.layers.4.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.3.mlp.linear_fc1.weight
 0:     Params for bucket 31 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.3.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.2.mlp.linear_fc2.weight
 0:     	module.decoder.layers.3.self_attention.linear_proj.weight
 0:     	module.decoder.layers.2.mlp.linear_fc1.weight
 0:     Params for bucket 32 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.1.mlp.linear_fc2.weight
 0:     	module.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.1.mlp.linear_fc1.weight
 0:     	module.decoder.layers.2.self_attention.linear_proj.weight
 0:     	module.decoder.layers.2.self_attention.linear_qkv.weight
 0:     Params for bucket 33 (218112000 elements, 218112000 padded size):
 0:     	module.decoder.layers.1.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.0.mlp.linear_fc2.weight
 0:     	module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.1.self_attention.linear_proj.weight
 0:     	module.decoder.layers.0.mlp.linear_fc1.weight
 0:     Params for bucket 34 (567287808 elements, 567287808 padded size):
 0:     	module.decoder.layers.0.self_attention.linear_proj.weight
 0:     	module.embedding.word_embeddings.weight
 0:     	module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight
 0:     	module.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.0.self_attention.linear_qkv.weight
 0: [NeMo I 2025-10-08 04:45:36 utils:662] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0008, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp8_recipe='tensorwise', fp16=False, bf16=True, reuse_grad_buf_for_mxfp8_param_ag=False, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_ti
 0: me=False, timers=None, config_logger_dir='')
 0: 
 0:   | Name   | Type | Params | Mode 
 0: ----------------------------------------
 0: 0 | module | DDP  | 8.0 B  | train
 0: ----------------------------------------
 0: 8.0 B     Trainable params
 0: 0         Non-trainable params
 0: 8.0 B     Total params
 0: 32,121.045Total estimated model params size (MB)
 0: 651       Modules in train mode
 0: 0         Modules in eval mode
24: SLURM auto-requeueing enabled. Setting signal handlers.
25: SLURM auto-requeueing enabled. Setting signal handlers.
26: SLURM auto-requeueing enabled. Setting signal handlers.
27: SLURM auto-requeueing enabled. Setting signal handlers.
28: SLURM auto-requeueing enabled. Setting signal handlers.
29: SLURM auto-requeueing enabled. Setting signal handlers.
30: SLURM auto-requeueing enabled. Setting signal handlers.
31: SLURM auto-requeueing enabled. Setting signal handlers.
16: SLURM auto-requeueing enabled. Setting signal handlers.
 8: SLURM auto-requeueing enabled. Setting signal handlers.
17: SLURM auto-requeueing enabled. Setting signal handlers.
 9: SLURM auto-requeueing enabled. Setting signal handlers.
18: SLURM auto-requeueing enabled. Setting signal handlers.
10: SLURM auto-requeueing enabled. Setting signal handlers.
 0: SLURM auto-requeueing enabled. Setting signal handlers.
 1: SLURM auto-requeueing enabled. Setting signal handlers.
 2: SLURM auto-requeueing enabled. Setting signal handlers.
19: SLURM auto-requeueing enabled. Setting signal handlers.
11: SLURM auto-requeueing enabled. Setting signal handlers.
 3: SLURM auto-requeueing enabled. Setting signal handlers.
20: SLURM auto-requeueing enabled. Setting signal handlers.
12: SLURM auto-requeueing enabled. Setting signal handlers.
 4: SLURM auto-requeueing enabled. Setting signal handlers.
21: SLURM auto-requeueing enabled. Setting signal handlers.
13: SLURM auto-requeueing enabled. Setting signal handlers.
 5: SLURM auto-requeueing enabled. Setting signal handlers.
22: SLURM auto-requeueing enabled. Setting signal handlers.
14: SLURM auto-requeueing enabled. Setting signal handlers.
 6: SLURM auto-requeueing enabled. Setting signal handlers.
23: SLURM auto-requeueing enabled. Setting signal handlers.
15: SLURM auto-requeueing enabled. Setting signal handlers.
 7: SLURM auto-requeueing enabled. Setting signal handlers.
 0: [AUX I 2025-10-08 04:45:36 data:291] Instantiating MegatronPretrainingSampler with total_samples: 38441516 and consumed_samples: 0
 0: [AUX I 2025-10-08 04:45:36 data:291] Instantiating MegatronPretrainingSampler with total_samples: 3202455 and consumed_samples: 0
24: GPTModel(
24:   (embedding): LanguageModelEmbedding(
24:     (word_embeddings): VocabParallelEmbedding()
24:     (embedding_dropout): Dropout(p=0.0, inplace=False)
24:   )
24:   (rotary_pos_emb): RotaryEmbedding()
24:   (decoder): TransformerBlock(
24:     (layers): ModuleList(
24:       (0-31): 32 x TransformerLayer(
24:         (input_layernorm): IdentityOp()
24:         (self_attention): SelfAttention(
24:           (core_attention): TEDotProductAttention(
24:             (flash_attention): FlashAttention()
24:             (fused_attention): FusedAttention()
24:             (unfused_attention): UnfusedDotProductAttention(
24:               (scale_mask_softmax): FusedScaleMaskSoftmax()
24:               (attention_dropout): Dropout(p=0.0, inplace=False)
24:             )
24:           )
24:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
24:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
24:           (q_layernorm): IdentityOp()
24:           (k_layernorm): IdentityOp()
24:         )
24:         (pre_cross_attn_layernorm): IdentityOp()
24:         (cross_attention): IdentityOp()
24:         (cross_attn_bda): IdentityFuncOp()
24:         (pre_mlp_layernorm): IdentityOp()
24:         (mlp): TEFusedMLP(
24:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
24:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
24:         )
24:       )
24:     )
24:     (final_layernorm): RMSNorm()
24:   )
24:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
24: )
26: GPTModel(
26:   (embedding): LanguageModelEmbedding(
26:     (word_embeddings): VocabParallelEmbedding()
26:     (embedding_dropout): Dropout(p=0.0, inplace=False)
26:   )
26:   (rotary_pos_emb): RotaryEmbedding()
26:   (decoder): TransformerBlock(
26:     (layers): ModuleList(
26:       (0-31): 32 x TransformerLayer(
26:         (input_layernorm): IdentityOp()
26:         (self_attention): SelfAttention(
26:           (core_attention): TEDotProductAttention(
26:             (flash_attention): FlashAttention()
26:             (fused_attention): FusedAttention()
26:             (unfused_attention): UnfusedDotProductAttention(
26:               (scale_mask_softmax): FusedScaleMaskSoftmax()
26:               (attention_dropout): Dropout(p=0.0, inplace=False)
26:             )
26:           )
26:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
26:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
26:           (q_layernorm): IdentityOp()
26:           (k_layernorm): IdentityOp()
26:         )
26:         (pre_cross_attn_layernorm): IdentityOp()
26:         (cross_attention): IdentityOp()
26:         (cross_attn_bda): IdentityFuncOp()
26:         (pre_mlp_layernorm): IdentityOp()
26:         (mlp): TEFusedMLP(
26:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
26:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
26:         )
26:       )
26:     )
26:     (final_layernorm): RMSNorm()
26:   )
26:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
26: )
27: GPTModel(
27:   (embedding): LanguageModelEmbedding(
27:     (word_embeddings): VocabParallelEmbedding()
27:     (embedding_dropout): Dropout(p=0.0, inplace=False)
27:   )
27:   (rotary_pos_emb): RotaryEmbedding()
27:   (decoder): TransformerBlock(
27:     (layers): ModuleList(
27:       (0-31): 32 x TransformerLayer(
27:         (input_layernorm): IdentityOp()
27:         (self_attention): SelfAttention(
27:           (core_attention): TEDotProductAttention(
27:             (flash_attention): FlashAttention()
27:             (fused_attention): FusedAttention()
27:             (unfused_attention): UnfusedDotProductAttention(
27:               (scale_mask_softmax): FusedScaleMaskSoftmax()
27:               (attention_dropout): Dropout(p=0.0, inplace=False)
27:             )
27:           )
27:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
27:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
27:           (q_layernorm): IdentityOp()
27:           (k_layernorm): IdentityOp()
27:         )
27:         (pre_cross_attn_layernorm): IdentityOp()
27:         (cross_attention): IdentityOp()
27:         (cross_attn_bda): IdentityFuncOp()
27:         (pre_mlp_layernorm): IdentityOp()
27:         (mlp): TEFusedMLP(
27:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
27:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
27:         )
27:       )
27:     )
27:     (final_layernorm): RMSNorm()
27:   )
27:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
27: )
28: GPTModel(
28:   (embedding): LanguageModelEmbedding(
28:     (word_embeddings): VocabParallelEmbedding()
28:     (embedding_dropout): Dropout(p=0.0, inplace=False)
28:   )
28:   (rotary_pos_emb): RotaryEmbedding()
28:   (decoder): TransformerBlock(
28:     (layers): ModuleList(
28:       (0-31): 32 x TransformerLayer(
28:         (input_layernorm): IdentityOp()
28:         (self_attention): SelfAttention(
28:           (core_attention): TEDotProductAttention(
28:             (flash_attention): FlashAttention()
28:             (fused_attention): FusedAttention()
28:             (unfused_attention): UnfusedDotProductAttention(
28:               (scale_mask_softmax): FusedScaleMaskSoftmax()
28:               (attention_dropout): Dropout(p=0.0, inplace=False)
28:             )
28:           )
28:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
28:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
28:           (q_layernorm): IdentityOp()
28:           (k_layernorm): IdentityOp()
28:         )
28:         (pre_cross_attn_layernorm): IdentityOp()
28:         (cross_attention): IdentityOp()
28:         (cross_attn_bda): IdentityFuncOp()
28:         (pre_mlp_layernorm): IdentityOp()
28:         (mlp): TEFusedMLP(
28:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
28:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
28:         )
28:       )
28:     )
28:     (final_layernorm): RMSNorm()
28:   )
28:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
28: )
29: GPTModel(
29:   (embedding): LanguageModelEmbedding(
29:     (word_embeddings): VocabParallelEmbedding()
29:     (embedding_dropout): Dropout(p=0.0, inplace=False)
29:   )
29:   (rotary_pos_emb): RotaryEmbedding()
29:   (decoder): TransformerBlock(
29:     (layers): ModuleList(
29:       (0-31): 32 x TransformerLayer(
29:         (input_layernorm): IdentityOp()
29:         (self_attention): SelfAttention(
29:           (core_attention): TEDotProductAttention(
29:             (flash_attention): FlashAttention()
29:             (fused_attention): FusedAttention()
29:             (unfused_attention): UnfusedDotProductAttention(
29:               (scale_mask_softmax): FusedScaleMaskSoftmax()
29:               (attention_dropout): Dropout(p=0.0, inplace=False)
29:             )
29:           )
29:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
29:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
29:           (q_layernorm): IdentityOp()
29:           (k_layernorm): IdentityOp()
29:         )
29:         (pre_cross_attn_layernorm): IdentityOp()
29:         (cross_attention): IdentityOp()
29:         (cross_attn_bda): IdentityFuncOp()
29:         (pre_mlp_layernorm): IdentityOp()
29:         (mlp): TEFusedMLP(
29:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
29:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
29:         )
29:       )
29:     )
29:     (final_layernorm): RMSNorm()
29:   )
29:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
29: )
30: GPTModel(
30:   (embedding): LanguageModelEmbedding(
30:     (word_embeddings): VocabParallelEmbedding()
30:     (embedding_dropout): Dropout(p=0.0, inplace=False)
30:   )
30:   (rotary_pos_emb): RotaryEmbedding()
30:   (decoder): TransformerBlock(
30:     (layers): ModuleList(
30:       (0-31): 32 x TransformerLayer(
30:         (input_layernorm): IdentityOp()
30:         (self_attention): SelfAttention(
30:           (core_attention): TEDotProductAttention(
30:             (flash_attention): FlashAttention()
30:             (fused_attention): FusedAttention()
30:             (unfused_attention): UnfusedDotProductAttention(
30:               (scale_mask_softmax): FusedScaleMaskSoftmax()
30:               (attention_dropout): Dropout(p=0.0, inplace=False)
30:             )
30:           )
30:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
30:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
30:           (q_layernorm): IdentityOp()
30:           (k_layernorm): IdentityOp()
30:         )
30:         (pre_cross_attn_layernorm): IdentityOp()
30:         (cross_attention): IdentityOp()
30:         (cross_attn_bda): IdentityFuncOp()
30:         (pre_mlp_layernorm): IdentityOp()
30:         (mlp): TEFusedMLP(
30:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
30:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
30:         )
30:       )
30:     )
30:     (final_layernorm): RMSNorm()
30:   )
30:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
30: )
31: GPTModel(
31:   (embedding): LanguageModelEmbedding(
31:     (word_embeddings): VocabParallelEmbedding()
31:     (embedding_dropout): Dropout(p=0.0, inplace=False)
31:   )
31:   (rotary_pos_emb): RotaryEmbedding()
31:   (decoder): TransformerBlock(
31:     (layers): ModuleList(
31:       (0-31): 32 x TransformerLayer(
31:         (input_layernorm): IdentityOp()
31:         (self_attention): SelfAttention(
31:           (core_attention): TEDotProductAttention(
31:             (flash_attention): FlashAttention()
31:             (fused_attention): FusedAttention()
31:             (unfused_attention): UnfusedDotProductAttention(
31:               (scale_mask_softmax): FusedScaleMaskSoftmax()
31:               (attention_dropout): Dropout(p=0.0, inplace=False)
31:             )
31:           )
31:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
31:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
31:           (q_layernorm): IdentityOp()
31:           (k_layernorm): IdentityOp()
31:         )
31:         (pre_cross_attn_layernorm): IdentityOp()
31:         (cross_attention): IdentityOp()
31:         (cross_attn_bda): IdentityFuncOp()
31:         (pre_mlp_layernorm): IdentityOp()
31:         (mlp): TEFusedMLP(
31:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
31:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
31:         )
31:       )
31:     )
31:     (final_layernorm): RMSNorm()
31:   )
31:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
31: )
25: GPTModel(
25:   (embedding): LanguageModelEmbedding(
25:     (word_embeddings): VocabParallelEmbedding()
25:     (embedding_dropout): Dropout(p=0.0, inplace=False)
25:   )
25:   (rotary_pos_emb): RotaryEmbedding()
25:   (decoder): TransformerBlock(
25:     (layers): ModuleList(
25:       (0-31): 32 x TransformerLayer(
25:         (input_layernorm): IdentityOp()
25:         (self_attention): SelfAttention(
25:           (core_attention): TEDotProductAttention(
25:             (flash_attention): FlashAttention()
25:             (fused_attention): FusedAttention()
25:             (unfused_attention): UnfusedDotProductAttention(
25:               (scale_mask_softmax): FusedScaleMaskSoftmax()
25:               (attention_dropout): Dropout(p=0.0, inplace=False)
25:             )
25:           )
25:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
25:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
25:           (q_layernorm): IdentityOp()
25:           (k_layernorm): IdentityOp()
25:         )
25:         (pre_cross_attn_layernorm): IdentityOp()
25:         (cross_attention): IdentityOp()
25:         (cross_attn_bda): IdentityFuncOp()
25:         (pre_mlp_layernorm): IdentityOp()
25:         (mlp): TEFusedMLP(
25:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
25:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
25:         )
25:       )
25:     )
25:     (final_layernorm): RMSNorm()
25:   )
25:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
25: )
 0: GPTModel(
 0:   (embedding): LanguageModelEmbedding(
 0:     (word_embeddings): VocabParallelEmbedding()
 0:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 0:   )
 0:   (rotary_pos_emb): RotaryEmbedding()
 0:   (decoder): TransformerBlock(
 0:     (layers): ModuleList(
 0:       (0-31): 32 x TransformerLayer(
 0:         (input_layernorm): IdentityOp()
 0:         (self_attention): SelfAttention(
 0:           (core_attention): TEDotProductAttention(
 0:             (flash_attention): FlashAttention()
 0:             (fused_attention): FusedAttention()
 0:             (unfused_attention): UnfusedDotProductAttention(
 0:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 0:               (attention_dropout): Dropout(p=0.0, inplace=False)
 0:             )
 0:           )
 0:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 0:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 0:           (q_layernorm): IdentityOp()
 0:           (k_layernorm): IdentityOp()
 0:         )
 0:         (pre_cross_attn_layernorm): IdentityOp()
 0:         (cross_attention): IdentityOp()
 0:         (cross_attn_bda): IdentityFuncOp()
 0:         (pre_mlp_layernorm): IdentityOp()
 0:         (mlp): TEFusedMLP(
 0:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 0:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 0:         )
 0:       )
 0:     )
 0:     (final_layernorm): RMSNorm()
 0:   )
 0:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 0: )
 3: GPTModel(
 3:   (embedding): LanguageModelEmbedding(
 3:     (word_embeddings): VocabParallelEmbedding()
 3:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 3:   )
 3:   (rotary_pos_emb): RotaryEmbedding()
 3:   (decoder): TransformerBlock(
 3:     (layers): ModuleList(
 3:       (0-31): 32 x TransformerLayer(
 3:         (input_layernorm): IdentityOp()
 3:         (self_attention): SelfAttention(
 3:           (core_attention): TEDotProductAttention(
 3:             (flash_attention): FlashAttention()
 3:             (fused_attention): FusedAttention()
 3:             (unfused_attention): UnfusedDotProductAttention(
 3:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 3:               (attention_dropout): Dropout(p=0.0, inplace=False)
 3:             )
 3:           )
 3:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 3:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 3:           (q_layernorm): IdentityOp()
 3:           (k_layernorm): IdentityOp()
12: GPTModel(
12:   (embedding): LanguageModelEmbedding(
12:     (word_embeddings): VocabParallelEmbedding()
12:     (embedding_dropout): Dropout(p=0.0, inplace=False)
12:   )
12:   (rotary_pos_emb): RotaryEmbedding()
12:   (decoder): TransformerBlock(
12:     (layers): ModuleList(
12:       (0-31): 32 x TransformerLayer(
12:         (input_layernorm): IdentityOp()
12:         (self_attention): SelfAttention(
12:           (core_attention): TEDotProductAttention(
12:             (flash_attention): FlashAttention()
12:             (fused_attention): FusedAttention()
12:             (unfused_attention): UnfusedDotProductAttention(
12:               (scale_mask_softmax): FusedScaleMaskSoftmax()
12:               (attention_dropout): Dropout(p=0.0, inplace=False)
12:             )
12:           )
12:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
12:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
12:           (q_layernorm): IdentityOp()
12:           (k_layernorm): IdentityOp()
12:         )
12:         (pre_cross_attn_layernorm): IdentityOp()
12:         (cross_attention): IdentityOp()
12:         (cross_attn_bda): IdentityFuncOp()
12:         (pre_mlp_layernorm): IdentityOp()
12:         (mlp): TEFusedMLP(
12:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
12:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
12:         )
12:       )
12:     )
12:     (final_layernorm): RMSNorm()
12:   )
12:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
12: )
13: GPTModel(
13:   (embedding): LanguageModelEmbedding(
13:     (word_embeddings): VocabParallelEmbedding()
13:     (embedding_dropout): Dropout(p=0.0, inplace=False)
13:   )
13:   (rotary_pos_emb): RotaryEmbedding()
13:   (decoder): TransformerBlock(
13:     (layers): ModuleList(
13:       (0-31): 32 x TransformerLayer(
13:         (input_layernorm): IdentityOp()
13:         (self_attention): SelfAttention(
13:           (core_attention): TEDotProductAttention(
13:             (flash_attention): FlashAttention()
13:             (fused_attention): FusedAttention()
13:             (unfused_attention): UnfusedDotProductAttention(
13:               (scale_mask_softmax): FusedScaleMaskSoftmax()
13:               (attention_dropout): Dropout(p=0.0, inplace=False)
13:             )
13:           )
13:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
13:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
13:           (q_layernorm): IdentityOp()
13:           (k_layernorm): IdentityOp()
13:         )
13:         (pre_cross_attn_layernorm): IdentityOp()
13:         (cross_attention): IdentityOp()
13:         (cross_attn_bda): IdentityFuncOp()
13:         (pre_mlp_layernorm): IdentityOp()
13:         (mlp): TEFusedMLP(
13:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
13:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
13:         )
13:       )
13:     )
13:     (final_layernorm): RMSNorm()
13:   )
13:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
13: )
14: GPTModel(
14:   (embedding): LanguageModelEmbedding(
14:     (word_embeddings): VocabParallelEmbedding()
14:     (embedding_dropout): Dropout(p=0.0, inplace=False)
14:   )
14:   (rotary_pos_emb): RotaryEmbedding()
14:   (decoder): TransformerBlock(
14:     (layers): ModuleList(
14:       (0-31): 32 x TransformerLayer(
14:         (input_layernorm): IdentityOp()
14:         (self_attention): SelfAttention(
14:           (core_attention): TEDotProductAttention(
14:             (flash_attention): FlashAttention()
14:             (fused_attention): FusedAttention()
14:             (unfused_attention): UnfusedDotProductAttention(
14:               (scale_mask_softmax): FusedScaleMaskSoftmax()
14:               (attention_dropout): Dropout(p=0.0, inplace=False)
14:             )
14:           )
14:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
14:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
14:           (q_layernorm): IdentityOp()
14:           (k_layernorm): IdentityOp()
14:         )
14:         (pre_cross_attn_layernorm): IdentityOp()
14:         (cross_attention): IdentityOp()
14:         (cross_attn_bda): IdentityFuncOp()
14:         (pre_mlp_layernorm): IdentityOp()
14:         (mlp): TEFusedMLP(
14:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
14:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
14:         )
14:       )
14:     )
14:     (final_layernorm): RMSNorm()
14:   )
14:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
14: )
15: GPTModel(
15:   (embedding): LanguageModelEmbedding(
15:     (word_embeddings): VocabParallelEmbedding()
15:     (embedding_dropout): Dropout(p=0.0, inplace=False)
15:   )
15:   (rotary_pos_emb): RotaryEmbedding()
15:   (decoder): TransformerBlock(
15:     (layers): ModuleList(
15:       (0-31): 32 x TransformerLayer(
15:         (input_layernorm): IdentityOp()
15:         (self_attention): SelfAttention(
15:           (core_attention): TEDotProductAttention(
15:             (flash_attention): FlashAttention()
15:             (fused_attention): FusedAttention()
15:             (unfused_attention): UnfusedDotProductAttention(
15:               (scale_mask_softmax): FusedScaleMaskSoftmax()
15:               (attention_dropout): Dropout(p=0.0, inplace=False)
15:             )
15:           )
15:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
15:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
15:           (q_layernorm): IdentityOp()
15:           (k_layernorm): IdentityOp()
15:         )
15:         (pre_cross_attn_layernorm): IdentityOp()
15:         (cross_attention): IdentityOp()
15:         (cross_attn_bda): IdentityFuncOp()
15:         (pre_mlp_layernorm): IdentityOp()
15:         (mlp): TEFusedMLP(
15:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
15:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
15:         )
15:       )
15:     )
15:     (final_layernorm): RMSNorm()
15:   )
15:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
15: )
18: GPTModel(
18:   (embedding): LanguageModelEmbedding(
18:     (word_embeddings): VocabParallelEmbedding()
18:     (embedding_dropout): Dropout(p=0.0, inplace=False)
18:   )
18:   (rotary_pos_emb): RotaryEmbedding()
18:   (decoder): TransformerBlock(
18:     (layers): ModuleList(
18:       (0-31): 32 x TransformerLayer(
18:         (input_layernorm): IdentityOp()
18:         (self_attention): SelfAttention(
18:           (core_attention): TEDotProductAttention(
18:             (flash_attention): FlashAttention()
18:             (fused_attention): FusedAttention()
18:             (unfused_attention): UnfusedDotProductAttention(
18:               (scale_mask_softmax): FusedScaleMaskSoftmax()
18:               (attention_dropout): Dropout(p=0.0, inplace=False)
18:             )
18:           )
18:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
18:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
18:           (q_layernorm): IdentityOp()
18:           (k_layernorm): IdentityOp()
 9: GPTModel(
 9:   (embedding): LanguageModelEmbedding(
 9:     (word_embeddings): VocabParallelEmbedding()
 9:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 9:   )
 9:   (rotary_pos_emb): RotaryEmbedding()
 9:   (decoder): TransformerBlock(
 9:     (layers): ModuleList(
 9:       (0-31): 32 x TransformerLayer(
 9:         (input_layernorm): IdentityOp()
 9:         (self_attention): SelfAttention(
 9:           (core_attention): TEDotProductAttention(
 9:             (flash_attention): FlashAttention()
 9:             (fused_attention): FusedAttention()
 9:             (unfused_attention): UnfusedDotProductAttention(
 9:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 9:               (attention_dropout): Dropout(p=0.0, inplace=False)
 9:             )
 9:           )
 9:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 9:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 9:           (q_layernorm): IdentityOp()
 9:           (k_layernorm): IdentityOp()
 3:         )
 3:         (pre_cross_attn_layernorm): IdentityOp()
 3:         (cross_attention): IdentityOp()
 3:         (cross_attn_bda): IdentityFuncOp()
 3:         (pre_mlp_layernorm): IdentityOp()
 3:         (mlp): TEFusedMLP(
 3:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 3:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 3:         )
 3:       )
 3:     )
 3:     (final_layernorm): RMSNorm()
 3:   )
 3:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
18:         )
18:         (pre_cross_attn_layernorm): IdentityOp()
18:         (cross_attention): IdentityOp()
18:         (cross_attn_bda): IdentityFuncOp()
18:         (pre_mlp_layernorm): IdentityOp()
18:         (mlp): TEFusedMLP(
18:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
18:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
18:         )
18:       )
18:     )
18:     (final_layernorm): RMSNorm()
18:   )
18:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
18: )
 9:         )
 9:         (pre_cross_attn_layernorm): IdentityOp()
 9:         (cross_attention): IdentityOp()
 9:         (cross_attn_bda): IdentityFuncOp()
 9:         (pre_mlp_layernorm): IdentityOp()
 9:         (mlp): TEFusedMLP(
 9:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 9:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 9:         )
 9:       )
 9:     )
 9:     (final_layernorm): RMSNorm()
 9:   )
 9:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 3: )
16: GPTModel(
16:   (embedding): LanguageModelEmbedding(
16:     (word_embeddings): VocabParallelEmbedding()
16:     (embedding_dropout): Dropout(p=0.0, inplace=False)
16:   )
16:   (rotary_pos_emb): RotaryEmbedding()
16:   (decoder): TransformerBlock(
16:     (layers): ModuleList(
16:       (0-31): 32 x TransformerLayer(
16:         (input_layernorm): IdentityOp()
16:         (self_attention): SelfAttention(
16:           (core_attention): TEDotProductAttention(
16:             (flash_attention): FlashAttention()
16:             (fused_attention): FusedAttention()
16:             (unfused_attention): UnfusedDotProductAttention(
16:               (scale_mask_softmax): FusedScaleMaskSoftmax()
16:               (attention_dropout): Dropout(p=0.0, inplace=False)
16:             )
16:           )
16:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
16:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
16:           (q_layernorm): IdentityOp()
16:           (k_layernorm): IdentityOp()
10: GPTModel(
10:   (embedding): LanguageModelEmbedding(
10:     (word_embeddings): VocabParallelEmbedding()
10:     (embedding_dropout): Dropout(p=0.0, inplace=False)
10:   )
10:   (rotary_pos_emb): RotaryEmbedding()
10:   (decoder): TransformerBlock(
10:     (layers): ModuleList(
10:       (0-31): 32 x TransformerLayer(
10:         (input_layernorm): IdentityOp()
10:         (self_attention): SelfAttention(
10:           (core_attention): TEDotProductAttention(
10:             (flash_attention): FlashAttention()
10:             (fused_attention): FusedAttention()
10:             (unfused_attention): UnfusedDotProductAttention(
10:               (scale_mask_softmax): FusedScaleMaskSoftmax()
10:               (attention_dropout): Dropout(p=0.0, inplace=False)
10:             )
10:           )
10:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
10:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
10:           (q_layernorm): IdentityOp()
10:           (k_layernorm): IdentityOp()
 0: 
 0: MCore config:
16:         )
16:         (pre_cross_attn_layernorm): IdentityOp()
16:         (cross_attention): IdentityOp()
16:         (cross_attn_bda): IdentityFuncOp()
16:         (pre_mlp_layernorm): IdentityOp()
16:         (mlp): TEFusedMLP(
16:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
16:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
16:         )
16:       )
16:     )
16:     (final_layernorm): RMSNorm()
16:   )
16:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
16: )
10:         )
10:         (pre_cross_attn_layernorm): IdentityOp()
10:         (cross_attention): IdentityOp()
10:         (cross_attn_bda): IdentityFuncOp()
10:         (pre_mlp_layernorm): IdentityOp()
10:         (mlp): TEFusedMLP(
10:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
10:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
10:         )
10:       )
10:     )
10:     (final_layernorm): RMSNorm()
10:   )
10:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
10: )
 1: GPTModel(
 1:   (embedding): LanguageModelEmbedding(
 1:     (word_embeddings): VocabParallelEmbedding()
 1:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 1:   )
 1:   (rotary_pos_emb): RotaryEmbedding()
 1:   (decoder): TransformerBlock(
 1:     (layers): ModuleList(
 1:       (0-31): 32 x TransformerLayer(
 1:         (input_layernorm): IdentityOp()
 1:         (self_attention): SelfAttention(
 1:           (core_attention): TEDotProductAttention(
 1:             (flash_attention): FlashAttention()
 1:             (fused_attention): FusedAttention()
 1:             (unfused_attention): UnfusedDotProductAttention(
 1:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 1:               (attention_dropout): Dropout(p=0.0, inplace=False)
 1:             )
 1:           )
 1:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 1:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 1:           (q_layernorm): IdentityOp()
 1:           (k_layernorm): IdentityOp()
19: GPTModel(
19:   (embedding): LanguageModelEmbedding(
19:     (word_embeddings): VocabParallelEmbedding()
19:     (embedding_dropout): Dropout(p=0.0, inplace=False)
19:   )
19:   (rotary_pos_emb): RotaryEmbedding()
19:   (decoder): TransformerBlock(
19:     (layers): ModuleList(
19:       (0-31): 32 x TransformerLayer(
19:         (input_layernorm): IdentityOp()
19:         (self_attention): SelfAttention(
19:           (core_attention): TEDotProductAttention(
19:             (flash_attention): FlashAttention()
19:             (fused_attention): FusedAttention()
19:             (unfused_attention): UnfusedDotProductAttention(
19:               (scale_mask_softmax): FusedScaleMaskSoftmax()
19:               (attention_dropout): Dropout(p=0.0, inplace=False)
19:             )
19:           )
19:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
19:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
19:           (q_layernorm): IdentityOp()
19:           (k_layernorm): IdentityOp()
11: GPTModel(
11:   (embedding): LanguageModelEmbedding(
11:     (word_embeddings): VocabParallelEmbedding()
11:     (embedding_dropout): Dropout(p=0.0, inplace=False)
11:   )
11:   (rotary_pos_emb): RotaryEmbedding()
11:   (decoder): TransformerBlock(
11:     (layers): ModuleList(
11:       (0-31): 32 x TransformerLayer(
11:         (input_layernorm): IdentityOp()
11:         (self_attention): SelfAttention(
11:           (core_attention): TEDotProductAttention(
11:             (flash_attention): FlashAttention()
11:             (fused_attention): FusedAttention()
11:             (unfused_attention): UnfusedDotProductAttention(
11:               (scale_mask_softmax): FusedScaleMaskSoftmax()
11:               (attention_dropout): Dropout(p=0.0, inplace=False)
11:             )
11:           )
11:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
11:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
11:           (q_layernorm): IdentityOp()
11:           (k_layernorm): IdentityOp()
 1:         )
 1:         (pre_cross_attn_layernorm): IdentityOp()
 1:         (cross_attention): IdentityOp()
 1:         (cross_attn_bda): IdentityFuncOp()
 1:         (pre_mlp_layernorm): IdentityOp()
 1:         (mlp): TEFusedMLP(
 1:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 1:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 1:         )
 1:       )
 1:     )
 1:     (final_layernorm): RMSNorm()
 1:   )
 1:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
19:         )
19:         (pre_cross_attn_layernorm): IdentityOp()
19:         (cross_attention): IdentityOp()
19:         (cross_attn_bda): IdentityFuncOp()
19:         (pre_mlp_layernorm): IdentityOp()
19:         (mlp): TEFusedMLP(
19:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
19:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
19:         )
19:       )
19:     )
19:     (final_layernorm): RMSNorm()
19:   )
19:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
19: )
11:         )
11:         (pre_cross_attn_layernorm): IdentityOp()
11:         (cross_attention): IdentityOp()
11:         (cross_attn_bda): IdentityFuncOp()
11:         (pre_mlp_layernorm): IdentityOp()
11:         (mlp): TEFusedMLP(
11:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
11:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
11:         )
11:       )
11:     )
11:     (final_layernorm): RMSNorm()
11:   )
11:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
11: )
 1: )
21: GPTModel(
21:   (embedding): LanguageModelEmbedding(
21:     (word_embeddings): VocabParallelEmbedding()
21:     (embedding_dropout): Dropout(p=0.0, inplace=False)
21:   )
21:   (rotary_pos_emb): RotaryEmbedding()
21:   (decoder): TransformerBlock(
21:     (layers): ModuleList(
21:       (0-31): 32 x TransformerLayer(
21:         (input_layernorm): IdentityOp()
21:         (self_attention): SelfAttention(
21:           (core_attention): TEDotProductAttention(
21:             (flash_attention): FlashAttention()
21:             (fused_attention): FusedAttention()
21:             (unfused_attention): UnfusedDotProductAttention(
21:               (scale_mask_softmax): FusedScaleMaskSoftmax()
21:               (attention_dropout): Dropout(p=0.0, inplace=False)
21:             )
21:           )
21:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
21:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
21:           (q_layernorm): IdentityOp()
21:           (k_layernorm): IdentityOp()
21:         )
21:         (pre_cross_attn_layernorm): IdentityOp()
21:         (cross_attention): IdentityOp()
21:         (cross_attn_bda): IdentityFuncOp()
21:         (pre_mlp_layernorm): IdentityOp()
21:         (mlp): TEFusedMLP(
21:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
21:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
21:         )
21:       )
21:     )
21:     (final_layernorm): RMSNorm()
21:   )
21:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
21: )
23: GPTModel(
23:   (embedding): LanguageModelEmbedding(
23:     (word_embeddings): VocabParallelEmbedding()
23:     (embedding_dropout): Dropout(p=0.0, inplace=False)
23:   )
23:   (rotary_pos_emb): RotaryEmbedding()
23:   (decoder): TransformerBlock(
23:     (layers): ModuleList(
23:       (0-31): 32 x TransformerLayer(
23:         (input_layernorm): IdentityOp()
23:         (self_attention): SelfAttention(
23:           (core_attention): TEDotProductAttention(
23:             (flash_attention): FlashAttention()
23:             (fused_attention): FusedAttention()
23:             (unfused_attention): UnfusedDotProductAttention(
23:               (scale_mask_softmax): FusedScaleMaskSoftmax()
23:               (attention_dropout): Dropout(p=0.0, inplace=False)
23:             )
23:           )
23:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
23:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
23:           (q_layernorm): IdentityOp()
23:           (k_layernorm): IdentityOp()
23:         )
23:         (pre_cross_attn_layernorm): IdentityOp()
23:         (cross_attention): IdentityOp()
23:         (cross_attn_bda): IdentityFuncOp()
23:         (pre_mlp_layernorm): IdentityOp()
23:         (mlp): TEFusedMLP(
23:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
23:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
23:         )
23:       )
23:     )
23:     (final_layernorm): RMSNorm()
23:   )
23:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
23: )
 2: GPTModel(
 2:   (embedding): LanguageModelEmbedding(
 2:     (word_embeddings): VocabParallelEmbedding()
 2:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 2:   )
 2:   (rotary_pos_emb): RotaryEmbedding()
 2:   (decoder): TransformerBlock(
 2:     (layers): ModuleList(
 2:       (0-31): 32 x TransformerLayer(
 2:         (input_layernorm): IdentityOp()
 2:         (self_attention): SelfAttention(
 2:           (core_attention): TEDotProductAttention(
 2:             (flash_attention): FlashAttention()
 2:             (fused_attention): FusedAttention()
 2:             (unfused_attention): UnfusedDotProductAttention(
 2:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 2:               (attention_dropout): Dropout(p=0.0, inplace=False)
 2:             )
 2:           )
 2:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 2:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 2:           (q_layernorm): IdentityOp()
 2:           (k_layernorm): IdentityOp()
 2:         )
 2:         (pre_cross_attn_layernorm): IdentityOp()
 2:         (cross_attention): IdentityOp()
 2:         (cross_attn_bda): IdentityFuncOp()
 2:         (pre_mlp_layernorm): IdentityOp()
 2:         (mlp): TEFusedMLP(
 2:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 2:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 2:         )
 2:       )
 2:     )
 2:     (final_layernorm): RMSNorm()
 2:   )
 2:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 2: )
 4: GPTModel(
 4:   (embedding): LanguageModelEmbedding(
 4:     (word_embeddings): VocabParallelEmbedding()
 4:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 4:   )
 4:   (rotary_pos_emb): RotaryEmbedding()
 4:   (decoder): TransformerBlock(
 4:     (layers): ModuleList(
 4:       (0-31): 32 x TransformerLayer(
 4:         (input_layernorm): IdentityOp()
 4:         (self_attention): SelfAttention(
 4:           (core_attention): TEDotProductAttention(
 4:             (flash_attention): FlashAttention()
 4:             (fused_attention): FusedAttention()
 4:             (unfused_attention): UnfusedDotProductAttention(
 4:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 4:               (attention_dropout): Dropout(p=0.0, inplace=False)
 4:             )
 4:           )
 4:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 4:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 4:           (q_layernorm): IdentityOp()
 4:           (k_layernorm): IdentityOp()
 8: GPTModel(
 8:   (embedding): LanguageModelEmbedding(
 8:     (word_embeddings): VocabParallelEmbedding()
 8:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 8:   )
 8:   (rotary_pos_emb): RotaryEmbedding()
 8:   (decoder): TransformerBlock(
 8:     (layers): ModuleList(
 8:       (0-31): 32 x TransformerLayer(
 8:         (input_layernorm): IdentityOp()
 8:         (self_attention): SelfAttention(
 8:           (core_attention): TEDotProductAttention(
 8:             (flash_attention): FlashAttention()
 8:             (fused_attention): FusedAttention()
 8:             (unfused_attention): UnfusedDotProductAttention(
 8:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 8:               (attention_dropout): Dropout(p=0.0, inplace=False)
 8:             )
 8:           )
 8:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 8:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 8:           (q_layernorm): IdentityOp()
 8:           (k_layernorm): IdentityOp()
 4:         )
 4:         (pre_cross_attn_layernorm): IdentityOp()
 4:         (cross_attention): IdentityOp()
 4:         (cross_attn_bda): IdentityFuncOp()
 4:         (pre_mlp_layernorm): IdentityOp()
 4:         (mlp): TEFusedMLP(
 4:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 4:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 4:         )
 4:       )
 4:     )
 4:     (final_layernorm): RMSNorm()
 4:   )
 4:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 4: )
20: GPTModel(
20:   (embedding): LanguageModelEmbedding(
20:     (word_embeddings): VocabParallelEmbedding()
20:     (embedding_dropout): Dropout(p=0.0, inplace=False)
20:   )
20:   (rotary_pos_emb): RotaryEmbedding()
20:   (decoder): TransformerBlock(
20:     (layers): ModuleList(
20:       (0-31): 32 x TransformerLayer(
20:         (input_layernorm): IdentityOp()
20:         (self_attention): SelfAttention(
20:           (core_attention): TEDotProductAttention(
20:             (flash_attention): FlashAttention()
20:             (fused_attention): FusedAttention()
20:             (unfused_attention): UnfusedDotProductAttention(
20:               (scale_mask_softmax): FusedScaleMaskSoftmax()
20:               (attention_dropout): Dropout(p=0.0, inplace=False)
20:             )
20:           )
20:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
20:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
20:           (q_layernorm): IdentityOp()
20:           (k_layernorm): IdentityOp()
 8:         )
 8:         (pre_cross_attn_layernorm): IdentityOp()
 8:         (cross_attention): IdentityOp()
 8:         (cross_attn_bda): IdentityFuncOp()
 8:         (pre_mlp_layernorm): IdentityOp()
 8:         (mlp): TEFusedMLP(
 8:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 8:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 8:         )
 8:       )
 8:     )
 8:     (final_layernorm): RMSNorm()
 8:   )
 8:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 8: )
 5: GPTModel(
 5:   (embedding): LanguageModelEmbedding(
 5:     (word_embeddings): VocabParallelEmbedding()
 5:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 5:   )
 5:   (rotary_pos_emb): RotaryEmbedding()
 5:   (decoder): TransformerBlock(
 5:     (layers): ModuleList(
 5:       (0-31): 32 x TransformerLayer(
 5:         (input_layernorm): IdentityOp()
 5:         (self_attention): SelfAttention(
 5:           (core_attention): TEDotProductAttention(
 5:             (flash_attention): FlashAttention()
 5:             (fused_attention): FusedAttention()
 5:             (unfused_attention): UnfusedDotProductAttention(
 5:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 5:               (attention_dropout): Dropout(p=0.0, inplace=False)
 5:             )
 5:           )
 5:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 5:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 5:           (q_layernorm): IdentityOp()
 5:           (k_layernorm): IdentityOp()
20:         )
20:         (pre_cross_attn_layernorm): IdentityOp()
20:         (cross_attention): IdentityOp()
20:         (cross_attn_bda): IdentityFuncOp()
20:         (pre_mlp_layernorm): IdentityOp()
20:         (mlp): TEFusedMLP(
20:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
20:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
20:         )
20:       )
20:     )
20:     (final_layernorm): RMSNorm()
20:   )
20:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 9: )
 5:         )
 5:         (pre_cross_attn_layernorm): IdentityOp()
 5:         (cross_attention): IdentityOp()
 5:         (cross_attn_bda): IdentityFuncOp()
 5:         (pre_mlp_layernorm): IdentityOp()
 5:         (mlp): TEFusedMLP(
 5:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 5:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 5:         )
 5:       )
 5:     )
 5:     (final_layernorm): RMSNorm()
 5:   )
 5:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 5: )
20: )
 6: GPTModel(
 6:   (embedding): LanguageModelEmbedding(
 6:     (word_embeddings): VocabParallelEmbedding()
 6:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 6:   )
 6:   (rotary_pos_emb): RotaryEmbedding()
 6:   (decoder): TransformerBlock(
 6:     (layers): ModuleList(
 6:       (0-31): 32 x TransformerLayer(
 6:         (input_layernorm): IdentityOp()
 6:         (self_attention): SelfAttention(
 6:           (core_attention): TEDotProductAttention(
 6:             (flash_attention): FlashAttention()
 6:             (fused_attention): FusedAttention()
 6:             (unfused_attention): UnfusedDotProductAttention(
 6:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 6:               (attention_dropout): Dropout(p=0.0, inplace=False)
 6:             )
 6:           )
 6:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 6:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 6:           (q_layernorm): IdentityOp()
 6:           (k_layernorm): IdentityOp()
22: GPTModel(
22:   (embedding): LanguageModelEmbedding(
22:     (word_embeddings): VocabParallelEmbedding()
22:     (embedding_dropout): Dropout(p=0.0, inplace=False)
22:   )
22:   (rotary_pos_emb): RotaryEmbedding()
22:   (decoder): TransformerBlock(
22:     (layers): ModuleList(
22:       (0-31): 32 x TransformerLayer(
22:         (input_layernorm): IdentityOp()
22:         (self_attention): SelfAttention(
22:           (core_attention): TEDotProductAttention(
22:             (flash_attention): FlashAttention()
22:             (fused_attention): FusedAttention()
22:             (unfused_attention): UnfusedDotProductAttention(
22:               (scale_mask_softmax): FusedScaleMaskSoftmax()
22:               (attention_dropout): Dropout(p=0.0, inplace=False)
22:             )
22:           )
22:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
22:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
22:           (q_layernorm): IdentityOp()
22:           (k_layernorm): IdentityOp()
 6:         )
 6:         (pre_cross_attn_layernorm): IdentityOp()
 6:         (cross_attention): IdentityOp()
 6:         (cross_attn_bda): IdentityFuncOp()
 6:         (pre_mlp_layernorm): IdentityOp()
 6:         (mlp): TEFusedMLP(
 6:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 6:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 6:         )
 6:       )
 6:     )
 6:     (final_layernorm): RMSNorm()
 6:   )
 6:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 6: )
22:         )
22:         (pre_cross_attn_layernorm): IdentityOp()
22:         (cross_attention): IdentityOp()
22:         (cross_attn_bda): IdentityFuncOp()
22:         (pre_mlp_layernorm): IdentityOp()
22:         (mlp): TEFusedMLP(
22:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
22:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
22:         )
22:       )
22:     )
22:     (final_layernorm): RMSNorm()
22:   )
22:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 7: GPTModel(
 7:   (embedding): LanguageModelEmbedding(
 7:     (word_embeddings): VocabParallelEmbedding()
 7:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 7:   )
 7:   (rotary_pos_emb): RotaryEmbedding()
 7:   (decoder): TransformerBlock(
 7:     (layers): ModuleList(
 7:       (0-31): 32 x TransformerLayer(
 7:         (input_layernorm): IdentityOp()
 7:         (self_attention): SelfAttention(
 7:           (core_attention): TEDotProductAttention(
 7:             (flash_attention): FlashAttention()
 7:             (fused_attention): FusedAttention()
 7:             (unfused_attention): UnfusedDotProductAttention(
 7:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 7:               (attention_dropout): Dropout(p=0.0, inplace=False)
 7:             )
 7:           )
 7:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 7:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 7:           (q_layernorm): IdentityOp()
 7:           (k_layernorm): IdentityOp()
17: GPTModel(
17:   (embedding): LanguageModelEmbedding(
17:     (word_embeddings): VocabParallelEmbedding()
17:     (embedding_dropout): Dropout(p=0.0, inplace=False)
17:   )
17:   (rotary_pos_emb): RotaryEmbedding()
17:   (decoder): TransformerBlock(
17:     (layers): ModuleList(
17:       (0-31): 32 x TransformerLayer(
17:         (input_layernorm): IdentityOp()
17:         (self_attention): SelfAttention(
17:           (core_attention): TEDotProductAttention(
17:             (flash_attention): FlashAttention()
17:             (fused_attention): FusedAttention()
17:             (unfused_attention): UnfusedDotProductAttention(
17:               (scale_mask_softmax): FusedScaleMaskSoftmax()
17:               (attention_dropout): Dropout(p=0.0, inplace=False)
17:             )
17:           )
17:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
17:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
17:           (q_layernorm): IdentityOp()
17:           (k_layernorm): IdentityOp()
 7:         )
 7:         (pre_cross_attn_layernorm): IdentityOp()
 7:         (cross_attention): IdentityOp()
 7:         (cross_attn_bda): IdentityFuncOp()
 7:         (pre_mlp_layernorm): IdentityOp()
 7:         (mlp): TEFusedMLP(
 7:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 7:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 7:         )
 7:       )
 7:     )
 7:     (final_layernorm): RMSNorm()
 7:   )
 7:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 7: )
17:         )
17:         (pre_cross_attn_layernorm): IdentityOp()
17:         (cross_attention): IdentityOp()
17:         (cross_attn_bda): IdentityFuncOp()
17:         (pre_mlp_layernorm): IdentityOp()
17:         (mlp): TEFusedMLP(
17:           (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
17:           (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
17:         )
17:       )
17:     )
17:     (final_layernorm): RMSNorm()
17:   )
17:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
17: )
22: )
 0: Llama31Config8B(tensor_model_parallel_size=1,
 0:                 pipeline_model_parallel_comm_backend=None,
 0:                 pipeline_model_parallel_size=1,
 0:                 virtual_pipeline_model_parallel_size=None,
 0:                 sequence_parallel=False,
 0:                 context_parallel_size=1,
 0:                 hierarchical_context_parallel_sizes=None,
 0:                 expert_model_parallel_size=1,
 0:                 expert_tensor_parallel_size=1,
 0:                 moe_extended_tp=False,
 0:                 perform_initialization=True,
 0:                 use_cpu_initialization=False,
 0:                 fp16=False,
 0:                 bf16=True,
 0:                 params_dtype=torch.bfloat16,
 0:                 timers=<megatron.core.timers.Timers object at 0xda73c8c0950>,
 0:                 finalize_model_grads_func=<function MegatronOptimizerModule.on_fit_start.<locals>.finalize_model_grads_func at 0xda6f8117c40>,
 0:                 grad_scale_func=None,
 0:                 no_sync_func=<bound method DistributedDataParallel.no_sync of DDP(
 0:   (module): Float16Module(
 0:     (module): GPTModel(
 0:       (embedding): LanguageModelEmbedding(
 0:         (word_embeddings): VocabParallelEmbedding()
 0:         (embedding_dropout): Dropout(p=0.0, inplace=False)
 0:       )
 0:       (rotary_pos_emb): RotaryEmbedding()
 0:       (decoder): TransformerBlock(
 0:         (layers): ModuleList(
 0:           (0-31): 32 x TransformerLayer(
 0:             (input_layernorm): IdentityOp()
 0:             (self_attention): SelfAttention(
 0:               (core_attention): TEDotProductAttention(
 0:                 (flash_attention): FlashAttention()
 0:                 (fused_attention): FusedAttention()
 0:                 (unfused_attention): UnfusedDotProductAttention(
 0:                   (scale_mask_softmax): FusedScaleMaskSoftmax()
 0:                   (attention_dropout): Dropout(p=0.0, inplace=False)
 0:                 )
 0:               )
 0:               (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 0:               (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 0:               (q_layernorm): IdentityOp()
 0:               (k_layernorm): IdentityOp()
 0:             )
 0:             (pre_cross_attn_layernorm): IdentityOp()
 0:             (cross_attention): IdentityOp()
 0:             (cross_attn_bda): IdentityFuncOp()
 0:             (pre_mlp_layernorm): IdentityOp()
 0:             (mlp): TEFusedMLP(
 0:               (linear_fc1): TELayerNormColumnParallelLinear(in_features=4096, out_features=28672, bias=False, TP=1)
 0:               (linear_fc2): TERowParallelLinear(in_features=14336, out_features=4096, bias=False, TP=1)
 0:             )
 0:           )
 0:         )
 0:         (final_layernorm): RMSNorm()
 0:       )
 0:       (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 0:     )
 0:   )
 0: )>,
 0:                 grad_sync_func=None,
 0:                 param_sync_func=None,
 0:                 deterministic_mode=False,
 0:                 enable_autocast=False,
 0:                 autocast_dtype=torch.bfloat16,
 0:                 num_microbatches_with_partial_activation_checkpoints=None,
 0:                 gradient_accumulation_fusion=True,
 0:                 async_tensor_model_parallel_allreduce=False,
 0:                 use_te_rng_tracker=(True,),
 0:                 tp_comm_overlap=False,
 0:                 tp_comm_bulk_wgrad=True,
 0:                 tp_comm_bulk_dgrad=True,
 0:                 tp_comm_overlap_ag=True,
 0:                 tp_comm_overlap_rs=True,
 0:                 tp_comm_overlap_rs_dgrad=False,
 0:                 tp_comm_split_ag=True,
 0:                 tp_comm_atomic_ag=False,
 0:                 tp_comm_split_rs=True,
 0:                 tp_comm_atomic_rs=False,
 0:                 cross_entropy_loss_fusion=True,
 0:                 cross_entropy_fusion_impl='te',
 0:                 tp_comm_overlap_disable_qkv=False,
 0:                 tp_comm_overlap_disable_fc1=False,
 0:                 tp_comm_bootstrap_backend=None,
 0:                 overlap_moe_expert_parallel_comm=False,
 0:                 delay_wgrad_compute=False,
 0:                 pipeline_dtype=torch.bfloat16,
 0:                 variable_seq_lengths=False,
 0:                 overlap_p2p_comm=True,
 0:                 batch_p2p_comm=False,
 0:                 batch_p2p_sync=True,
 0:                 use_ring_exchange_p2p=False,
 0:                 deallocate_pipeline_outputs=True,
 0:                 defer_embedding_wgrad_compute=False,
 0:                 wgrad_deferral_limit=50,
 0:                 overlap_p2p_comm_warmup_flush=False,
 0:                 microbatch_group_size_per_vp_stage=1,
 0:                 cpu_offloading=False,
 0:                 cpu_offloading_num_layers=0,
 0:                 _cpu_offloading_context=None,
 0:                 cpu_offloading_activations=True,
 0:                 cpu_offloading_weights=False,
 0:                 cpu_offloading_double_buffering=False,
 0:                 barrier_with_L1_time=True,
 0:                 num_layers=32,
 0:                 mtp_num_layers=None,
 0:                 mtp_loss_scaling_factor=None,
 0:                 num_layers_in_first_pipeline_stage=None,
 0:                 num_layers_in_last_pipeline_stage=None,
 0:                 pipeline_model_parallel_layout=None,
 0:                 account_for_embedding_in_pipeline_split=False,
 0:                 account_for_loss_in_pipeline_split=False,
 0:                 hidden_size=4096,
 0:                 num_attention_heads=32,
 0:                 attention_backend=<AttnBackend.auto: 5>,
 0:                 softmax_scale=None,
 0:                 softmax_type='vanilla',
 0:                 num_query_groups=8,
 0:                 ffn_hidden_size=14336,
 0:                 kv_channels=128,
 0:                 hidden_dropout=0.0,
 0:                 attention_dropout=0.0,
 0:                 fp32_residual_connection=False,
 0:                 apply_residual_connection_post_layernorm=False,
 0:                 layernorm_epsilon=1e-05,
 0:                 layernorm_zero_centered_gamma=False,
 0:                 add_bias_linear=False,
 0:                 add_qkv_bias=False,
 0:                 gated_linear_unit=True,
 0:                 activation_func=<function silu at 0xdaa3509a480>,
 0:                 activation_func_fp8_input_store=False,
 0:                 glu_linear_offset=0.0,
 0:                 activation_func_clamp_value=None,
 0:                 num_moe_experts=None,
 0:                 rotary_interleaved=False,
 0:                 window_size=None,
 0:                 window_attn_skip_freq=None,
 0:                 normalization='RMSNorm',
 0:                 qk_layernorm=False,
 0:                 test_mode=False,
 0:                 calculate_per_token_loss=False,
 0:                 multi_latent_attention=False,
 0:                 no_rope_freq=None,
 0:                 moe_deepep_num_sms=20,
 0:                 init_method=functools.partial(<function normal_ at 0xdaa34f1ade0>, mean=0.0, std=0.02),
 0:                 output_layer_init_method=functools.partial(<function normal_ at 0xdaa34f1ade0>, mean=0.0, std=0.0025),
 0:                 init_method_std=0.02,
 0:                 embedding_init_method=functools.partial(<function normal_ at 0xdaa34f1ade0>, mean=0.0, std=0.02),
 0:                 embedding_init_method_std=0.02,
 0:                 init_model_with_meta_device=False,
 0:                 apply_query_key_layer_scaling=False,
 0:                 attention_softmax_in_fp32=False,
 0:                 disable_bf16_reduced_precision_matmul=False,
 0:                 bias_activation_fusion=True,
 0:                 masked_softmax_fusion=True,
 0:                 persist_layer_norm=True,
 0:                 memory_efficient_layer_norm=False,
 0:                 bias_dropout_fusion=True,
 0:                 apply_rope_fusion=True,
 0:                 use_fused_weighted_squared_relu=False,
 0:                 fused_single_qkv_rope=True,
 0:                 recompute_granularity=None,
 0:                 recompute_method=None,
 0:                 recompute_num_layers=None,
 0:                 distribute_saved_activations=None,
 0:                 recompute_modules=['core_attn'],
 0:                 fp8=None,
 0:                 fp8_recipe='tensorwise',
 0:                 fp8_param=False,
 0:                 fp8_margin=0,
 0:                 fp8_interval=1,
 0:                 fp8_amax_history_len=1,
 0:                 fp8_amax_compute_algo='most_recent',
 0:                 fp8_wgrad=True,
 0:                 fp8_dot_product_attention=True,
 0:                 fp8_multi_head_attention=False,
 0:                 tp_only_amax_red=False,
 0:                 first_last_layers_bf16=False,
 0:                 num_layers_at_start_in_bf16=0,
 0:                 num_layers_at_end_in_bf16=0,
 0:                 use_kitchen=False,
 0:                 fp4='e2m1',
 0:                 fp4_recipe='nvfp4',
 0:                 fp4_param=False,
 0:                 moe_shared_expert_intermediate_size=None,
 0:                 moe_shared_expert_overlap=False,
 0:                 moe_layer_freq=1,
 0:                 moe_ffn_hidden_size=None,
 0:                 moe_router_load_balancing_type='aux_loss',
 0:                 moe_router_topk=2,
 0:                 moe_router_topk_limited_devices=None,
 0:                 moe_router_padding_for_fp8=False,
 0:                 moe_router_num_groups=None,
 0:                 moe_router_group_topk=None,
 0:                 moe_router_pre_softmax=False,
 0:                 moe_router_topk_scaling_factor=None,
 0:                 moe_router_score_function='softmax',
 0:                 moe_router_dtype=None,
 0:                 moe_router_enable_expert_bias=False,
 0:                 moe_router_bias_update_rate=0.001,
 0:                 moe_router_force_load_balancing=False,
 0:                 moe_grouped_gemm=False,
 0:                 moe_use_legacy_grouped_gemm=False,
 0:                 moe_aux_loss_coeff=0.0,
 0:                 moe_z_loss_coeff=None,
 0:                 moe_input_jitter_eps=None,
 0:                 moe_token_dropping=False,
 0:                 moe_token_dispatcher_type='allgather',
 0:                 moe_enable_deepep=False,
 0:                 moe_per_layer_logging=False,
 0:                 moe_expert_capacity_factor=None,
 0:                 moe_pad_expert_input_to_capacity=False,
 0:                 moe_token_drop_policy='probs',
 0:                 moe_layer_recompute=False,
 0:                 moe_permute_fusion=False,
 0:                 moe_router_fusion=False,
 0:                 moe_apply_probs_on_input=False,
 0:                 cp_comm_type=None,
 0:                 enable_cuda_graph=1,
 0:                 cuda_graph_use_single_mempool=False,
 0:                 cuda_graph_retain_backward_graph=False,
 0:                 cuda_graph_warmup_steps=3,
 0:                 external_cuda_graph=False,
 0:                 cuda_graph_scope='full_iteration',
 0:                 clone_scatter_output_in_embedding=True,
 0:                 disable_parameter_transpose_cache=False,
 0:                 config_logger_dir='',
 0:                 flash_decode=False,
 0:                 use_te_activation_func=False,
 0:                 inference_rng_tracker=False,
 0:                 inference_sampling_seed=42,
 0:                 symmetric_ar_type=None,
 0:                 mrope_section=None,
 0:                 is_hybrid_model=False,
 0:                 mamba_state_dim=128,
 0:                 mamba_head_dim=64,
 0:                 mamba_num_groups=8,
 0:                 mamba_num_heads=None,
 0:                 use_mamba_mem_eff_path=True,
 0:                 mlp_chunks_for_prefill=1,
 0:                 heterogeneous_block_specs=False,
 0:                 hetereogenous_dist_checkpoint=False,
 0:                 quant_recipe=None,
 0:                 transformer_impl='transformer_engine',
 0:                 fp16_lm_cross_entropy=False,
 0:                 parallel_output=True,
 0:                 share_embeddings_and_output_weights=False,
 0:                 make_vocab_size_divisible_by=128,
 0:                 position_embedding_type='rope',
 0:                 rotary_base=500000,
 0:                 rotary_percent=1.0,
 0:                 seq_len_interpolation_factor=None,
 0:                 seq_length=8192,
 0:                 scatter_embedding_sequence_parallel=True,
 0:                 use_transformer_engine_full_layer_spec=False,
 0:                 transformer_layer_spec=<function default_layer_spec at 0xda73c98aac0>,
 0:                 forward_step_fn=<function gpt_forward_step at 0xda73c989440>,
 0:                 data_step_fn=<function gpt_data_step at 0xda73c989300>,
 0:                 generation_config=None,
 0:                 vocab_size=None,
 0:                 tp_comm_overlap_cfg=None,
 0:                 use_transformer_engine_op_fuser=True,
 0:                 scale_factor=8.0,
 0:                 low_freq_factor=1.0,
 0:                 high_freq_factor=4.0,
 0:                 old_context_len=8192)
 0: [AUX I 2025-10-08 04:45:36 data:291] Instantiating MegatronPretrainingSampler with total_samples: 10000000 and consumed_samples: 0
 7: [rank7]:[W1008 04:45:36.765361087 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 122 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
28: [rank28]:[W1008 04:45:36.816924904 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 185 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
31: [rank31]:[W1008 04:45:36.824327920 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 194 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 1: [rank1]:[W1008 04:45:36.799548255 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 104 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
29: [rank29]:[W1008 04:45:36.828085500 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 188 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
23: [rank23]:[W1008 04:45:36.928068668 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 170 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
21: [rank21]:[W1008 04:45:36.931035089 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 164 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
26: [rank26]:[W1008 04:45:36.837761875 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 179 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
24: [rank24]:[W1008 04:45:36.844047156 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 173 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
15: [rank15]:[W1008 04:45:36.886988504 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 146 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
19: [rank19]:[W1008 04:45:36.945275433 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 158 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
18: [rank18]:[W1008 04:45:36.945498134 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 155 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 3: [rank3]:[W1008 04:45:36.823749305 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 110 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
14: [rank14]:[W1008 04:45:36.897990619 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 143 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
12: [rank12]:[W1008 04:45:36.900499481 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 137 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
16: [rank16]:[W1008 04:45:36.956764500 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 149 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
13: [rank13]:[W1008 04:45:36.903030342 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 140 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
20: [rank20]:[W1008 04:45:37.969659775 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 161 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
17: [rank17]:[W1008 04:45:37.975953120 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 152 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 2: [rank2]:[W1008 04:45:37.854977774 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 107 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
22: [rank22]:[W1008 04:45:37.987029781 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 167 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 0: [rank0]:[W1008 04:45:37.864469509 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 101 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
25: [rank25]:[W1008 04:45:37.895688553 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 176 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 6: [rank6]:[W1008 04:45:37.880751417 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 119 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 5: [rank5]:[W1008 04:45:37.881056526 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 116 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 8: [rank8]:[W1008 04:45:37.951674012 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 125 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
27: [rank27]:[W1008 04:45:37.918895181 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 182 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
10: [rank10]:[W1008 04:45:37.962457022 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 131 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
30: [rank30]:[W1008 04:45:37.923241100 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 191 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 4: [rank4]:[W1008 04:45:37.909073363 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 113 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 9: [rank9]:[W1008 04:45:37.006282700 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 128 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
11: [rank11]:[W1008 04:45:37.016588765 ProcessGroupNCCL.cpp:5084] [PG ID 6 PG GUID 134 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 0: [AUX I 2025-10-08 04:45:38 custom_callbacks:129] Starting training warmup
 0: [AUX I 2025-10-08 04:45:38 custom_callbacks:133]     Starting warmup step 0
 0: [AUX I 2025-10-08 04:46:03 custom_callbacks:150]     Finished warmup step 0, takes 25.308744430541992 s
 0: [AUX I 2025-10-08 04:46:03 custom_callbacks:133]     Starting warmup step 1
 0: [NeMo I 2025-10-08 04:46:03 full_cuda_graph:164] Capture CUDA graph for training!!!
 0: [NeMo I 2025-10-08 04:46:04 full_cuda_graph:182] CUDA graph capture done!!!
 0: [AUX I 2025-10-08 04:46:04 custom_callbacks:150]     Finished warmup step 1, takes 0.9115886688232422 s
 0: [AUX I 2025-10-08 04:46:04 custom_callbacks:157] Finished training warmup: 26.225025415420532 s. 
 0: [AUX I 2025-10-08 04:46:04 custom_callbacks:176] Starting validation warmups
 0: [NeMo I 2025-10-08 04:46:04 full_cuda_graph:164] Capture CUDA graph for validation!!!
 0: [NeMo I 2025-10-08 04:46:05 full_cuda_graph:182] CUDA graph capture done!!!
 0: [AUX I 2025-10-08 04:46:05 custom_callbacks:195] Finished validation warmup: 1.1397705078125 s. 
 0: [AUX I 2025-10-08 04:46:05 custom_callbacks:202] Finished training warmup: 1.140599012374878 s. 
 0: [AUX I 2025-10-08 04:46:05 custom_callbacks:212] Time spent in run_training_warmup: 1.1444172859191895s
 0: :::MLLOG {"namespace": "", "time_ms": 1759898765534, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"warmup_time": 87.79515607911162}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898765606, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"init_finished": 0.07131286687217653}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898765606, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898765607, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898765609, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898773984, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.25739145278930664, "reduced_train_loss": 9.759668350219727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 31.0, "samples_count": 1024.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898782268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2625281810760498, "reduced_train_loss": 7.509285926818848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 63.0, "samples_count": 2048.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898790688, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26152920722961426, "reduced_train_loss": 7.070063591003418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 95.0, "samples_count": 3072.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898799176, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26355910301208496, "reduced_train_loss": 6.805673122406006}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 127.0, "samples_count": 4096.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898807708, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26589465141296387, "reduced_train_loss": 6.728021621704102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 159.0, "samples_count": 5120.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898816287, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2669072151184082, "reduced_train_loss": 6.5399980545043945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 191.0, "samples_count": 6144.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898824847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2660188674926758, "reduced_train_loss": 6.416435718536377}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 223.0, "samples_count": 7168.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898833423, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26685500144958496, "reduced_train_loss": 6.315154075622559}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 255.0, "samples_count": 8192.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898841997, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2649574279785156, "reduced_train_loss": 6.194585800170898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 287.0, "samples_count": 9216.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898850557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2642223834991455, "reduced_train_loss": 6.034603118896484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 319.0, "samples_count": 10240.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898859125, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26206278800964355, "reduced_train_loss": 5.929859161376953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 351.0, "samples_count": 11264.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898867666, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26827120780944824, "reduced_train_loss": 5.920018196105957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 383.0, "samples_count": 12288.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868125, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26697849864346307}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868126, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868126, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 12288, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868249, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.5831818580627441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 0, "samples_count": 32}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868328, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07974362373352051}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1, "samples_count": 64}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868405, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07692503929138184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2, "samples_count": 96}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868482, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07718372344970703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3, "samples_count": 128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868560, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07773494720458984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4, "samples_count": 160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0779879093170166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5, "samples_count": 192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868717, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07851195335388184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6, "samples_count": 224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868794, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07790589332580566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7, "samples_count": 256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868874, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07987594604492188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 8, "samples_count": 288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898868957, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08282065391540527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 9, "samples_count": 320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869037, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07990407943725586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 10, "samples_count": 352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08090591430664062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 11, "samples_count": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869201, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08266186714172363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 12, "samples_count": 416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869279, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07870030403137207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 13, "samples_count": 448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07925152778625488}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 14, "samples_count": 480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08077096939086914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 15, "samples_count": 512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869520, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08036589622497559}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 16, "samples_count": 544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869598, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0787668228149414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 17, "samples_count": 576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869679, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0802774429321289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 18, "samples_count": 608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869759, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07979369163513184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 19, "samples_count": 640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869839, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08014869689941406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 20, "samples_count": 672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869918, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07902884483337402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 21, "samples_count": 704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898869997, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07893109321594238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 22, "samples_count": 736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870076, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07943320274353027}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 23, "samples_count": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08024716377258301}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 24, "samples_count": 800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870237, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08086681365966797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 25, "samples_count": 832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870318, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08073973655700684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 26, "samples_count": 864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870396, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07850241661071777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 27, "samples_count": 896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870477, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08009505271911621}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 28, "samples_count": 928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870556, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0796651840209961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 29, "samples_count": 960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08012509346008301}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 30, "samples_count": 992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07982444763183594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 31, "samples_count": 1024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870720, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 5.792514801025391, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870720, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.5947916109580547}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870720, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 12288, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898870720, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898879295, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27057766914367676, "reduced_train_loss": 5.681272029876709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 415.0, "samples_count": 13312.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898887856, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27048182487487793, "reduced_train_loss": 5.522820472717285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 447.0, "samples_count": 14336.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898896421, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26508259773254395, "reduced_train_loss": 5.395190238952637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 479.0, "samples_count": 15360.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898904990, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27341651916503906, "reduced_train_loss": 5.3329033851623535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 511.0, "samples_count": 16384.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898913562, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2642934322357178, "reduced_train_loss": 5.185225963592529}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 543.0, "samples_count": 17408.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898922143, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26960206031799316, "reduced_train_loss": 5.088408470153809}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 575.0, "samples_count": 18432.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898930723, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2662777900695801, "reduced_train_loss": 5.139366149902344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 607.0, "samples_count": 19456.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898939288, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26713085174560547, "reduced_train_loss": 4.937551975250244}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 639.0, "samples_count": 20480.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898947858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26452040672302246, "reduced_train_loss": 4.846871852874756}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 671.0, "samples_count": 21504.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898956434, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2676520347595215, "reduced_train_loss": 4.721735954284668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 703.0, "samples_count": 22528.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898965005, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26715922355651855, "reduced_train_loss": 4.633925437927246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 735.0, "samples_count": 23552.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898973587, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2727952003479004, "reduced_train_loss": 4.579256057739258}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 767.0, "samples_count": 24576.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974175, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2694127551640122}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974175, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974175, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 24576, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6717891693115234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 32, "samples_count": 1056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0772867202758789}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 33, "samples_count": 1088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974414, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07898736000061035}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 34, "samples_count": 1120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974493, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07871198654174805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 35, "samples_count": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974572, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0790097713470459}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 36, "samples_count": 1184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974651, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07916927337646484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 37, "samples_count": 1216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0787043571472168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 38, "samples_count": 1248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974809, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07861852645874023}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 39, "samples_count": 1280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974890, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08158659934997559}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 40, "samples_count": 1312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898974971, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08097290992736816}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 41, "samples_count": 1344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0803837776184082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 42, "samples_count": 1376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975131, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07976579666137695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 43, "samples_count": 1408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975213, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08113217353820801}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 44, "samples_count": 1440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975294, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0816495418548584}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 45, "samples_count": 1472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975375, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08088564872741699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 46, "samples_count": 1504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975458, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08252596855163574}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 47, "samples_count": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08229637145996094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 48, "samples_count": 1568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975619, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07879424095153809}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 49, "samples_count": 1600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975699, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08013796806335449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 50, "samples_count": 1632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975780, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08106875419616699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 51, "samples_count": 1664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975859, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07887959480285645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 52, "samples_count": 1696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898975937, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07875704765319824}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 53, "samples_count": 1728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08120870590209961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 54, "samples_count": 1760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976098, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07944726943969727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 55, "samples_count": 1792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0797884464263916}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 56, "samples_count": 1824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976257, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07937908172607422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 57, "samples_count": 1856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976339, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0814511775970459}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 58, "samples_count": 1888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976418, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07914423942565918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 59, "samples_count": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07901883125305176}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 60, "samples_count": 1952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08284163475036621}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 61, "samples_count": 1984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07944488525390625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 62, "samples_count": 2016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07940006256103516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 63, "samples_count": 2048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976739, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 4.57346248626709, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 24576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976740, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.5650034460704774}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976740, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 24576, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898976740, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898985311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26892542839050293, "reduced_train_loss": 4.551113128662109}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 799.0, "samples_count": 25600.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759898993887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.271028995513916, "reduced_train_loss": 4.53924036026001}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 831.0, "samples_count": 26624.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899002445, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2688415050506592, "reduced_train_loss": 4.384860515594482}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 863.0, "samples_count": 27648.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899011028, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2713613510131836, "reduced_train_loss": 4.279797554016113}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 895.0, "samples_count": 28672.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899019586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26489806175231934, "reduced_train_loss": 4.320023059844971}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 927.0, "samples_count": 29696.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899028178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2692146301269531, "reduced_train_loss": 4.266206741333008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 959.0, "samples_count": 30720.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899036756, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2691223621368408, "reduced_train_loss": 4.2260236740112305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 991.0, "samples_count": 31744.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899045332, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26601743698120117, "reduced_train_loss": 4.256741046905518}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1023.0, "samples_count": 32768.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899053903, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2702972888946533, "reduced_train_loss": 4.239474296569824}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1055.0, "samples_count": 33792.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899062495, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2682383060455322, "reduced_train_loss": 4.065601348876953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1087.0, "samples_count": 34816.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899071058, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26892542839050293, "reduced_train_loss": 4.160506725311279}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1119.0, "samples_count": 35840.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899079642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2680394649505615, "reduced_train_loss": 4.229284763336182}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1151.0, "samples_count": 36864.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080191, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26940565563563723}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080193, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080193, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 36864, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080277, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6358194351196289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 64, "samples_count": 2080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080355, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07828593254089355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 65, "samples_count": 2112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080436, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08060455322265625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 66, "samples_count": 2144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07882332801818848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 67, "samples_count": 2176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080593, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07843542098999023}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 68, "samples_count": 2208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07980489730834961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 69, "samples_count": 2240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080752, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07913994789123535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 70, "samples_count": 2272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080831, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07937002182006836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 71, "samples_count": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080911, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07932257652282715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 72, "samples_count": 2336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899080994, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08275151252746582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 73, "samples_count": 2368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081074, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08047246932983398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 74, "samples_count": 2400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081155, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08057069778442383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 75, "samples_count": 2432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081234, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0795893669128418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 76, "samples_count": 2464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081314, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07991695404052734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 77, "samples_count": 2496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081394, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0800621509552002}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 78, "samples_count": 2528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081475, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08096075057983398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 79, "samples_count": 2560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081556, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08098006248474121}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 80, "samples_count": 2592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07975339889526367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 81, "samples_count": 2624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081717, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08095932006835938}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 82, "samples_count": 2656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081798, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08091235160827637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 83, "samples_count": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07931852340698242}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 84, "samples_count": 2720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899081958, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08105206489562988}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 85, "samples_count": 2752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082039, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08136892318725586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 86, "samples_count": 2784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0784921646118164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 87, "samples_count": 2816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082198, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08045554161071777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 88, "samples_count": 2848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082278, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07947754859924316}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 89, "samples_count": 2880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08116674423217773}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 90, "samples_count": 2912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082438, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07901692390441895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 91, "samples_count": 2944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082520, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08151769638061523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 92, "samples_count": 2976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082599, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07912802696228027}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 93, "samples_count": 3008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082679, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08022856712341309}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 94, "samples_count": 3040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082758, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07908439636230469}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 95, "samples_count": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082759, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 4.26442813873291, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 36864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082759, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.56757449102588}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082759, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 36864, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899082759, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899091355, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2644164562225342, "reduced_train_loss": 4.2206621170043945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1183.0, "samples_count": 37888.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899099939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2714722156524658, "reduced_train_loss": 4.121086597442627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1215.0, "samples_count": 38912.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899108509, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.268296480178833, "reduced_train_loss": 4.098134517669678}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1247.0, "samples_count": 39936.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899117088, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.267592191696167, "reduced_train_loss": 4.086439609527588}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1279.0, "samples_count": 40960.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899125684, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26908230781555176, "reduced_train_loss": 4.066633224487305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1311.0, "samples_count": 41984.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899134256, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2670633792877197, "reduced_train_loss": 4.042642593383789}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1343.0, "samples_count": 43008.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899142828, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26505231857299805, "reduced_train_loss": 3.9922189712524414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1375.0, "samples_count": 44032.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899151403, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.265383243560791, "reduced_train_loss": 4.072223663330078}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1407.0, "samples_count": 45056.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899159981, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2642338275909424, "reduced_train_loss": 4.051815986633301}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1439.0, "samples_count": 46080.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899168574, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27077674865722656, "reduced_train_loss": 3.9765515327453613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1471.0, "samples_count": 47104.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899177158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2650423049926758, "reduced_train_loss": 3.9537296295166016}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1503.0, "samples_count": 48128.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899185759, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26961588859558105, "reduced_train_loss": 3.8249361515045166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1535.0, "samples_count": 49152.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186338, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2697360692551835}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186338, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186338, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 49152, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186423, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6641745567321777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 96, "samples_count": 3104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186502, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0791776180267334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 97, "samples_count": 3136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0775144100189209}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 98, "samples_count": 3168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07951879501342773}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 99, "samples_count": 3200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186737, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07758975028991699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 100, "samples_count": 3232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186816, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07887101173400879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 101, "samples_count": 3264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186895, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07916975021362305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 102, "samples_count": 3296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899186974, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07895421981811523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 103, "samples_count": 3328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08306169509887695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 104, "samples_count": 3360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187139, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08173799514770508}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 105, "samples_count": 3392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187218, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07933855056762695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 106, "samples_count": 3424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187301, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08321046829223633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 107, "samples_count": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08233523368835449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 108, "samples_count": 3488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187465, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0815129280090332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 109, "samples_count": 3520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187545, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08005595207214355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 110, "samples_count": 3552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187625, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07944226264953613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 111, "samples_count": 3584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187705, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08021092414855957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 112, "samples_count": 3616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187787, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08180713653564453}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 113, "samples_count": 3648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08078980445861816}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 114, "samples_count": 3680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899187947, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07924342155456543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 115, "samples_count": 3712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08051419258117676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 116, "samples_count": 3744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188108, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08070063591003418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 117, "samples_count": 3776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188189, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08077526092529297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 118, "samples_count": 3808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188267, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07834148406982422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 119, "samples_count": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07864832878112793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 120, "samples_count": 3872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188425, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07951211929321289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 121, "samples_count": 3904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188508, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0825507640838623}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 122, "samples_count": 3936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188591, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08355426788330078}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 123, "samples_count": 3968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188669, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07803511619567871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 124, "samples_count": 4000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188751, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08162045478820801}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 125, "samples_count": 4032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188834, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08267426490783691}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 126, "samples_count": 4064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188917, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08341217041015625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 127, "samples_count": 4096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188918, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.9365999698638916, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 49152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188918, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.5803473577834666}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188918, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 49152, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899188918, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899197519, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2686426639556885, "reduced_train_loss": 3.950709342956543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1567.0, "samples_count": 50176.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899206115, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2700040340423584, "reduced_train_loss": 3.827810049057007}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1599.0, "samples_count": 51200.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899214716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26705241203308105, "reduced_train_loss": 3.905355215072632}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1631.0, "samples_count": 52224.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899223320, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26929783821105957, "reduced_train_loss": 3.923142433166504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1663.0, "samples_count": 53248.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899231921, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2747514247894287, "reduced_train_loss": 3.9457764625549316}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1695.0, "samples_count": 54272.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899240487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2655336856842041, "reduced_train_loss": 3.821732521057129}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1727.0, "samples_count": 55296.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899249063, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2694270610809326, "reduced_train_loss": 3.8112759590148926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1759.0, "samples_count": 56320.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899257647, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2702217102050781, "reduced_train_loss": 3.868241310119629}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1791.0, "samples_count": 57344.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899266219, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2697784900665283, "reduced_train_loss": 3.84161376953125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1823.0, "samples_count": 58368.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899274828, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2659947872161865, "reduced_train_loss": 3.8636341094970703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1855.0, "samples_count": 59392.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899283412, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26859426498413086, "reduced_train_loss": 3.797490119934082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1887.0, "samples_count": 60416.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2694060802459717, "reduced_train_loss": 3.7216954231262207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1919.0, "samples_count": 61440.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292581, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26995499170091836}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292581, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292582, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 61440, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292665, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6377170085906982}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 128, "samples_count": 4128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292743, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07808136940002441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 129, "samples_count": 4160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292821, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07836365699768066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 130, "samples_count": 4192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292899, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07818126678466797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 131, "samples_count": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899292977, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0780339241027832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 132, "samples_count": 4256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07997345924377441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 133, "samples_count": 4288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293138, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08040285110473633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 134, "samples_count": 4320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07885098457336426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 135, "samples_count": 4352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08207368850708008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 136, "samples_count": 4384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293379, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08018827438354492}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 137, "samples_count": 4416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293458, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07970547676086426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 138, "samples_count": 4448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08194637298583984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 139, "samples_count": 4480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07917356491088867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 140, "samples_count": 4512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293699, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07909846305847168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 141, "samples_count": 4544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293779, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08068680763244629}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 142, "samples_count": 4576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07878899574279785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 143, "samples_count": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899293939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08124923706054688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 144, "samples_count": 4640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07992005348205566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 145, "samples_count": 4672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294099, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07976603507995605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 146, "samples_count": 4704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0794670581817627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 147, "samples_count": 4736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07968711853027344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 148, "samples_count": 4768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294338, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.079345703125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 149, "samples_count": 4800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294417, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07954716682434082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 150, "samples_count": 4832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294499, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08240175247192383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 151, "samples_count": 4864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08096528053283691}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 152, "samples_count": 4896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07925677299499512}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 153, "samples_count": 4928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07836008071899414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 154, "samples_count": 4960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294818, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07994914054870605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 155, "samples_count": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294898, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08015084266662598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 156, "samples_count": 5024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899294980, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08178925514221191}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 157, "samples_count": 5056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899295062, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08156132698059082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 158, "samples_count": 5088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899295143, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0813140869140625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 159, "samples_count": 5120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899295144, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.8104541301727295, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 61440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899295144, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.563046383904293}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899295144, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 61440, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899295144, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899303726, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27183079719543457, "reduced_train_loss": 3.7770462036132812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1951.0, "samples_count": 62464.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899312314, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2680337429046631, "reduced_train_loss": 3.8501081466674805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 1983.0, "samples_count": 63488.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899320890, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2645683288574219, "reduced_train_loss": 3.7574303150177}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2015.0, "samples_count": 64512.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899329480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2740945816040039, "reduced_train_loss": 3.7047934532165527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2047.0, "samples_count": 65536.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899338069, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26727914810180664, "reduced_train_loss": 3.7990405559539795}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2079.0, "samples_count": 66560.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899346668, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2691662311553955, "reduced_train_loss": 3.728564977645874}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2111.0, "samples_count": 67584.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899355237, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27033424377441406, "reduced_train_loss": 3.7431654930114746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2143.0, "samples_count": 68608.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899363808, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2655766010284424, "reduced_train_loss": 3.781071186065674}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2175.0, "samples_count": 69632.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899372406, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26608824729919434, "reduced_train_loss": 3.7182602882385254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2207.0, "samples_count": 70656.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899381000, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26599717140197754, "reduced_train_loss": 3.729191303253174}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2239.0, "samples_count": 71680.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899389608, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26518678665161133, "reduced_train_loss": 3.6780171394348145}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2271.0, "samples_count": 72704.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899398184, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2694852352142334, "reduced_train_loss": 3.775296926498413}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2303.0, "samples_count": 73728.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899398723, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2697344302608447}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899398725, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899398725, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 73728, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899398845, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.661264181137085}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 160, "samples_count": 5152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899398926, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0802919864654541}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 161, "samples_count": 5184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07850313186645508}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 162, "samples_count": 5216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399082, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07847833633422852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 163, "samples_count": 5248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399163, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0800776481628418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 164, "samples_count": 5280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399241, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07872867584228516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 165, "samples_count": 5312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399319, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07731366157531738}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 166, "samples_count": 5344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399398, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07966375350952148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 167, "samples_count": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08151030540466309}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 168, "samples_count": 5408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399559, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07929635047912598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 169, "samples_count": 5440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399640, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0807502269744873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 170, "samples_count": 5472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399721, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08128237724304199}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 171, "samples_count": 5504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399800, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07918286323547363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 172, "samples_count": 5536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399880, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08011317253112793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 173, "samples_count": 5568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899399959, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07887077331542969}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 174, "samples_count": 5600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400038, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0786280632019043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 175, "samples_count": 5632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400121, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08302974700927734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 176, "samples_count": 5664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08127212524414062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 177, "samples_count": 5696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400284, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08196592330932617}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 178, "samples_count": 5728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400364, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07973504066467285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 179, "samples_count": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400445, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08157086372375488}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 180, "samples_count": 5792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400525, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07981181144714355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 181, "samples_count": 5824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400606, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08083462715148926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 182, "samples_count": 5856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400686, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07944202423095703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 183, "samples_count": 5888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400768, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08208274841308594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 184, "samples_count": 5920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400846, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07871747016906738}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 185, "samples_count": 5952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899400929, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08308887481689453}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 186, "samples_count": 5984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401013, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08330321311950684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 187, "samples_count": 6016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401092, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0791935920715332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 188, "samples_count": 6048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401174, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08169794082641602}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 189, "samples_count": 6080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401255, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08168148994445801}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 190, "samples_count": 6112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07970523834228516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 191, "samples_count": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401336, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.7124578952789307, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 73728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.614191895816475}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401336, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 73728, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899401336, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899409919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26399970054626465, "reduced_train_loss": 3.7009313106536865}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2335.0, "samples_count": 74752.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899418500, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26910924911499023, "reduced_train_loss": 3.6746058464050293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2367.0, "samples_count": 75776.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899427102, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2709207534790039, "reduced_train_loss": 3.646937131881714}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2399.0, "samples_count": 76800.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899435703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.270949125289917, "reduced_train_loss": 3.735808849334717}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2431.0, "samples_count": 77824.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899444314, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2706289291381836, "reduced_train_loss": 3.728766441345215}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2463.0, "samples_count": 78848.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899452912, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26836323738098145, "reduced_train_loss": 3.690448760986328}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2495.0, "samples_count": 79872.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899461515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.269071102142334, "reduced_train_loss": 3.620756149291992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2527.0, "samples_count": 80896.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899470110, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2644619941711426, "reduced_train_loss": 3.613783359527588}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2559.0, "samples_count": 81920.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899478696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2685389518737793, "reduced_train_loss": 3.607729434967041}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2591.0, "samples_count": 82944.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899487302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27583932876586914, "reduced_train_loss": 3.7168128490448}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2623.0, "samples_count": 83968.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899495880, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27207279205322266, "reduced_train_loss": 3.6559853553771973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2655.0, "samples_count": 84992.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899504485, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2657766342163086, "reduced_train_loss": 3.641663074493408}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2687.0, "samples_count": 86016.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2700288645131271}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505028, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505028, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 86016, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505143, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6584901809692383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 192, "samples_count": 6176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505221, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07787060737609863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 193, "samples_count": 6208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505300, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07892465591430664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 194, "samples_count": 6240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505376, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07685399055480957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 195, "samples_count": 6272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505455, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07848143577575684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 196, "samples_count": 6304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505534, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07919955253601074}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 197, "samples_count": 6336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505613, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07924604415893555}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 198, "samples_count": 6368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505694, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08093380928039551}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 199, "samples_count": 6400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0816187858581543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 200, "samples_count": 6432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505857, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0810539722442627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 201, "samples_count": 6464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899505938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08060169219970703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 202, "samples_count": 6496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08173632621765137}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 203, "samples_count": 6528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506102, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0825505256652832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 204, "samples_count": 6560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506181, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0792233943939209}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 205, "samples_count": 6592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506262, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08060717582702637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 206, "samples_count": 6624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506342, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08006572723388672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 207, "samples_count": 6656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506424, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08246040344238281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 208, "samples_count": 6688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506506, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08149504661560059}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 209, "samples_count": 6720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506588, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08188796043395996}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 210, "samples_count": 6752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506666, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07845115661621094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 211, "samples_count": 6784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506747, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0809030532836914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 212, "samples_count": 6816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506826, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0785837173461914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 213, "samples_count": 6848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506908, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08296751976013184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 214, "samples_count": 6880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899506992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08373665809631348}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 215, "samples_count": 6912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507071, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07900094985961914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 216, "samples_count": 6944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507151, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07979154586791992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 217, "samples_count": 6976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507232, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08128070831298828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 218, "samples_count": 7008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507313, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08096933364868164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 219, "samples_count": 7040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507395, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0814049243927002}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 220, "samples_count": 7072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507474, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07981061935424805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 221, "samples_count": 7104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507555, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08088803291320801}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 222, "samples_count": 7136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08041024208068848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 223, "samples_count": 7168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507636, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.665998935699463, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 86016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.6099415060598403}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507637, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 86016, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899507637, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899516243, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2662353515625, "reduced_train_loss": 3.5396714210510254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2719.0, "samples_count": 87040.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899524850, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2705099582672119, "reduced_train_loss": 3.629791259765625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2751.0, "samples_count": 88064.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899533457, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2670478820800781, "reduced_train_loss": 3.705540657043457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2783.0, "samples_count": 89088.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899542057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2689952850341797, "reduced_train_loss": 3.564164876937866}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2815.0, "samples_count": 90112.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899550663, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2631797790527344, "reduced_train_loss": 3.7082061767578125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2847.0, "samples_count": 91136.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899559287, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.269681453704834, "reduced_train_loss": 3.571582317352295}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2879.0, "samples_count": 92160.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899567892, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26530885696411133, "reduced_train_loss": 3.586266279220581}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2911.0, "samples_count": 93184.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899576498, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27224016189575195, "reduced_train_loss": 3.6078734397888184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2943.0, "samples_count": 94208.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899585124, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2714729309082031, "reduced_train_loss": 3.5435500144958496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 2975.0, "samples_count": 95232.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899593722, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26830053329467773, "reduced_train_loss": 3.6169655323028564}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3007.0, "samples_count": 96256.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899602324, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2717623710632324, "reduced_train_loss": 3.5932557582855225}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3039.0, "samples_count": 97280.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899610914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26747608184814453, "reduced_train_loss": 3.5447494983673096}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3071.0, "samples_count": 98304.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2703209630623557}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611442, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611442, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 98304, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6432595252990723}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 224, "samples_count": 7200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07992982864379883}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 225, "samples_count": 7232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07884621620178223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 226, "samples_count": 7264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0791633129119873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 227, "samples_count": 7296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611874, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0786745548248291}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 228, "samples_count": 7328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899611954, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07984709739685059}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 229, "samples_count": 7360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612033, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07959461212158203}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 230, "samples_count": 7392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612114, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08123326301574707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 231, "samples_count": 7424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612195, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0801534652709961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 232, "samples_count": 7456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612276, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08115196228027344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 233, "samples_count": 7488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612357, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08091521263122559}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 234, "samples_count": 7520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612436, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07945609092712402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 235, "samples_count": 7552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612516, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08031392097473145}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 236, "samples_count": 7584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612597, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08043813705444336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 237, "samples_count": 7616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612677, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07966947555541992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 238, "samples_count": 7648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612757, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08065915107727051}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 239, "samples_count": 7680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612836, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07892203330993652}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 240, "samples_count": 7712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07906317710876465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 241, "samples_count": 7744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899612996, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08124876022338867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 242, "samples_count": 7776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08030247688293457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 243, "samples_count": 7808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08090949058532715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 244, "samples_count": 7840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613239, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08133482933044434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 245, "samples_count": 7872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613319, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08001017570495605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 246, "samples_count": 7904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613398, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07903051376342773}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 247, "samples_count": 7936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08207297325134277}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 248, "samples_count": 7968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613561, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08059310913085938}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 249, "samples_count": 8000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08103370666503906}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 250, "samples_count": 8032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613723, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08174681663513184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 251, "samples_count": 8064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613807, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08330678939819336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 252, "samples_count": 8096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613885, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07870197296142578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 253, "samples_count": 8128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899613965, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07958817481994629}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 254, "samples_count": 8160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899614047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08165764808654785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 255, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899614047, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.573817253112793, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 98304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899614048, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.6074441850651056}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899614048, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 98304, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899614048, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899622648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26828885078430176, "reduced_train_loss": 3.550598382949829}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3103.0, "samples_count": 99328.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899631233, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26810193061828613, "reduced_train_loss": 3.6102070808410645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3135.0, "samples_count": 100352.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899639846, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2704465389251709, "reduced_train_loss": 3.5127644538879395}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3167.0, "samples_count": 101376.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899648447, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2759816646575928, "reduced_train_loss": 3.4727964401245117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3199.0, "samples_count": 102400.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899657042, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2676880359649658, "reduced_train_loss": 3.4987986087799072}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3231.0, "samples_count": 103424.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899665636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26657986640930176, "reduced_train_loss": 3.513410806655884}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3263.0, "samples_count": 104448.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899674227, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27215123176574707, "reduced_train_loss": 3.5178675651550293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3295.0, "samples_count": 105472.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899682804, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26866817474365234, "reduced_train_loss": 3.5946455001831055}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3327.0, "samples_count": 106496.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899691412, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27475881576538086, "reduced_train_loss": 3.511815071105957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3359.0, "samples_count": 107520.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899700010, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26596760749816895, "reduced_train_loss": 3.5099408626556396}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3391.0, "samples_count": 108544.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899708597, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2672140598297119, "reduced_train_loss": 3.56443190574646}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3423.0, "samples_count": 109568.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899717196, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26825809478759766, "reduced_train_loss": 3.3952481746673584}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3455.0, "samples_count": 110592.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899717739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27002961325524666}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899717740, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899717740, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 110592, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899717845, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.648902416229248}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 256, "samples_count": 8224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899717924, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0792243480682373}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 257, "samples_count": 8256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718003, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07886576652526855}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 258, "samples_count": 8288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718083, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08043694496154785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 259, "samples_count": 8320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718163, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0797736644744873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 260, "samples_count": 8352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718241, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07818078994750977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 261, "samples_count": 8384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718320, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07850170135498047}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 262, "samples_count": 8416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718399, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07901620864868164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 263, "samples_count": 8448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718483, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08371758460998535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 264, "samples_count": 8480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718562, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07987189292907715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 265, "samples_count": 8512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718645, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08269047737121582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 266, "samples_count": 8544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08537936210632324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 267, "samples_count": 8576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718809, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07886767387390137}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 268, "samples_count": 8608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718890, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08049631118774414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 269, "samples_count": 8640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899718969, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07884907722473145}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 270, "samples_count": 8672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719048, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07920145988464355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 271, "samples_count": 8704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719129, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08150649070739746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 272, "samples_count": 8736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719211, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08184671401977539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 273, "samples_count": 8768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719291, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07979655265808105}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 274, "samples_count": 8800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08234810829162598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 275, "samples_count": 8832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719453, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0791623592376709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 276, "samples_count": 8864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719536, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08344268798828125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 277, "samples_count": 8896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719618, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08189034461975098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 278, "samples_count": 8928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07835626602172852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 279, "samples_count": 8960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07979011535644531}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 280, "samples_count": 8992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08172893524169922}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 281, "samples_count": 9024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899719939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0815732479095459}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 282, "samples_count": 9056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720021, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08121681213378906}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 283, "samples_count": 9088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720100, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07907891273498535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 284, "samples_count": 9120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720181, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.081329345703125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 285, "samples_count": 9152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720262, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08114051818847656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 286, "samples_count": 9184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08383536338806152}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 287, "samples_count": 9216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720347, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.524376630783081, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 110592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720347, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.6078281418886036}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720347, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 110592, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899720347, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899728937, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2658524513244629, "reduced_train_loss": 3.5496978759765625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3487.0, "samples_count": 111616.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899737523, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26909899711608887, "reduced_train_loss": 3.4979774951934814}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3519.0, "samples_count": 112640.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899746113, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26904296875, "reduced_train_loss": 3.4612302780151367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3551.0, "samples_count": 113664.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899754696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2693326473236084, "reduced_train_loss": 3.5599803924560547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3583.0, "samples_count": 114688.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899763278, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27426600456237793, "reduced_train_loss": 3.396909713745117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3615.0, "samples_count": 115712.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899771855, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2706263065338135, "reduced_train_loss": 3.573291301727295}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3647.0, "samples_count": 116736.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899780434, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2695450782775879, "reduced_train_loss": 3.6226460933685303}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3679.0, "samples_count": 117760.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899789020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2693338394165039, "reduced_train_loss": 3.515331983566284}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3711.0, "samples_count": 118784.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899797611, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2655642032623291, "reduced_train_loss": 3.435725212097168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3743.0, "samples_count": 119808.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899806182, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2651097774505615, "reduced_train_loss": 3.472609043121338}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3775.0, "samples_count": 120832.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899814786, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.270693302154541, "reduced_train_loss": 3.462259292602539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3807.0, "samples_count": 121856.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899823354, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2683830261230469, "reduced_train_loss": 3.545783519744873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3839.0, "samples_count": 122880.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899823891, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26964580953426776}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899823892, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899823892, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 122880, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899823989, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6355092525482178}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 288, "samples_count": 9248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824068, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07870340347290039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 289, "samples_count": 9280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824146, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07806849479675293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 290, "samples_count": 9312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824225, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07865619659423828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 291, "samples_count": 9344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824304, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07929611206054688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 292, "samples_count": 9376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07995223999023438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 293, "samples_count": 9408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824463, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0788567066192627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 294, "samples_count": 9440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07735157012939453}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 295, "samples_count": 9472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824627, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08655333518981934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 296, "samples_count": 9504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824713, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08651852607727051}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 297, "samples_count": 9536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824792, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07917523384094238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 298, "samples_count": 9568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824872, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07929015159606934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 299, "samples_count": 9600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899824952, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08074784278869629}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 300, "samples_count": 9632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825033, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08080649375915527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 301, "samples_count": 9664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825114, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08139824867248535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 302, "samples_count": 9696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825194, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0791316032409668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 303, "samples_count": 9728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07948184013366699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 304, "samples_count": 9760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825353, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0803072452545166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 305, "samples_count": 9792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825433, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07930111885070801}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 306, "samples_count": 9824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08267927169799805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 307, "samples_count": 9856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825600, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08452677726745605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 308, "samples_count": 9888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825681, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08107972145080566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 309, "samples_count": 9920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825764, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08274292945861816}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 310, "samples_count": 9952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07824468612670898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 311, "samples_count": 9984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899825924, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08206868171691895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 312, "samples_count": 10016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07981634140014648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 313, "samples_count": 10048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826084, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08029842376708984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 314, "samples_count": 10080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826165, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08104968070983887}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 315, "samples_count": 10112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826245, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08018136024475098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 316, "samples_count": 10144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08183169364929199}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 317, "samples_count": 10176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07959246635437012}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 318, "samples_count": 10208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08039259910583496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 319, "samples_count": 10240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826488, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.479379177093506, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 122880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826488, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.597298505017534}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826488, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 122880, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899826488, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899835064, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26695871353149414, "reduced_train_loss": 3.5205812454223633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3871.0, "samples_count": 123904.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899843641, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26371026039123535, "reduced_train_loss": 3.5145938396453857}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3903.0, "samples_count": 124928.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899852247, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.264070987701416, "reduced_train_loss": 3.47812819480896}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3935.0, "samples_count": 125952.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899860845, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26588964462280273, "reduced_train_loss": 3.5471439361572266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3967.0, "samples_count": 126976.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899869429, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2676661014556885, "reduced_train_loss": 3.43497633934021}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 3999.0, "samples_count": 128000.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899878027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26955103874206543, "reduced_train_loss": 3.4401042461395264}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4031.0, "samples_count": 129024.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899886623, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2692739963531494, "reduced_train_loss": 3.565695285797119}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4063.0, "samples_count": 130048.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899895211, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2663395404815674, "reduced_train_loss": 3.4029269218444824}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4095.0, "samples_count": 131072.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899903812, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26946091651916504, "reduced_train_loss": 3.45998215675354}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4127.0, "samples_count": 132096.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899912389, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26448702812194824, "reduced_train_loss": 3.429155111312866}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4159.0, "samples_count": 133120.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899920972, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2641410827636719, "reduced_train_loss": 3.4748635292053223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4191.0, "samples_count": 134144.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899929550, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2680201530456543, "reduced_train_loss": 3.4643588066101074}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4223.0, "samples_count": 135168.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930079, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2697688714918816}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930080, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930080, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 135168, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930199, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6496965885162354}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 320, "samples_count": 10272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930279, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07985734939575195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 321, "samples_count": 10304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930357, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0780339241027832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 322, "samples_count": 10336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930437, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07956814765930176}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 323, "samples_count": 10368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07867622375488281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 324, "samples_count": 10400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930594, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07888484001159668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 325, "samples_count": 10432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07859611511230469}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 326, "samples_count": 10464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08179163932800293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 327, "samples_count": 10496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930834, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07989335060119629}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 328, "samples_count": 10528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930917, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08291029930114746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 329, "samples_count": 10560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899930997, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07948040962219238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 330, "samples_count": 10592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08050131797790527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 331, "samples_count": 10624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931157, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07950115203857422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 332, "samples_count": 10656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931239, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08270812034606934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 333, "samples_count": 10688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931322, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08295392990112305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 334, "samples_count": 10720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931401, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07845091819763184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 335, "samples_count": 10752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931484, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08315324783325195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 336, "samples_count": 10784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931564, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07959318161010742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 337, "samples_count": 10816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931645, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0815432071685791}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 338, "samples_count": 10848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931725, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08010029792785645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 339, "samples_count": 10880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931805, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08006763458251953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 340, "samples_count": 10912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08159494400024414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 341, "samples_count": 10944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899931966, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07925057411193848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 342, "samples_count": 10976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07968640327453613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 343, "samples_count": 11008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932126, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08047199249267578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 344, "samples_count": 11040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932206, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07975196838378906}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 345, "samples_count": 11072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932287, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08076357841491699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 346, "samples_count": 11104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932367, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07990789413452148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 347, "samples_count": 11136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932446, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07960700988769531}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 348, "samples_count": 11168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932527, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08050847053527832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 349, "samples_count": 11200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932610, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08327817916870117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 350, "samples_count": 11232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932690, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0795283317565918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 351, "samples_count": 11264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932690, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.4423129558563232, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 135168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932691, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.611258267890662}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932691, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 135168, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899932691, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899941268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2679612636566162, "reduced_train_loss": 3.3590195178985596}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4255.0, "samples_count": 136192.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899949852, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26589488983154297, "reduced_train_loss": 3.4910430908203125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4287.0, "samples_count": 137216.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899958448, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26766109466552734, "reduced_train_loss": 3.3792624473571777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4319.0, "samples_count": 138240.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899967040, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2671799659729004, "reduced_train_loss": 3.3296563625335693}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4351.0, "samples_count": 139264.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899975624, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2731304168701172, "reduced_train_loss": 3.378267526626587}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4383.0, "samples_count": 140288.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899984245, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2704765796661377, "reduced_train_loss": 3.4238710403442383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4415.0, "samples_count": 141312.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759899992819, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2709202766418457, "reduced_train_loss": 3.4399256706237793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4447.0, "samples_count": 142336.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900001407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26704907417297363, "reduced_train_loss": 3.4567854404449463}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4479.0, "samples_count": 143360.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900010004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.268829345703125, "reduced_train_loss": 3.398932933807373}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4511.0, "samples_count": 144384.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900018586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2659437656402588, "reduced_train_loss": 3.4281399250030518}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4543.0, "samples_count": 145408.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900027190, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2727019786834717, "reduced_train_loss": 3.3487939834594727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4575.0, "samples_count": 146432.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900035793, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2667577266693115, "reduced_train_loss": 3.367260456085205}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4607.0, "samples_count": 147456.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036334, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26990475831007643}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036335, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036335, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 147456, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036421, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6280946731567383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 352, "samples_count": 11296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036499, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0776360034942627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 353, "samples_count": 11328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07839107513427734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 354, "samples_count": 11360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0790402889251709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 355, "samples_count": 11392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036735, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07857155799865723}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 356, "samples_count": 11424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036815, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08061575889587402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 357, "samples_count": 11456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036892, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07719135284423828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 358, "samples_count": 11488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900036972, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07917904853820801}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 359, "samples_count": 11520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037053, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08110928535461426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 360, "samples_count": 11552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037135, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08270502090454102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 361, "samples_count": 11584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08064770698547363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 362, "samples_count": 11616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08176207542419434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 363, "samples_count": 11648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037377, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0788114070892334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 364, "samples_count": 11680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037457, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08045196533203125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 365, "samples_count": 11712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037537, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0802912712097168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 366, "samples_count": 11744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037617, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07952022552490234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 367, "samples_count": 11776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037697, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07999253273010254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 368, "samples_count": 11808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07967782020568848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 369, "samples_count": 11840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08130931854248047}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 370, "samples_count": 11872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900037938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08026742935180664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 371, "samples_count": 11904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038017, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07907938957214355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 372, "samples_count": 11936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038097, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07944512367248535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 373, "samples_count": 11968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038177, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08077764511108398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 374, "samples_count": 12000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038257, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07981038093566895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 375, "samples_count": 12032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07904171943664551}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 376, "samples_count": 12064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038417, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08040523529052734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 377, "samples_count": 12096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038496, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07927536964416504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 378, "samples_count": 12128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08170080184936523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 379, "samples_count": 12160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038658, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08040881156921387}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 380, "samples_count": 12192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07965350151062012}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 381, "samples_count": 12224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038817, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07941675186157227}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 382, "samples_count": 12256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07894229888916016}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 383, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038897, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.415541410446167, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 147456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038897, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.5629066310357302}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038897, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 147456, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900038897, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900047494, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2718229293823242, "reduced_train_loss": 3.4290335178375244}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4639.0, "samples_count": 148480.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900056097, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27068138122558594, "reduced_train_loss": 3.412788152694702}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4671.0, "samples_count": 149504.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900064701, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2737851142883301, "reduced_train_loss": 3.3799960613250732}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4703.0, "samples_count": 150528.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900073272, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27002835273742676, "reduced_train_loss": 3.471520185470581}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4735.0, "samples_count": 151552.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900081883, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27108263969421387, "reduced_train_loss": 3.4429564476013184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4767.0, "samples_count": 152576.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900090480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27330565452575684, "reduced_train_loss": 3.439537525177002}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4799.0, "samples_count": 153600.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900099060, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26583123207092285, "reduced_train_loss": 3.440861701965332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4831.0, "samples_count": 154624.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900107660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2665290832519531, "reduced_train_loss": 3.4169344902038574}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4863.0, "samples_count": 155648.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900116264, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2661728858947754, "reduced_train_loss": 3.3720288276672363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4895.0, "samples_count": 156672.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900124842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2671535015106201, "reduced_train_loss": 3.3689472675323486}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4927.0, "samples_count": 157696.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900133435, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26760220527648926, "reduced_train_loss": 3.348621129989624}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4959.0, "samples_count": 158720.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142024, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.270801305770874, "reduced_train_loss": 3.3395841121673584}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 4991.0, "samples_count": 159744.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142572, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2699859241068528}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142572, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142573, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 159744, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142657, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6327738761901855}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 384, "samples_count": 12320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142735, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07840371131896973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 385, "samples_count": 12352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142814, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07894420623779297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 386, "samples_count": 12384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07940864562988281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 387, "samples_count": 12416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900142971, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07791900634765625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 388, "samples_count": 12448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143051, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07956433296203613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 389, "samples_count": 12480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143130, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0790095329284668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 390, "samples_count": 12512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143207, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07732176780700684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 391, "samples_count": 12544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143290, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08254265785217285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 392, "samples_count": 12576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143371, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08182621002197266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 393, "samples_count": 12608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143452, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08048439025878906}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 394, "samples_count": 12640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143533, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08069992065429688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 395, "samples_count": 12672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143612, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07965397834777832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 396, "samples_count": 12704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143692, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07977676391601562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 397, "samples_count": 12736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143773, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08076310157775879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 398, "samples_count": 12768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143853, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08055853843688965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 399, "samples_count": 12800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900143932, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07908892631530762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 400, "samples_count": 12832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144013, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08097577095031738}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 401, "samples_count": 12864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144095, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0812234878540039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 402, "samples_count": 12896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144174, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07912230491638184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 403, "samples_count": 12928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144254, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08047652244567871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 404, "samples_count": 12960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144334, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0799262523651123}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 405, "samples_count": 12992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144414, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08028960227966309}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 406, "samples_count": 13024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144495, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0804443359375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 407, "samples_count": 13056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144574, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07895135879516602}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 408, "samples_count": 13088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144654, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08046936988830566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 409, "samples_count": 13120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144734, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07995462417602539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 410, "samples_count": 13152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144815, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0808858871459961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 411, "samples_count": 13184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144894, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07910680770874023}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 412, "samples_count": 13216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900144975, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08025503158569336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 413, "samples_count": 13248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900145057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08199381828308105}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 414, "samples_count": 13280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900145138, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08143186569213867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 415, "samples_count": 13312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900145139, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.3863987922668457, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 159744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900145139, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.5673958980478346}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900145139, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 159744, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900145139, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900153753, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2724337577819824, "reduced_train_loss": 3.3699493408203125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5023.0, "samples_count": 160768.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900162329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26647233963012695, "reduced_train_loss": 3.40433931350708}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5055.0, "samples_count": 161792.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900170924, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26828765869140625, "reduced_train_loss": 3.330070972442627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5087.0, "samples_count": 162816.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900179513, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27091121673583984, "reduced_train_loss": 3.31878662109375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5119.0, "samples_count": 163840.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900188107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27228569984436035, "reduced_train_loss": 3.3660244941711426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5151.0, "samples_count": 164864.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900196727, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27194952964782715, "reduced_train_loss": 3.4169771671295166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5183.0, "samples_count": 165888.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900205304, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26861071586608887, "reduced_train_loss": 3.4477646350860596}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5215.0, "samples_count": 166912.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900213884, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.266704797744751, "reduced_train_loss": 3.3725032806396484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5247.0, "samples_count": 167936.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900222467, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2678868770599365, "reduced_train_loss": 3.402581214904785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5279.0, "samples_count": 168960.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900231042, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26601076126098633, "reduced_train_loss": 3.431403636932373}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5311.0, "samples_count": 169984.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900239615, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26680946350097656, "reduced_train_loss": 3.342792510986328}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5343.0, "samples_count": 171008.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900248218, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26795363426208496, "reduced_train_loss": 3.436568260192871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5375.0, "samples_count": 172032.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900248771, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2698739297393331}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900248772, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900248772, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 172032, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900248855, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6375575065612793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 416, "samples_count": 13344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900248933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07824873924255371}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 417, "samples_count": 13376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249011, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07779717445373535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 418, "samples_count": 13408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249091, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07977771759033203}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 419, "samples_count": 13440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249170, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07948684692382812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 420, "samples_count": 13472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249251, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08045625686645508}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 421, "samples_count": 13504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249330, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07960891723632812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 422, "samples_count": 13536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249409, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07843327522277832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 423, "samples_count": 13568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08159160614013672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 424, "samples_count": 13600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249572, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08139300346374512}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 425, "samples_count": 13632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249652, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08040547370910645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 426, "samples_count": 13664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249734, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08133554458618164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 427, "samples_count": 13696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249813, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07938814163208008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 428, "samples_count": 13728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07960796356201172}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 429, "samples_count": 13760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900249974, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08098649978637695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 430, "samples_count": 13792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250054, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0808408260345459}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 431, "samples_count": 13824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250135, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0806436538696289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 432, "samples_count": 13856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08054137229919434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 433, "samples_count": 13888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250296, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08091545104980469}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 434, "samples_count": 13920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250378, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08153915405273438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 435, "samples_count": 13952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250459, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08110642433166504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 436, "samples_count": 13984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250539, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07975435256958008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 437, "samples_count": 14016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08123254776000977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 438, "samples_count": 14048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250700, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07938599586486816}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 439, "samples_count": 14080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250782, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08275365829467773}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 440, "samples_count": 14112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250863, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08028984069824219}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 441, "samples_count": 14144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900250943, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08035922050476074}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 442, "samples_count": 14176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251024, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08099222183227539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 443, "samples_count": 14208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251103, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0792701244354248}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 444, "samples_count": 14240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0816354751586914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 445, "samples_count": 14272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251267, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08172821998596191}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 446, "samples_count": 14304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251347, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08086085319519043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 447, "samples_count": 14336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251348, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.3735735416412354, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 172032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251348, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.57772111101076}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251348, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 172032, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900251348, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900259967, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2680699825286865, "reduced_train_loss": 3.2623159885406494}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5407.0, "samples_count": 173056.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900268552, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.267822265625, "reduced_train_loss": 3.3559658527374268}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5439.0, "samples_count": 174080.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900277146, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27230358123779297, "reduced_train_loss": 3.247532844543457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5471.0, "samples_count": 175104.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900285729, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26443028450012207, "reduced_train_loss": 3.4621245861053467}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5503.0, "samples_count": 176128.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900294317, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.265122652053833, "reduced_train_loss": 3.360027551651001}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5535.0, "samples_count": 177152.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900302886, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2653472423553467, "reduced_train_loss": 3.2470028400421143}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5567.0, "samples_count": 178176.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900311470, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26488351821899414, "reduced_train_loss": 3.334536552429199}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5599.0, "samples_count": 179200.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900320053, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2683687210083008, "reduced_train_loss": 3.2843174934387207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5631.0, "samples_count": 180224.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900328634, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2701575756072998, "reduced_train_loss": 3.323636531829834}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5663.0, "samples_count": 181248.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900337224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2666923999786377, "reduced_train_loss": 3.3645551204681396}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5695.0, "samples_count": 182272.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900345823, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2678196430206299, "reduced_train_loss": 3.3111021518707275}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5727.0, "samples_count": 183296.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900354399, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26848912239074707, "reduced_train_loss": 3.3227579593658447}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5759.0, "samples_count": 184320.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900354933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26975169746886724}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900354934, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900354934, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 184320, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355035, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6359610557556152}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 448, "samples_count": 14368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355116, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08091235160827637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 449, "samples_count": 14400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355194, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07865118980407715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 450, "samples_count": 14432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07813262939453125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 451, "samples_count": 14464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355350, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07781100273132324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 452, "samples_count": 14496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355429, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07852625846862793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 453, "samples_count": 14528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355508, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07966852188110352}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 454, "samples_count": 14560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355591, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08238363265991211}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 455, "samples_count": 14592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08166241645812988}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 456, "samples_count": 14624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355753, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08000779151916504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 457, "samples_count": 14656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355835, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08208060264587402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 458, "samples_count": 14688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07900381088256836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 459, "samples_count": 14720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900355994, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07991695404052734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 460, "samples_count": 14752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356074, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08089256286621094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 461, "samples_count": 14784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356153, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07899355888366699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 462, "samples_count": 14816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356233, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07962441444396973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 463, "samples_count": 14848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356314, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08066964149475098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 464, "samples_count": 14880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356396, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08209371566772461}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 465, "samples_count": 14912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356476, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08018994331359863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 466, "samples_count": 14944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08099818229675293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 467, "samples_count": 14976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0802466869354248}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 468, "samples_count": 15008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356718, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08032774925231934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 469, "samples_count": 15040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356798, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08038496971130371}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 470, "samples_count": 15072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07910585403442383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 471, "samples_count": 15104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900356959, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08149886131286621}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 472, "samples_count": 15136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357038, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07967209815979004}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 473, "samples_count": 15168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07870864868164062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 474, "samples_count": 15200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357198, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08095908164978027}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 475, "samples_count": 15232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357277, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07951998710632324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 476, "samples_count": 15264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08147954940795898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 477, "samples_count": 15296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08085989952087402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 478, "samples_count": 15328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357521, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0810399055480957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 479, "samples_count": 15360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357522, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.344482183456421, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 184320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357522, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.5890169830527157}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357522, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 184320, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900357522, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900366117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26601481437683105, "reduced_train_loss": 3.2690048217773438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5791.0, "samples_count": 185344.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900374691, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26914548873901367, "reduced_train_loss": 3.398434638977051}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5823.0, "samples_count": 186368.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900383261, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27246761322021484, "reduced_train_loss": 3.330488920211792}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5855.0, "samples_count": 187392.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900391845, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27350592613220215, "reduced_train_loss": 3.229004144668579}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5887.0, "samples_count": 188416.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900400416, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2718479633331299, "reduced_train_loss": 3.3753437995910645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5919.0, "samples_count": 189440.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900408992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26925134658813477, "reduced_train_loss": 3.2923381328582764}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5951.0, "samples_count": 190464.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900417569, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27067995071411133, "reduced_train_loss": 3.4058444499969482}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 5983.0, "samples_count": 191488.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900426158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26759815216064453, "reduced_train_loss": 3.399796485900879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6015.0, "samples_count": 192512.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900434754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26441335678100586, "reduced_train_loss": 3.2903947830200195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6047.0, "samples_count": 193536.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900443322, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2663533687591553, "reduced_train_loss": 3.3170979022979736}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6079.0, "samples_count": 194560.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900451914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2719690799713135, "reduced_train_loss": 3.328550100326538}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6111.0, "samples_count": 195584.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900460489, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26567697525024414, "reduced_train_loss": 3.247079610824585}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6143.0, "samples_count": 196608.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.269549254351053}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461030, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461030, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 196608, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461133, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.643841028213501}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 480, "samples_count": 15392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461211, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07858443260192871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 481, "samples_count": 15424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461291, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0801079273223877}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 482, "samples_count": 15456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461370, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07921218872070312}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 483, "samples_count": 15488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461448, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07778215408325195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 484, "samples_count": 15520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461527, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07867836952209473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 485, "samples_count": 15552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08003950119018555}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 486, "samples_count": 15584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461687, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08040237426757812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 487, "samples_count": 15616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461768, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08093619346618652}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 488, "samples_count": 15648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461850, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08177018165588379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 489, "samples_count": 15680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900461929, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07921910285949707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 490, "samples_count": 15712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462013, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08376073837280273}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 491, "samples_count": 15744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462097, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08416366577148438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 492, "samples_count": 15776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462176, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07861208915710449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 493, "samples_count": 15808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0821542739868164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 494, "samples_count": 15840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462339, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08091497421264648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 495, "samples_count": 15872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462418, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07918906211853027}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 496, "samples_count": 15904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07927989959716797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 497, "samples_count": 15936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0810859203338623}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 498, "samples_count": 15968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08043980598449707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 499, "samples_count": 16000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0803980827331543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 500, "samples_count": 16032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462820, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0812387466430664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 501, "samples_count": 16064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462903, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08231210708618164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 502, "samples_count": 16096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900462983, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0798799991607666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 503, "samples_count": 16128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463063, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08001470565795898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 504, "samples_count": 16160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463142, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0793006420135498}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 505, "samples_count": 16192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463223, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08144354820251465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 506, "samples_count": 16224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463303, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07996964454650879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 507, "samples_count": 16256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463385, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08173966407775879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 508, "samples_count": 16288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07921934127807617}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 509, "samples_count": 16320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463544, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.079498291015625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 510, "samples_count": 16352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463626, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08211112022399902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 511, "samples_count": 16384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463627, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.3204379081726074, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 196608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463627, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.5980510180816054}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463627, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 196608, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900463627, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900472206, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27172088623046875, "reduced_train_loss": 3.2267112731933594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6175.0, "samples_count": 197632.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900480781, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2646164894104004, "reduced_train_loss": 3.3003997802734375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6207.0, "samples_count": 198656.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900489372, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26813650131225586, "reduced_train_loss": 3.3614416122436523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6239.0, "samples_count": 199680.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900497967, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2676231861114502, "reduced_train_loss": 3.311504364013672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6271.0, "samples_count": 200704.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900506550, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26624274253845215, "reduced_train_loss": 3.3114993572235107}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6303.0, "samples_count": 201728.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900515149, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27024054527282715, "reduced_train_loss": 3.299960136413574}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6335.0, "samples_count": 202752.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900523735, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2709956169128418, "reduced_train_loss": 3.2869696617126465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6367.0, "samples_count": 203776.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900532308, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2715878486633301, "reduced_train_loss": 3.339911460876465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6399.0, "samples_count": 204800.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900540893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2666606903076172, "reduced_train_loss": 3.255216360092163}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6431.0, "samples_count": 205824.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900549495, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2702364921569824, "reduced_train_loss": 3.4529037475585938}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6463.0, "samples_count": 206848.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900558081, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2684500217437744, "reduced_train_loss": 3.2607038021087646}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6495.0, "samples_count": 207872.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900566650, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26726698875427246, "reduced_train_loss": 3.3204362392425537}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6527.0, "samples_count": 208896.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567235, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2698126719818295}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567236, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 6528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567237, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 208896, "step": 6528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567320, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6702606678009033}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 512, "samples_count": 16416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567400, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08036041259765625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 513, "samples_count": 16448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567479, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07912445068359375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 514, "samples_count": 16480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567558, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0785224437713623}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 515, "samples_count": 16512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08016633987426758}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 516, "samples_count": 16544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567718, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0798947811126709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 517, "samples_count": 16576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567796, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07798528671264648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 518, "samples_count": 16608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567876, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08018755912780762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 519, "samples_count": 16640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900567958, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08207392692565918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 520, "samples_count": 16672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568039, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08071279525756836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 521, "samples_count": 16704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07982254028320312}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 522, "samples_count": 16736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568198, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07913398742675781}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 523, "samples_count": 16768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568278, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08069396018981934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 524, "samples_count": 16800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568360, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08108830451965332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 525, "samples_count": 16832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07955598831176758}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 526, "samples_count": 16864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568520, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08051609992980957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 527, "samples_count": 16896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568599, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07920074462890625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 528, "samples_count": 16928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568679, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07987451553344727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 529, "samples_count": 16960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568759, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08034849166870117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 530, "samples_count": 16992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568840, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0813755989074707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 531, "samples_count": 17024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900568921, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0804295539855957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 532, "samples_count": 17056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569001, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08058857917785645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 533, "samples_count": 17088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569081, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08001518249511719}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 534, "samples_count": 17120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569161, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07967829704284668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 535, "samples_count": 17152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569243, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08190488815307617}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 536, "samples_count": 17184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08414244651794434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 537, "samples_count": 17216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569406, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07879304885864258}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 538, "samples_count": 17248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569486, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07997560501098633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 539, "samples_count": 17280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569567, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08089566230773926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 540, "samples_count": 17312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08117556571960449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 541, "samples_count": 17344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569729, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08072638511657715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 542, "samples_count": 17376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569810, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08134031295776367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 543, "samples_count": 17408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569811, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.307371139526367, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 208896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569811, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.57604884612374}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 6528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569811, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 208896, "step": 6528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900569811, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 6528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900578409, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26917171478271484, "reduced_train_loss": 3.256432056427002}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6559.0, "samples_count": 209920.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900586999, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2672102451324463, "reduced_train_loss": 3.2475264072418213}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6591.0, "samples_count": 210944.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900595571, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26709628105163574, "reduced_train_loss": 3.2331464290618896}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6623.0, "samples_count": 211968.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900604147, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.270244836807251, "reduced_train_loss": 4.007317543029785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6655.0, "samples_count": 212992.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900612722, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26862430572509766, "reduced_train_loss": 3.3391404151916504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6687.0, "samples_count": 214016.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900621300, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2663595676422119, "reduced_train_loss": 3.3568756580352783}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6719.0, "samples_count": 215040.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900629880, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2732276916503906, "reduced_train_loss": 3.2587711811065674}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6751.0, "samples_count": 216064.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900638470, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26979684829711914, "reduced_train_loss": 3.3049733638763428}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6783.0, "samples_count": 217088.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900647042, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26764512062072754, "reduced_train_loss": 3.313361883163452}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6815.0, "samples_count": 218112.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900655622, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2663874626159668, "reduced_train_loss": 3.2952466011047363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6847.0, "samples_count": 219136.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900664208, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2712423801422119, "reduced_train_loss": 3.296755313873291}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6879.0, "samples_count": 220160.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900672782, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2646327018737793, "reduced_train_loss": 3.3554649353027344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6911.0, "samples_count": 221184.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2695779644400318}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673330, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 6912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673330, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 221184, "step": 6912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673452, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.670433759689331}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 544, "samples_count": 17440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673529, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07738351821899414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 545, "samples_count": 17472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07837319374084473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 546, "samples_count": 17504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673687, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07999706268310547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 547, "samples_count": 17536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673766, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07806968688964844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 548, "samples_count": 17568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673844, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07824015617370605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 549, "samples_count": 17600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900673923, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0788424015045166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 550, "samples_count": 17632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674005, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0827176570892334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 551, "samples_count": 17664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674088, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08304619789123535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 552, "samples_count": 17696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07935333251953125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 553, "samples_count": 17728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674247, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07972598075866699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 554, "samples_count": 17760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07938718795776367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 555, "samples_count": 17792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08023691177368164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 556, "samples_count": 17824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08003783226013184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 557, "samples_count": 17856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674568, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08086013793945312}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 558, "samples_count": 17888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674650, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08200454711914062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 559, "samples_count": 17920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674729, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0788567066192627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 560, "samples_count": 17952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674810, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08093142509460449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 561, "samples_count": 17984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674889, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07915973663330078}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 562, "samples_count": 18016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900674970, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08081364631652832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 563, "samples_count": 18048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675049, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07930326461791992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 564, "samples_count": 18080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675127, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07833099365234375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 565, "samples_count": 18112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675208, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0803532600402832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 566, "samples_count": 18144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675290, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0819697380065918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 567, "samples_count": 18176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675371, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08149933815002441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 568, "samples_count": 18208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675452, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08067154884338379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 569, "samples_count": 18240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675531, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07934856414794922}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 570, "samples_count": 18272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675613, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08150315284729004}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 571, "samples_count": 18304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675694, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08078384399414062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 572, "samples_count": 18336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675775, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08147120475769043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 573, "samples_count": 18368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675855, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07968783378601074}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 574, "samples_count": 18400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675935, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07994461059570312}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 575, "samples_count": 18432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675935, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.313727378845215, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 221184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675936, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.6066891939844936}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 6912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675936, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 221184, "step": 6912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900675936, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 12288, "step": 6912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900684514, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26566314697265625, "reduced_train_loss": 3.3485007286071777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6943.0, "samples_count": 222208.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900693096, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26873040199279785, "reduced_train_loss": 3.2537903785705566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 6975.0, "samples_count": 223232.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900701674, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26591920852661133, "reduced_train_loss": 3.2933709621429443}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7007.0, "samples_count": 224256.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900710243, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2678232192993164, "reduced_train_loss": 3.3245468139648438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7039.0, "samples_count": 225280.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900718830, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26929521560668945, "reduced_train_loss": 3.3245058059692383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7071.0, "samples_count": 226304.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900727413, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2677791118621826, "reduced_train_loss": 3.220644474029541}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7103.0, "samples_count": 227328.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900735973, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2670469284057617, "reduced_train_loss": 3.241070032119751}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7135.0, "samples_count": 228352.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900744554, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2671356201171875, "reduced_train_loss": 3.3795907497406006}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7167.0, "samples_count": 229376.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900753114, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.27024102210998535, "reduced_train_loss": 3.2640483379364014}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7199.0, "samples_count": 230400.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900761680, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.269702672958374, "reduced_train_loss": 3.3060879707336426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7231.0, "samples_count": 231424.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900770276, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.2636442184448242, "reduced_train_loss": 3.2295103073120117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7263.0, "samples_count": 232448.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900778882, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26882147789001465, "reduced_train_loss": 3.1931209564208984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 7295.0, "samples_count": 233472.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779434, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.26952659105457616}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779435, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 12288, "step": 7296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779435, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 233472, "step": 7296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779522, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.6405172348022461}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 576, "samples_count": 18464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779603, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08107304573059082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 577, "samples_count": 18496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779680, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07687973976135254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 578, "samples_count": 18528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779757, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07678627967834473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 579, "samples_count": 18560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779836, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07880306243896484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 580, "samples_count": 18592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07907915115356445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 581, "samples_count": 18624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900779994, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07882452011108398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 582, "samples_count": 18656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780073, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07966041564941406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 583, "samples_count": 18688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08066320419311523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 584, "samples_count": 18720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780236, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08167362213134766}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 585, "samples_count": 18752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780315, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07978534698486328}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 586, "samples_count": 18784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780397, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08118605613708496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 587, "samples_count": 18816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780477, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0805504322052002}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 588, "samples_count": 18848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08011746406555176}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 589, "samples_count": 18880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08019089698791504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 590, "samples_count": 18912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780719, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08118057250976562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 591, "samples_count": 18944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780800, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08095669746398926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 592, "samples_count": 18976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780881, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08194994926452637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 593, "samples_count": 19008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900780964, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08291387557983398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 594, "samples_count": 19040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07961177825927734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 595, "samples_count": 19072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781124, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08038759231567383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 596, "samples_count": 19104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781206, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08198976516723633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 597, "samples_count": 19136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781288, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08115148544311523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 598, "samples_count": 19168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781367, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07922816276550293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 599, "samples_count": 19200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781448, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08152103424072266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 600, "samples_count": 19232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781528, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0792696475982666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 601, "samples_count": 19264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781608, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08012127876281738}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 602, "samples_count": 19296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781687, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07964682579040527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 603, "samples_count": 19328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781768, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08086681365966797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 604, "samples_count": 19360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781848, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07999897003173828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 605, "samples_count": 19392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900781928, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.07996201515197754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 606, "samples_count": 19424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900782009, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08050942420959473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 480, "step": 607, "samples_count": 19456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900782009, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.2765328884124756, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 233472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900782010, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.575834824005142}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 7296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1759900782010, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 233472, "step": 7296}}
 0: Average train_step_time 0.26822549085083763
 0: :::MLLOG {"namespace": "", "time_ms": 1759900782051, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 106, "step": 7296, "samples_count": 233472, "status": "success"}}
++ date +%s
+ echo 'RUNANDTIME_STOP 1759900835'
RUNANDTIME_STOP 1759900835
+ set -e
