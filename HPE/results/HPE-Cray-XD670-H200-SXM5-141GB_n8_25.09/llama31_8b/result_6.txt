+ echo 'Beginning trial 04 of 11'
Beginning trial 04 of 11
+ echo ':::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv51-llama31_8b-amd-20250908.nemo.sqsh 14057 8 sith[1-8] HPE Cray XD670 XD670_8x8x1xtp1pp1cp2_8b-trial'
:::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv51-llama31_8b-amd-20250908.nemo.sqsh 14057 8 sith[1-8] HPE Cray XD670 XD670_8x8x1xtp1pp1cp2_8b-trial
++ srun -N1 -n1 --container-name=llama31_8b_14057 --no-container-mount-home --container-remap-root --container-writable mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.08","framework_name":"","other_software_stack":{"cuda_version":"13.0.0.044","cuda_driver_version":"580.65.06","nccl_version":"2.27.7-fix-v2.28.3-1","cublas_version":"13.0.0.19","cudnn_version":"9.12.0.46","trt_version":"10.13.2.6","dali_version":"1.51.2","mofed_version":"5.4-rdmacore56.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.08","framework_name":"","other_software_stack":{"cuda_version":"13.0.0.044","cuda_driver_version":"580.65.06","nccl_version":"2.27.7-fix-v2.28.3-1","cublas_version":"13.0.0.19","cudnn_version":"9.12.0.46","trt_version":"10.13.2.6","dali_version":"1.51.2","mofed_version":"5.4-rdmacore56.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=llama31_8b_14057 --no-container-mount-home --container-remap-root --container-writable bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID b2b724a3a3a8af79d3a610b3d3a6f85c7f9869e6 
+ export SEED=31623
+ SEED=31623
+ '[' 1 -eq 1 ']'
+ srun --ntasks-per-node=1 bash -c '
                 host=$(hostname)
                 echo "$host sync_start"
                 sync && echo "$host sync_done"
                 cache_before=$(awk "/^Cached:/ {print \$2}" /proc/meminfo)
                 sudo /usr/local/bin/drop_cache
                 cache_after=$(awk "/^Cached:/ {print \$2}" /proc/meminfo)
                 echo "$host cache_cleared ${cache_before}kB to ${cache_after}kB"
            '
sith4 sync_start
sith4 sync_start
sith4 sync_start
sith4 sync_start
sith4 sync_start
sith4 sync_start
sith4 sync_start
sith4 sync_start
sith4 sync_done
sith4 sync_done
sith4 sync_done
sith4 sync_done
sith4 sync_done
sith4 sync_done
sith4 sync_done
sith4 sync_done
sith4 cache_cleared 7593468kB to 1906208kB
sith4 cache_cleared 7593468kB to 1906208kB
sith4 cache_cleared 7593468kB to 1906208kB
sith4 cache_cleared 7593468kB to 1906208kB
sith4 cache_cleared 7593468kB to 1906208kB
sith4 cache_cleared 7593468kB to 1906208kB
sith4 cache_cleared 7593468kB to 1906208kB
sith4 cache_cleared 7593468kB to 1906208kB
+ srun --ntasks-per-node=1 --container-name=llama31_8b_14057 --no-container-mount-home --container-remap-root --container-writable python -c '
from mlperf_common.callbacks import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
:::MLLOG {"namespace": "", "time_ms": 1760105153222, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1760105153222, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1760105153222, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1760105153222, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1760105153231, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1760105153231, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1760105153235, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1760105153241, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1760105154'
RUNANDTIME_START 1760105154
+ SLURM_HOSTFILE=/hpelustre/shruti/MLPerf-5.1-Training-internal-repo/llama3-8b-logs/8-nodes-trial-10-Oct/hostfile.14057.mPI8
+ NV_MLPERF_DEBUG=1
+ srun -l --mpi=pmi2 --ntasks-per-node=8 --distribution=arbitrary --time=60 --container-name=llama31_8b_14057 --no-container-mount-home --container-remap-root --container-writable --container-mounts=/hpelustre/shruti/MLPerf-5.1-Training-internal-repo/llama3-8b-logs/8-nodes-trial-10-Oct:/results,/hpelustre/shruti/MLPerf-5.1-Training-internal-repo/llama3-8b-logs/8-nodes-trial-10-Oct/251010070200228656059_npy_index:/npy_index,/hpelustre/shruti/MLPerf-5.1-Training-internal-repo/llama3-8b-logs/8-nodes-trial-10-Oct/mem_dump:/mem_dump,/hpelustre/SHARED/datasets/MLPERF/training5.1/llama3.1_8b/8b/tokenizer:/workspace/llm/nemo_tokenizer:ro,/hpelustre/SHARED/datasets/MLPERF/training5.1/llama3.1_8b/8b:/preproc_data:ro --container-workdir=/workspace/llm --container-env=MASTER_PORT,MASTER_ADDR,NCCL_SHARP_GROUP_SIZE_THRESH,NCCL_NVLS_ENABLE slurm2pytorch ./run_and_time.sh
 0: slurm2pytorch: MASTER_ADDR=sith1 MASTER_PORT=29500 WORLD_SIZE=64
 8: LOAD_CHECKPOINT=
 8: Hello from: sith2
20: LOAD_CHECKPOINT=
14: LOAD_CHECKPOINT=
 3: LOAD_CHECKPOINT=
 6: LOAD_CHECKPOINT=
19: LOAD_CHECKPOINT=
32: LOAD_CHECKPOINT=
32: Hello from: sith5
 9: LOAD_CHECKPOINT=
35: LOAD_CHECKPOINT=
10: LOAD_CHECKPOINT=
47: LOAD_CHECKPOINT=
23: LOAD_CHECKPOINT=
34: LOAD_CHECKPOINT=
22: LOAD_CHECKPOINT=
12: LOAD_CHECKPOINT=
 0: LOAD_CHECKPOINT=
 0: Hello from: sith1
 0: running LLM benchmark
 0: Extra args:  exp_manager.explicit_log_dir="/results/251010070200228656059"
55: LOAD_CHECKPOINT=
11: LOAD_CHECKPOINT=
15: LOAD_CHECKPOINT=
58: LOAD_CHECKPOINT=
 1: LOAD_CHECKPOINT=
16: LOAD_CHECKPOINT=
16: Hello from: sith3
 2: LOAD_CHECKPOINT=
 4: LOAD_CHECKPOINT=
 5: LOAD_CHECKPOINT=
 7: LOAD_CHECKPOINT=
36: LOAD_CHECKPOINT=
17: LOAD_CHECKPOINT=
18: LOAD_CHECKPOINT=
51: LOAD_CHECKPOINT=
62: LOAD_CHECKPOINT=
37: LOAD_CHECKPOINT=
33: LOAD_CHECKPOINT=
39: LOAD_CHECKPOINT=
38: LOAD_CHECKPOINT=
54: LOAD_CHECKPOINT=
13: LOAD_CHECKPOINT=
61: LOAD_CHECKPOINT=
56: LOAD_CHECKPOINT=
56: Hello from: sith8
60: LOAD_CHECKPOINT=
63: LOAD_CHECKPOINT=
59: LOAD_CHECKPOINT=
57: LOAD_CHECKPOINT=
53: LOAD_CHECKPOINT=
21: LOAD_CHECKPOINT=
48: LOAD_CHECKPOINT=
48: Hello from: sith7
46: LOAD_CHECKPOINT=
40: LOAD_CHECKPOINT=
42: LOAD_CHECKPOINT=
40: Hello from: sith6
49: LOAD_CHECKPOINT=
41: LOAD_CHECKPOINT=
52: LOAD_CHECKPOINT=
45: LOAD_CHECKPOINT=
44: LOAD_CHECKPOINT=
50: LOAD_CHECKPOINT=
43: LOAD_CHECKPOINT=
28: LOAD_CHECKPOINT=
24: LOAD_CHECKPOINT=
24: Hello from: sith4
25: LOAD_CHECKPOINT=
29: LOAD_CHECKPOINT=
30: LOAD_CHECKPOINT=
31: LOAD_CHECKPOINT=
26: LOAD_CHECKPOINT=
27: LOAD_CHECKPOINT=
47: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
32: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
20: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
55: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
33: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
23: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
54: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
19: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
41: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
28: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
16: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
18: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
34: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
44: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
46: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
51: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
53: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
43: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
52: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
17: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
21: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
22: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
48: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
50: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
35: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
49: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
61: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
37: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
56: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
58: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
45: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
39: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
40: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
42: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
36: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
38: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
60: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
62: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
63: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
57: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
59: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
30: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
26: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
24: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
29: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
31: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
25: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
27: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
47: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
47:   warnings.warn(
 0: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:   warnings.warn(
 8: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 8:   warnings.warn(
32: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
32:   warnings.warn(
33: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
33:   warnings.warn(
55: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
55:   warnings.warn(
54: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
54:   warnings.warn(
23: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
23:   warnings.warn(
14: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
14:   warnings.warn(
41: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
41:   warnings.warn(
20: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
20:   warnings.warn(
19: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
19:   warnings.warn(
18: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
18:   warnings.warn(
16: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
16:   warnings.warn(
15: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
15:   warnings.warn(
12: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
12:   warnings.warn(
11: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
11:   warnings.warn(
22: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
22:   warnings.warn(
51: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
51:   warnings.warn(
52: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
52:   warnings.warn(
53: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
53:   warnings.warn(
 9: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 9:   warnings.warn(
10: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
10:   warnings.warn(
13: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
13:   warnings.warn(
44: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
44:   warnings.warn(
43: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
43:   warnings.warn(
46: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
46:   warnings.warn(
48: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
48:   warnings.warn(
35: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
35:   warnings.warn(
34: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
34:   warnings.warn(
17: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
17:   warnings.warn(
50: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
50:   warnings.warn(
49: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
49:   warnings.warn(
21: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
21:   warnings.warn(
38: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
38:   warnings.warn(
36: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
36:   warnings.warn(
39: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
39:   warnings.warn(
 5: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 5:   warnings.warn(
37: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
37:   warnings.warn(
40: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
40:   warnings.warn(
61: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
61:   warnings.warn(
45: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
45:   warnings.warn(
56: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
56:   warnings.warn(
42: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
42:   warnings.warn(
 1: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 1:   warnings.warn(
 6: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 6:   warnings.warn(
 7: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 7:   warnings.warn(
 4: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 4:   warnings.warn(
59: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
59:   warnings.warn(
 3: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 3:   warnings.warn(
60: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
60:   warnings.warn(
 2: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 2:   warnings.warn(
58: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
58:   warnings.warn(
57: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
57:   warnings.warn(
63: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
63:   warnings.warn(
62: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
62:   warnings.warn(
24: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
24:   warnings.warn(
25: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
25:   warnings.warn(
26: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
26:   warnings.warn(
27: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
27:   warnings.warn(
28: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
28:   warnings.warn(
29: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
29:   warnings.warn(
30: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
30:   warnings.warn(
31: /usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
31:   warnings.warn(
 0: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 8: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
32: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
41: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
43: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
38: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 5: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
47: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
45: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
40: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
42: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
44: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
46: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
12: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
13: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
14: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
39: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 9: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
35: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
11: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
15: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
36: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
51: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
48: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
50: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 3: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
52: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 6: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
10: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 1: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 2: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
49: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
55: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
53: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
16: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
33: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
20: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
34: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 4: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 7: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
19: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
23: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
18: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
22: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
21: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
54: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
37: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
17: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
56: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 0: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 0:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 0:     return getattr(imported_module, symbol), True
 0:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 0: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 0: 
 0: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 0:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 0:     return getattr(imported_module, symbol), True
 0:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 0: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 0: 
59: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
57: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 8: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 8:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 8:     return getattr(imported_module, symbol), True
 8:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 8: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 8: 
 8: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 8:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 8:     return getattr(imported_module, symbol), True
 8:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 8: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 8: 
58: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
60: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
63: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
61: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
32: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
32:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
32:     return getattr(imported_module, symbol), True
32:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
32: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
32: 
32: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
32:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
32:     return getattr(imported_module, symbol), True
32:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
32: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
32: 
62: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
41: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
41:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
41:     return getattr(imported_module, symbol), True
41:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
41: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
41: 
41: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
41:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
41:     return getattr(imported_module, symbol), True
41:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
41: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
41: 
43: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
43:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
43:     return getattr(imported_module, symbol), True
43:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
43: 
43: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
43:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
43:     return getattr(imported_module, symbol), True
43:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
43: 
38: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
38:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
38:     return getattr(imported_module, symbol), True
38:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
38: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
38: 
38: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
38:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
38:     return getattr(imported_module, symbol), True
38:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
38: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
38: 
 5: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 5:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 5:     return getattr(imported_module, symbol), True
 5:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 5: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 5: 
 5: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 5:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 5:     return getattr(imported_module, symbol), True
 5:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 5: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 5: 
45: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
45:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
45:     return getattr(imported_module, symbol), True
45:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
45: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
45: 
45: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
45:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
45:     return getattr(imported_module, symbol), True
45:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
45: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
45: 
47: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
47:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
47:     return getattr(imported_module, symbol), True
47:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
47: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
47: 
47: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
47:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
47:     return getattr(imported_module, symbol), True
47:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
47: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
47: 
40: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
40:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
40:     return getattr(imported_module, symbol), True
40:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
40: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
40: 
40: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
40:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
40:     return getattr(imported_module, symbol), True
40:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
40: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
40: 
42: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
42:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
42:     return getattr(imported_module, symbol), True
42:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
42: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
42: 
42: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
42:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
42:     return getattr(imported_module, symbol), True
42:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
42: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
42: 
44: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
44:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
44:     return getattr(imported_module, symbol), True
44:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
44: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
44: 
44: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
44:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
44:     return getattr(imported_module, symbol), True
44:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
44: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
44: 
46: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
46:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
46:     return getattr(imported_module, symbol), True
46:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
46: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
46: 
46: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
46:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
46:     return getattr(imported_module, symbol), True
46:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
46: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
46: 
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170084, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 739}}
13: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
13:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
13:     return getattr(imported_module, symbol), True
13:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
13: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
13: 
13: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
13:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
13:     return getattr(imported_module, symbol), True
13:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
13: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
13: 
12: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
12:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
12:     return getattr(imported_module, symbol), True
12:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
12: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
12: 
12: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
12:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
12:     return getattr(imported_module, symbol), True
12:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
12: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
12: 
39: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
39:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
39:     return getattr(imported_module, symbol), True
39:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
39: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
39: 
39: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
39:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
39:     return getattr(imported_module, symbol), True
39:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
39: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
39: 
14: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
14:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
14:     return getattr(imported_module, symbol), True
14:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
14: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
14: 
14: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
14:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
14:     return getattr(imported_module, symbol), True
14:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
14: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
14: 
 9: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 9:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 9:     return getattr(imported_module, symbol), True
 9:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 9: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 9: 
 9: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 9:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 9:     return getattr(imported_module, symbol), True
 9:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 9: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 9: 
11: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
11:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
11:     return getattr(imported_module, symbol), True
11:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
11: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
11: 
11: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
11:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
11:     return getattr(imported_module, symbol), True
11:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
11: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
11: 
51: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
51:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
51:     return getattr(imported_module, symbol), True
51:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
51: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
51: 
51: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
51:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
51:     return getattr(imported_module, symbol), True
51:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
51: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
51: 
48: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
48:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
48:     return getattr(imported_module, symbol), True
48:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
48: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
48: 
48: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
48:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
48:     return getattr(imported_module, symbol), True
48:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
48: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
48: 
36: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
36:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
36:     return getattr(imported_module, symbol), True
36:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
36: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
36: 
36: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
36:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
36:     return getattr(imported_module, symbol), True
36:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
36: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
36: 
50: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
50:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
50:     return getattr(imported_module, symbol), True
50:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
50: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
50: 
50: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
50:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
50:     return getattr(imported_module, symbol), True
50:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
50: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
50: 
15: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
15:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
15:     return getattr(imported_module, symbol), True
15:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
15: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
15: 
15: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
15:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
15:     return getattr(imported_module, symbol), True
15:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
15: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
15: 
 6: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 6:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 6:     return getattr(imported_module, symbol), True
 6:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 6: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 6: 
 6: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 6:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 6:     return getattr(imported_module, symbol), True
 6:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 6: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 6: 
 3: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 3:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 3:     return getattr(imported_module, symbol), True
 3:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 3: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 3: 
 3: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 3:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 3:     return getattr(imported_module, symbol), True
 3:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 3: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 3: 
49: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
49:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
49:     return getattr(imported_module, symbol), True
49:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
49: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
49: 
49: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
49:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
49:     return getattr(imported_module, symbol), True
49:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
49: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
49: 
35: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
35:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
35:     return getattr(imported_module, symbol), True
35:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
35: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
35: 
35: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
35:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
35:     return getattr(imported_module, symbol), True
35:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
35: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
35: 
 1: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 1:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 1:     return getattr(imported_module, symbol), True
 1:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 1: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 1: 
 1: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 1:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 1:     return getattr(imported_module, symbol), True
 1:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 1: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 1: 
55: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
55:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
55:     return getattr(imported_module, symbol), True
55:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
55: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
55: 
55: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
55:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
55:     return getattr(imported_module, symbol), True
55:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
55: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
55: 
10: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
10:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
10:     return getattr(imported_module, symbol), True
10:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
10: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
10: 
10: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
10:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
10:     return getattr(imported_module, symbol), True
10:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
10: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
10: 
 2: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 2:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 2:     return getattr(imported_module, symbol), True
 2:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 2: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 2: 
 2: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 2:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 2:     return getattr(imported_module, symbol), True
 2:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 2: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 2: 
53: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
53:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
53:     return getattr(imported_module, symbol), True
53:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
53: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
53: 
53: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
53:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
53:     return getattr(imported_module, symbol), True
53:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
53: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
53: 
16: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
16:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
16:     return getattr(imported_module, symbol), True
16:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
16: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
16: 
16: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
16:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
16:     return getattr(imported_module, symbol), True
16:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
16: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
16: 
34: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
34:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
34:     return getattr(imported_module, symbol), True
34:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
34: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
34: 
34: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
34:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
34:     return getattr(imported_module, symbol), True
34:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
34: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
34: 
 4: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 4:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 4:     return getattr(imported_module, symbol), True
 4:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 4: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 4: 
 4: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 4:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 4:     return getattr(imported_module, symbol), True
 4:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 4: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 4: 
20: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
20:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
20:     return getattr(imported_module, symbol), True
20:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
20: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
20: 
20: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
20:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
20:     return getattr(imported_module, symbol), True
20:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
20: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
20: 
 7: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 7:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 7:     return getattr(imported_module, symbol), True
 7:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 7: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 7: 
 7: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
 7:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
 7:     return getattr(imported_module, symbol), True
 7:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 7: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
 7: 
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] 
 0:     
 0:     **************** Experiment configuration ****************
19: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
19:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
19:     return getattr(imported_module, symbol), True
19:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
19: 
19: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
19:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
19:     return getattr(imported_module, symbol), True
19:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
19: 
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] 
 0:     model:
 0:       data:
 0:         data_prefix:
 0:           train:
 0:           - 0.5
 0:           - /preproc_data/c4_en_6_c4_spm_text_document
 0:           - 0.5
 0:           - /preproc_data/c4_en_7_c4_spm_text_document
 0:           validation:
 0:           - /preproc_data/c4_en_validation_subset_c4_spm_text_document
 0:           test:
 0:           - /preproc_data/c4_en_validation_subset_c4_spm_text_document
 0:         index_mapping_dir: /npy_index
 0:         splits_string: null
 0:         validation_drop_last: false
 0:         pad_samples_to_global_batch_size: true
 0:         shuffle_documents: false
 0:         legacy_dataset: true
 0:         delay_data_init: true
 0:         delay_data_mmap: true
 0:         no_seqlen_plus_one_input_tokens: true
 0:         exchange_indices_distributed: true
 0:         mock_dataset: false
 0:         mock_tokenizer_vocab_size: 32000
 0:       mcore_gpt: true
 0:       name: megatron_gpt_full_te_layer_autocast
 0:       micro_batch_size: 1
 0:       tensor_model_parallel_size: 1
 0:       pipeline_model_parallel_size: 1
 0:       virtual_pipeline_model_parallel_size: null
 0:       context_parallel_size: 2
 0:       expert_model_parallel_size: 1
 0:       global_batch_size: 32
 0:       use_tp_pp_dp_mapping: true
 0:       base_config: 8b
 0:       overwritten_attributes:
 0:         num_layers: 32
 0:         enable_cuda_graph: 1
 0:         cuda_graph_scope: full_iteration
 0:       encoder_seq_length: 8192
 0:       overlap_p2p_comm: true
 0:       batch_p2p_comm: false
 0:       account_for_embedding_in_pipeline_split: false
 0:       account_for_loss_in_pipeline_split: false
 0:       external_cuda_graph: false
 0:       defer_embedding_wgrad_compute: false
 0:       wgrad_deferral_limit: 50
 0:       tokenizer:
 0:         model: /workspace/llm/nemo_tokenizer
 0:       gradient_accumulation_fusion: true
 0:       cross_entropy_loss_fusion: true
 0:       deterministic_mode: false
 0:       seed: 31623
 0:       resume_from_checkpoint: null
 0:       dist_ckpt_format: torch_dist
 0:       dist_ckpt_parallel_load: true
 0:       sync_batch_comm: false
 0:       activations_checkpoint_granularity: null
 0:       activations_checkpoint_method: null
 0:       activations_checkpoint_num_layers: null
 0:       sequence_parallel: false
 0:       transformer_engine: true
 0:       fp8: true
 0:       fp8_hybrid: true
 0:       fp8_recipe: tensorwise
 0:       fp8_amax_history_len: 1
 0:       fp8_amax_compute_algo: most_recent
 0:       reduce_amax: true
 0:       tp_only_amax_red: true
 0:       first_last_layers_bf16: false
 0:       num_layers_at_start_in_bf16: 0
 0:       num_layers_at_end_in_bf16: 0
 0:       use_te_rng_tracker: true
 0:       use_transformer_engine_op_fuser: true
 0:       cross_entropy_fusion_impl: te
 0:       ub_tp_comm_overlap: false
 0:       tp_comm_overlap_ag: true
 0:       tp_comm_overlap_rs: true
 0:       nccl_communicator_config_path: /workspace/llm/conf/nccl/custom_communicator_cta.yaml
 0:       sharp: false
 0:       optim:
 0:         overlap_grad_reduce: true
 0:         overlap_param_gather: true
 0:         align_param_gather: false
 0:         use_distributed_optimizer: true
 0:         bucket_size: 200
 0:         fp8_param_gather: true
 0:         overlap_param_gather_with_optim_step: false
 0:         lr: 0.0008
 0:         sched:
 0:           min_lr: 8.0e-05
 0:           warmup_steps: 96
 0:           max_steps_for_lr_sched: 43200000.0
 0:         lock_timeout: null
 0:       gc_interval_train: 10000
 0:       gc_interval_valid: 10000
 0:       nsys_profile:
 0:         enabled: false
 0:         start_step: 10
 0:         end_step: 10
 0:         ranks:
 0:         - 0
 0:         gen_shape: false
 0:         nvtx_ranges: false
 0:       custom:
 0:         log_metrics: NEMO
 0:         init_global_step: 0
 0:         target_log_ppl: 3.3
 0:         use_distributed_checkpointing: 1
 0:         run_warmup_on_synth_data: 1
 0:         reset_fp8_stats_after_warmup: 1
 0:         pre_validate: 0
 0:         override_zero_consumed_samples: 1
 0:         force_success_status: 0
 0:         warmup_train_steps: 2
 0:         warmup_validation_steps: 2
 0:         extend_run_evals: 0
 0:         disable_nemo_logs: true
 0:     proxy_gbs: 32
 0:     is_proxy_run: false
 0:     skip_evals: 12
 0:     default_val_check_interval: 384
 0:     trainer:
 0:       devices: 8
 0:       num_nodes: 8
 0:       precision: bf16
 0:       max_steps: 1200000
 0:       max_epochs: 1
 0:       log_every_n_steps: 32
 0:       val_check_interval: 256
 0:       limit_val_batches: 32
 0:       limit_test_batches: 1
 0:       limit_train_batches: null
 0:       enable_progress_bar: false
 0:       num_sanity_val_steps: 0
 0:     exp_manager:
 0:       explicit_log_dir: /results/251010070200228656059
 0:       resume_if_exists: 0
 0:       create_checkpoint_callback: 0
 0:       checkpoint_callback_params:
 0:         save_top_k: 1
 0:         mode: max
 0:         every_n_epochs: 0
 0:         save_last: true
 0:       log_step_timing: true
 0:       create_tensorboard_logger: false
 0:       log_global_rank_0_only: true
 0:     misc:
 0:       print_config: false
 0:       memory_profiler:
 0:         enable: false
 0:         file_prefix: memdump
 0:         max_entries: 1000000
 0:         rank_0_only: true
 0:         start_location: init
 0:         end_location: train_start
 0:         force_oom_before_stop: false
 0:         possible_oom: false
 0:     
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] 
 0:     TP: 1; PP: 1; VP: None; CP: 2
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] ======== Benchmarked setups ========
33: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
33:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
33:     return getattr(imported_module, symbol), True
33:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
33: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
33: 
33: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
33:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
33:     return getattr(imported_module, symbol), True
33:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
33: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
33: 
18: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
18:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
18:     return getattr(imported_module, symbol), True
18:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
18: 
18: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
18:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
18:     return getattr(imported_module, symbol), True
18:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
18: 
23: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
23:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
23:     return getattr(imported_module, symbol), True
23:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
23: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
23: 
23: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
23:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
23:     return getattr(imported_module, symbol), True
23:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
23: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
23: 
52: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
52:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
52:     return getattr(imported_module, symbol), True
52:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
52: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
52: 
52: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
52:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
52:     return getattr(imported_module, symbol), True
52:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
52: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
52: 
22: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
22:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
22:     return getattr(imported_module, symbol), True
22:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
22: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
22: 
22: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
22:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
22:     return getattr(imported_module, symbol), True
22:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
22: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
22: 
21: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
21:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
21:     return getattr(imported_module, symbol), True
21:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
21: 
21: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
21:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
21:     return getattr(imported_module, symbol), True
21:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
21: 
54: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
54:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
54:     return getattr(imported_module, symbol), True
54:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
54: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
54: 
54: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
54:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
54:     return getattr(imported_module, symbol), True
54:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
54: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
54: 
17: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
17:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
17:     return getattr(imported_module, symbol), True
17:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
17: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
17: 
17: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
17:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
17:     return getattr(imported_module, symbol), True
17:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
17: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
17: 
56: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
56:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
56:     return getattr(imported_module, symbol), True
56:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
56: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
56: 
56: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
56:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
56:     return getattr(imported_module, symbol), True
56:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
56: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
56: 
37: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
37:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
37:     return getattr(imported_module, symbol), True
37:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
37: 
37: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
37:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
37:     return getattr(imported_module, symbol), True
37:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
37: 
59: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
59:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
59:     return getattr(imported_module, symbol), True
59:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
59: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
59: 
59: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
59:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
59:     return getattr(imported_module, symbol), True
59:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
59: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
59: 
57: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
57:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
57:     return getattr(imported_module, symbol), True
57:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
57: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
57: 
57: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
57:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
57:     return getattr(imported_module, symbol), True
57:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
57: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
57: 
58: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
58:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
58:     return getattr(imported_module, symbol), True
58:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
58: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
58: 
58: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
58:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
58:     return getattr(imported_module, symbol), True
58:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
58: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
58: 
60: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
60:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
60:     return getattr(imported_module, symbol), True
60:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
60: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
60: 
60: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
60:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
60:     return getattr(imported_module, symbol), True
60:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
60: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
60: 
61: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
61:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
61:     return getattr(imported_module, symbol), True
61:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
61: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
61: 
61: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
61:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
61:     return getattr(imported_module, symbol), True
61:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
61: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
61: 
 0: GPU available: True (cuda), used: True
 0: TPU available: False, using: 0 TPU cores
 0: HPU available: False, using: 0 HPUs
 0: `Trainer(limit_test_batches=1)` was configured so 1 batch will be used.
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170820, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama31_8b", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HPE", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "seed", "value": 31623, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 32, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1.0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "max_sequence_length", "value": 8192, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 1024, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170821, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1574207408, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "init_checkpoint_step", "value": 0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0008, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.95, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-05, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.1, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 1.0, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_end_learning_rate", "value": 8e-05, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170822, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 96, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170823, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_steps", "value": 1199904, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170823, "event_type": "POINT_IN_TIME", "key": "max_steps", "value": 1200000, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170823, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_schedule", "value": "cosine with linear warmup", "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105170823, "event_type": "POINT_IN_TIME", "key": "target_accuracy", "value": 3.3, "metadata": {"file": "/workspace/llm/pretrain.py", "lineno": 586}}
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] ======== Benchmarked fit ========
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Experiments will be logged at /workspace/llm/nemo_experiments/default/2025-10-10_09-06-10
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has data parallel group : [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Ranks 0 has data parallel rank: 0
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has context parallel group: [0, 1]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] All context parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21], [22, 23], [24, 25], [26, 27], [28, 29], [30, 31], [32, 33], [34, 35], [36, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 47], [48, 49], [50, 51], [52, 53], [54, 55], [56, 57], [58, 59], [60, 61], [62, 63]]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Ranks 0 has context parallel rank: 0
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has model parallel group: [0]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] All model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has tensor model parallel group: [0]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] All tensor model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has tensor model parallel rank: 0
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] All expert tensor parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21], [22, 23], [24, 25], [26, 27], [28, 29], [30, 31], [32, 33], [34, 35], [36, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 47], [48, 49], [50, 51], [52, 53], [54, 55], [56, 57], [58, 59], [60, 61], [62, 63]]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has expert tensor parallel rank: 0
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has embedding group: [0]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has pipeline model parallel rank 0
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
 0: [NeMo I 2025-10-10 09:06:10 nemo_logging:393] Rank 0 has embedding rank: 0
 0: [AUX I 2025-10-10 09:06:10 megatron_strategy:594] Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/64
62: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
62:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
62:     return getattr(imported_module, symbol), True
62:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
62: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
62: 
62: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
62:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
62:     return getattr(imported_module, symbol), True
62:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
62: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
62: 
63: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
63:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
63:     return getattr(imported_module, symbol), True
63:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
63: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
63: 
63: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
63:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
63:     return getattr(imported_module, symbol), True
63:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
63: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
63: 
24: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
25: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
26: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
27: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
28: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
29: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
30: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
31: WARNING:megatron.core.utils:fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
 1: [W1010 09:06:13.713965404 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
40: [W1010 09:06:13.796767868 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 3: [W1010 09:06:13.713915453 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
42: [W1010 09:06:13.796708096 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 4: [W1010 09:06:13.713928836 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
43: [W1010 09:06:13.796771352 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 5: [W1010 09:06:13.713929337 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
44: [W1010 09:06:13.796790978 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 6: [W1010 09:06:13.713929522 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
45: [W1010 09:06:13.796932642 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
32: [W1010 09:06:13.575514936 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 9: [W1010 09:06:13.792841797 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
49: [W1010 09:06:13.659712709 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
41: [W1010 09:06:13.797052230 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
36: [W1010 09:06:13.575661864 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
10: [W1010 09:06:13.792876036 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
51: [W1010 09:06:13.659622719 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
46: [W1010 09:06:13.797033583 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
38: [W1010 09:06:13.575630763 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
11: [W1010 09:06:13.792838803 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
48: [W1010 09:06:13.659765244 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
47: [W1010 09:06:13.796982699 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
39: [W1010 09:06:13.575633988 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
12: [W1010 09:06:13.792915976 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
16: [W1010 09:06:13.676909025 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
13: [W1010 09:06:13.792913555 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
14: [W1010 09:06:13.792854654 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
15: [W1010 09:06:13.792909274 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 8: [W1010 09:06:13.793012278 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
53: [W1010 09:06:13.659900552 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
25: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
25:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
25:     return getattr(imported_module, symbol), True
25:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
25: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
25: 
25: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
25:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
25:     return getattr(imported_module, symbol), True
25:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
25: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
25: 
31: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
31:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
31:     return getattr(imported_module, symbol), True
31:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
31: 
31: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
31:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
31:     return getattr(imported_module, symbol), True
31:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
31: 
26: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
26:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
26:     return getattr(imported_module, symbol), True
26:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
26: 
26: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
26:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
26:     return getattr(imported_module, symbol), True
26:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
26: 
28: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
28:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
28:     return getattr(imported_module, symbol), True
28:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
28: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
28: 
28: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
28:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
28:     return getattr(imported_module, symbol), True
28:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
28: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
28: 
29: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
29:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
29:     return getattr(imported_module, symbol), True
29:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
29: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
29: 
29: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
29:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
29:     return getattr(imported_module, symbol), True
29:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
29: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
29: 
27: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
27:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
27:     return getattr(imported_module, symbol), True
27:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
27: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
27: 
27: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
27:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
27:     return getattr(imported_module, symbol), True
27:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
27: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
27: 
24: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
24:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
24:     return getattr(imported_module, symbol), True
24:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
24: 
24: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
24:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
24:     return getattr(imported_module, symbol), True
24:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
24: 
30: Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
30:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
30:     return getattr(imported_module, symbol), True
30:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
30: 
30: INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
30:   File "/workspace/NeMo/nemo/utils/import_utils.py", line 319, in safe_import_from
30:     return getattr(imported_module, symbol), True
30:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30: AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'
30: 
25: [W1010 09:06:14.222786326 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
28: [W1010 09:06:14.227287277 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
31: [W1010 09:06:14.227530967 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
27: [W1010 09:06:14.292582380 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
24: [W1010 09:06:14.326627640 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
30: [W1010 09:06:14.328497029 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
26: [W1010 09:06:14.331122280 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
29: [W1010 09:06:14.348885710 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
50: [W1010 09:06:16.960569665 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 7: [W1010 09:06:16.019846759 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
35: [W1010 09:06:16.882014491 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
19: [W1010 09:06:16.991278067 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 2: [W1010 09:06:16.032345869 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
20: [W1010 09:06:16.003870520 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
34: [W1010 09:06:16.910225095 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
18: [W1010 09:06:16.011495593 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
52: [W1010 09:06:16.006690182 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
21: [W1010 09:06:16.025262197 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
33: [W1010 09:06:16.927770135 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
22: [W1010 09:06:16.030765840 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
54: [W1010 09:06:16.052271277 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
55: [W1010 09:06:16.070436427 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
17: [W1010 09:06:16.114771354 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
23: [W1010 09:06:16.126864000 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
56: [W1010 09:06:16.126696004 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
37: [W1010 09:06:16.107637188 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
59: [W1010 09:06:17.381712831 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
57: [W1010 09:06:17.413416900 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
58: [W1010 09:06:17.447815006 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
61: [W1010 09:06:17.528122415 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
62: [W1010 09:06:17.550612958 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
63: [W1010 09:06:17.555453327 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
60: [W1010 09:06:17.599669113 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 0: [W1010 09:06:17.641908670 ProcessGroupNCCL.cpp:990] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
 0: ----------------------------------------------------------------------------------------------------
 0: distributed_backend=nccl
 0: All distributed processes registered. Starting with 64 processes
 0: ----------------------------------------------------------------------------------------------------
 0: 
 1: [Gloo] Rank 1 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 2: [Gloo] Rank 2 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 3: [Gloo] Rank 3 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 0: [Gloo] Rank 0 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 7: [Gloo] Rank 7 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 4: [Gloo] Rank 4 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 6: [Gloo] Rank 6 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 5: [Gloo] Rank 5 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 9: [Gloo] Rank 9 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
11: [Gloo] Rank 11 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
12: [Gloo] Rank 12 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
10: [Gloo] Rank 10 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
13: [Gloo] Rank 13 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
14: [Gloo] Rank 14 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
15: [Gloo] Rank 15 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
16: [Gloo] Rank 16 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
20: [Gloo] Rank 20 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
25: [Gloo] Rank 25 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
26: [Gloo] Rank 26 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
24: [Gloo] Rank 24 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
18: [Gloo] Rank 18 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
23: [Gloo] Rank 23 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
22: [Gloo] Rank 22 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
28: [Gloo] Rank 28 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
19: [Gloo] Rank 19 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
21: [Gloo] Rank 21 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
27: [Gloo] Rank 27 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
17: [Gloo] Rank 17 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
30: [Gloo] Rank 30 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
31: [Gloo] Rank 31 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
61: [Gloo] Rank 61 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
 8: [Gloo] Rank 8 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
60: [Gloo] Rank 60 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
29: [Gloo] Rank 29 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
63: [Gloo] Rank 63 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
32: [Gloo] Rank 32 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
33: [Gloo] Rank 33 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
34: [Gloo] Rank 34 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
35: [Gloo] Rank 35 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
36: [Gloo] Rank 36 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
37: [Gloo] Rank 37 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
58: [Gloo] Rank 58 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
38: [Gloo] Rank 38 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
39: [Gloo] Rank 39 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
57: [Gloo] Rank 57 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
40: [Gloo] Rank 40 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
59: [Gloo] Rank 59 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
50: [Gloo] Rank 50 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
56: [Gloo] Rank 56 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
41: [Gloo] Rank 41 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
42: [Gloo] Rank 42 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
43: [Gloo] Rank 43 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
44: [Gloo] Rank 44 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
62: [Gloo] Rank 62 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
45: [Gloo] Rank 45 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
46: [Gloo] Rank 46 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
48: [Gloo] Rank 48 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
51: [Gloo] Rank 51 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
52: [Gloo] Rank 52 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
53: [Gloo] Rank 53 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
54: [Gloo] Rank 54 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
55: [Gloo] Rank 55 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
49: [Gloo] Rank 49 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
47: [Gloo] Rank 47 is connected to 63 peer ranks. Expected number of connected peer ranks is : 63
61: [Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
24: [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
26: [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
25: [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
28: [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
30: [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
27: [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
29: [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
31: [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
59: [Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
63: [Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 9: [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
11: [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
13: [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 8: [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
10: [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
49: [Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
15: [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
12: [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
14: [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
56: [Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
17: [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
51: [Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
58: [Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
19: [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
53: [Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
62: [Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
16: [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
18: [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
60: [Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
21: [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
23: [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
57: [Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
20: [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
22: [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 0: [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 2: [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 4: [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
41: [Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 6: [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
55: [Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
48: [Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
52: [Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
54: [Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
36: [Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
50: [Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
32: [Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
42: [Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
38: [Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 1: [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
46: [Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
40: [Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
34: [Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 3: [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 5: [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
44: [Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 7: [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
33: [Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
37: [Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
43: [Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
47: [Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
35: [Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
39: [Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
45: [Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
11: [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
13: [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 1: [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 9: [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 3: [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
15: [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
17: [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
19: [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 5: [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
21: [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 7: [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
23: [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
27: [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
29: [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
31: [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
25: [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
33: [Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 0: [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
35: [Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 2: [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
37: [Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
39: [Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 4: [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
43: [Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 6: [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
57: [Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
41: [Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
45: [Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
49: [Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
59: [Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
47: [Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
51: [Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
55: [Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
61: [Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
63: [Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
53: [Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
10: [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
16: [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
12: [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
18: [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
20: [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
14: [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
22: [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 8: [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
26: [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
30: [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
56: [Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
28: [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
58: [Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
62: [Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
60: [Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
24: [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
32: [Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
34: [Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
38: [Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
36: [Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
42: [Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
40: [Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
44: [Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
50: [Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
54: [Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
46: [Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
48: [Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
52: [Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
 0: [NeMo I 2025-10-10 09:06:20 utils:661] Building GPTDataset splits with sizes=[38400000, 4800512, 32] and config=GPTDatasetConfig(random_seed=31623, sequence_length=8192, blend=None, blend_per_split=[(['/preproc_data/c4-train.en_6_text_document'], [50.0]), (['/preproc_data/c4-validation-91205-samples.en_text_document'], None), (['/preproc_data/c4-validation-91205-samples.en_text_document'], None)], multiple_validation_sets=None, full_validation=None, split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache='/npy_index', mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.huggingface.auto_tokenizer.AutoTokenizer object at 0x7ef975f91ee0>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)
 0: [NeMo I 2025-10-10 09:06:20 utils:661] Load the _IndexReader from /preproc_data/c4-train.en_6_text_document.idx
 0: [NeMo I 2025-10-10 09:06:20 utils:661] 	Extract the sequence lengths
 0: [NeMo I 2025-10-10 09:06:20 utils:661] 	Extract the sequence pointers
 0: [NeMo I 2025-10-10 09:06:20 utils:661] 	Extract the document indices
 0: [NeMo I 2025-10-10 09:06:20 utils:661] > total number of sequences: 45608611
 0: [NeMo I 2025-10-10 09:06:20 utils:661] > total number of documents: 45608611
 0: [NeMo I 2025-10-10 09:06:20 utils:661] Build and save the GPTDataset train indices
 0: [NeMo I 2025-10-10 09:07:00 utils:661] > total number of samples: 38441516
 0: [NeMo I 2025-10-10 09:07:00 utils:661] > total number of epochs: 15
 0: [NeMo I 2025-10-10 09:07:00 utils:661] Load the _IndexReader from /preproc_data/c4-validation-91205-samples.en_text_document.idx
 0: [NeMo I 2025-10-10 09:07:00 utils:661] 	Extract the sequence lengths
 0: [NeMo I 2025-10-10 09:07:00 utils:661] 	Extract the sequence pointers
 0: [NeMo I 2025-10-10 09:07:00 utils:661] 	Extract the document indices
 0: [NeMo I 2025-10-10 09:07:00 utils:661] > total number of sequences: 91205
 0: [NeMo I 2025-10-10 09:07:00 utils:661] > total number of documents: 91205
 0: [NeMo I 2025-10-10 09:07:00 utils:661] Build and save the GPTDataset valid indices
 0: [NeMo I 2025-10-10 09:07:05 utils:661] > total number of samples: 4803683
 0: [NeMo I 2025-10-10 09:07:05 utils:661] > total number of epochs: 945
 0: [NeMo I 2025-10-10 09:07:05 utils:661] Load the _IndexReader from /preproc_data/c4-validation-91205-samples.en_text_document.idx
 0: [NeMo I 2025-10-10 09:07:05 utils:661] 	Extract the sequence lengths
 0: [NeMo I 2025-10-10 09:07:05 utils:661] 	Extract the sequence pointers
 0: [NeMo I 2025-10-10 09:07:05 utils:661] 	Extract the document indices
 0: [NeMo I 2025-10-10 09:07:05 utils:661] > total number of sequences: 91205
 0: [NeMo I 2025-10-10 09:07:05 utils:661] > total number of documents: 91205
 0: [NeMo I 2025-10-10 09:07:05 utils:661] Build and save the GPTDataset test indices
 0: [NeMo I 2025-10-10 09:07:05 utils:661] > total number of samples: 5083
 0: [NeMo I 2025-10-10 09:07:05 utils:661] > total number of epochs: 1
 0: [NeMo I 2025-10-10 09:07:05 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.
38: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-10 09:07:06 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.
 6: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
44: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
60: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
41: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 7: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
46: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
52: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
51: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
57: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
56: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
35: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
62: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 8: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
11: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
13: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
10: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
37: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
63: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
23: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
36: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
47: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
48: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
49: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
33: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
50: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 4: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
55: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 5: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
32: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 3: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
58: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
22: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
16: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 9: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
53: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
15: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
34: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-10 09:07:06 nemo_logging:393] Copying Trainer's 'max_steps' (1200000) to LR scheduler's 'max_steps'.
 0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-10 09:07:06 num_microbatches_calculator:228] setting number of microbatches to constant 1
54: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
18: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
21: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
17: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 2: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-10 09:07:06 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 8030261248
12: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
45: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
19: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
59: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-10 09:07:06 utils:661] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=False, check_for_large_grads=False, bucket_size=134217728, pad_buckets_for_high_nccl_busbw=False, average_in_collective=True, fp8_param_gather=True, reuse_grad_buf_for_mxfp8_param_ag=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False, nccl_ub=False, fsdp_double_buffer=False)
20: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-10 09:07:06 utils:682] Number of buckets for gradient all-reduce / reduce-scatter: 2
 0:     Params for bucket 1 (525336576 elements, 525336576 padded size):
 0:     	module.output_layer.weight
 0:     Params for bucket 2 (525602816 elements, 525602816 padded size):
 0:     	module.decoder.layers.31.mlp.0.weight
 0:     	module.decoder.layers.27.mlp.0.weight
 0:     	module.decoder.layers.23.mlp.0.weight
 0:     	module.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.9.mlp.0.weight
 0:     	module.decoder.layers.5.mlp.0.weight
 0:     	module.decoder.layers.30.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.26.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.22.mlp.0.weight
 0:     	module.decoder.layers.18.mlp.0.weight
 0:     	module.decoder.layers.14.mlp.0.weight
 0:     	module.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.29.mlp.0.weight
 0:     	module.decoder.layers.29.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.25.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.7.mlp.0.weight
 0:     	module.decoder.layers.3.mlp.0.weight
 0:     	module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.28.mlp.0.weight
 0:     	module.decoder.layers.24.mlp.0.weight
 0:     	module.decoder.layers.20.mlp.0.weight
 0:     	module.decoder.layers.16.mlp.0.weight
 0:     	module.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.6.mlp.0.weight
 0:     	module.decoder.layers.2.mlp.0.weight
 0:     	module.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.31.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.27.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.19.mlp.0.weight
 0:     	module.decoder.layers.15.mlp.0.weight
 0:     	module.decoder.layers.11.mlp.0.weight
 0:     	module.decoder.layers.10.mlp.0.weight
 0:     	module.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.30.mlp.0.weight
 0:     	module.decoder.layers.26.mlp.0.weight
 0:     	module.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.8.mlp.0.weight
 0:     	module.decoder.layers.4.mlp.0.weight
 0:     	module.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
 0:     	module.embedding.word_embeddings.weight
 0:     	module.decoder.layers.25.mlp.0.weight
 0:     	module.decoder.layers.21.mlp.0.weight
 0:     	module.decoder.layers.17.mlp.0.weight
 0:     	module.decoder.layers.13.mlp.0.weight
 0:     	module.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.1.mlp.0.weight
 0:     	module.decoder.layers.0.mlp.0.weight
 0:     	module.decoder.final_layernorm.weight
 0:     	module.decoder.layers.28.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight
 0:     	module.decoder.layers.12.mlp.0.weight
 0:     	module.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
61: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
24: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
27: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-10 09:07:06 utils:682] Number of buckets for gradient all-reduce / reduce-scatter: 33
 0:     Params for bucket 1 (176160768 elements, 176160768 padded size):
 0:     	module.decoder.layers.31.mlp.3.weight
 0:     	module.decoder.layers.31.mlp.1.weight
 0:     Params for bucket 2 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.31.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.30.mlp.1.weight
 0:     	module.decoder.layers.30.mlp.3.weight
 0:     	module.decoder.layers.31.self_attention.linear_proj.weight
 0:     Params for bucket 3 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.30.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.30.self_attention.linear_proj.weight
 0:     	module.decoder.layers.29.mlp.3.weight
 0:     	module.decoder.layers.29.mlp.1.weight
 0:     Params for bucket 4 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.29.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.29.self_attention.linear_proj.weight
 0:     	module.decoder.layers.28.mlp.1.weight
 0:     	module.decoder.layers.28.mlp.3.weight
 0:     Params for bucket 5 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.28.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.27.mlp.3.weight
 0:     	module.decoder.layers.28.self_attention.linear_proj.weight
 0:     	module.decoder.layers.27.mlp.1.weight
 0:     Params for bucket 6 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.27.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.26.mlp.1.weight
 0:     	module.decoder.layers.26.mlp.3.weight
 0:     	module.decoder.layers.27.self_attention.linear_proj.weight
 0:     Params for bucket 7 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.26.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.26.self_attention.linear_proj.weight
 0:     	module.decoder.layers.25.mlp.1.weight
 0:     	module.decoder.layers.25.mlp.3.weight
 0:     Params for bucket 8 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.25.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.25.self_attention.linear_proj.weight
 0:     	module.decoder.layers.24.mlp.1.weight
 0:     	module.decoder.layers.24.mlp.3.weight
 0:     Params for bucket 9 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.24.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.24.self_attention.linear_proj.weight
 0:     	module.decoder.layers.23.mlp.3.weight
 0:     	module.decoder.layers.23.mlp.1.weight
 0:     Params for bucket 10 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.23.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.22.mlp.3.weight
 0:     	module.decoder.layers.23.self_attention.linear_proj.weight
 0:     	module.decoder.layers.22.mlp.1.weight
 0:     Params for bucket 11 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.22.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.21.mlp.1.weight
 0:     	module.decoder.layers.21.mlp.3.weight
 0:     	module.decoder.layers.22.self_attention.linear_proj.weight
 0:     Params for bucket 12 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.21.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.21.self_attention.linear_proj.weight
 0:     	module.decoder.layers.20.mlp.1.weight
 0:     	module.decoder.layers.20.mlp.3.weight
 0:     Params for bucket 13 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.20.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.19.mlp.3.weight
 0:     	module.decoder.layers.20.self_attention.linear_proj.weight
 0:     	module.decoder.layers.19.mlp.1.weight
 0:     Params for bucket 14 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.19.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.18.mlp.3.weight
 0:     	module.decoder.layers.19.self_attention.linear_proj.weight
 0:     	module.decoder.layers.18.mlp.1.weight
 0:     Params for bucket 15 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.18.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.17.mlp.1.weight
 0:     	module.decoder.layers.17.mlp.3.weight
 0:     	module.decoder.layers.18.self_attention.linear_proj.weight
 0:     Params for bucket 16 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.17.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.17.self_attention.linear_proj.weight
 0:     	module.decoder.layers.16.mlp.1.weight
 0:     	module.decoder.layers.16.mlp.3.weight
 0:     Params for bucket 17 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.16.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.16.self_attention.linear_proj.weight
 0:     	module.decoder.layers.15.mlp.1.weight
 0:     	module.decoder.layers.15.mlp.3.weight
 0:     Params for bucket 18 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.15.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.14.mlp.1.weight
 0:     	module.decoder.layers.15.self_attention.linear_proj.weight
 0:     	module.decoder.layers.14.mlp.3.weight
 0:     Params for bucket 19 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.14.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.13.mlp.1.weight
 0:     	module.decoder.layers.13.mlp.3.weight
 0:     	module.decoder.layers.14.self_attention.linear_proj.weight
 0:     Params for bucket 20 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.13.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.12.mlp.1.weight
 0:     	module.decoder.layers.12.mlp.3.weight
 0:     	module.decoder.layers.13.self_attention.linear_proj.weight
 0:     Params for bucket 21 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.12.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.12.self_attention.linear_proj.weight
 0:     	module.decoder.layers.11.mlp.1.weight
 0:     	module.decoder.layers.11.mlp.3.weight
 0:     Params for bucket 22 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.11.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.11.self_attention.linear_proj.weight
 0:     	module.decoder.layers.10.mlp.1.weight
 0:     	module.decoder.layers.10.mlp.3.weight
 0:     Params for bucket 23 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.10.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.10.self_attention.linear_proj.weight
 0:     	module.decoder.layers.9.mlp.1.weight
 0:     	module.decoder.layers.9.mlp.3.weight
 0:     Params for bucket 24 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.9.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.9.self_attention.linear_proj.weight
 0:     	module.decoder.layers.8.mlp.1.weight
 0:     	module.decoder.layers.8.mlp.3.weight
 0:     Params for bucket 25 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.8.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.7.mlp.3.weight
 0:     	module.decoder.layers.8.self_attention.linear_proj.weight
 0:     	module.decoder.layers.7.mlp.1.weight
 0:     Params for bucket 26 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.7.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.6.mlp.3.weight
 0:     	module.decoder.layers.6.mlp.1.weight
 0:     	module.decoder.layers.7.self_attention.linear_proj.weight
 0:     Params for bucket 27 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.6.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.5.mlp.1.weight
 0:     	module.decoder.layers.5.mlp.3.weight
 0:     	module.decoder.layers.6.self_attention.linear_proj.weight
 0:     Params for bucket 28 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.5.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.5.self_attention.linear_proj.weight
 0:     	module.decoder.layers.4.mlp.1.weight
 0:     	module.decoder.layers.4.mlp.3.weight
 0:     Params for bucket 29 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.4.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.3.mlp.3.weight
 0:     	module.decoder.layers.4.self_attention.linear_proj.weight
 0:     	module.decoder.layers.3.mlp.1.weight
 0:     Params for bucket 30 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.3.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.2.mlp.3.weight
 0:     	module.decoder.layers.3.self_attention.linear_proj.weight
 0:     	module.decoder.layers.2.mlp.1.weight
 0:     Params for bucket 31 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.2.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.2.self_attention.linear_proj.weight
 0:     	module.decoder.layers.1.mlp.1.weight
 0:     	module.decoder.layers.1.mlp.3.weight
 0:     Params for bucket 32 (218103808 elements, 218103808 padded size):
 0:     	module.decoder.layers.1.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.1.self_attention.linear_proj.weight
 0:     	module.decoder.layers.0.mlp.1.weight
 0:     	module.decoder.layers.0.mlp.3.weight
 0:     Params for bucket 33 (41943040 elements, 41943040 padded size):
 0:     	module.decoder.layers.0.self_attention.linear_qkv.weight
 0:     	module.decoder.layers.0.self_attention.linear_proj.weight
25: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
26: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
31: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: [NeMo I 2025-10-10 09:07:06 utils:661] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0008, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp8_recipe='tensorwise', fp16=False, bf16=True, reuse_grad_buf_for_mxfp8_param_ag=False, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_ti
 0: me=False, timers=None, config_logger_dir='')
39: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
43: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
40: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
42: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
14: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
30: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
29: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
28: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: 
 0:   | Name   | Type | Params | Mode 
 0: ----------------------------------------
 0: 0 | module | DDP  | 8.0 B  | train
 0: ----------------------------------------
 0: 8.0 B     Trainable params
 0: 0         Non-trainable params
 0: 8.0 B     Total params
 0: 32,121.045Total estimated model params size (MB)
 0: 843       Modules in train mode
 0: 0         Modules in eval mode
32: SLURM auto-requeueing enabled. Setting signal handlers.
 0: SLURM auto-requeueing enabled. Setting signal handlers.
33: SLURM auto-requeueing enabled. Setting signal handlers.
 1: SLURM auto-requeueing enabled. Setting signal handlers.
34: SLURM auto-requeueing enabled. Setting signal handlers.
 2: SLURM auto-requeueing enabled. Setting signal handlers.
48: SLURM auto-requeueing enabled. Setting signal handlers.
56: SLURM auto-requeueing enabled. Setting signal handlers.
16: SLURM auto-requeueing enabled. Setting signal handlers.
40: SLURM auto-requeueing enabled. Setting signal handlers.
24: SLURM auto-requeueing enabled. Setting signal handlers.
35: SLURM auto-requeueing enabled. Setting signal handlers.
 8: SLURM auto-requeueing enabled. Setting signal handlers.
 3: SLURM auto-requeueing enabled. Setting signal handlers.
49: SLURM auto-requeueing enabled. Setting signal handlers.
57: SLURM auto-requeueing enabled. Setting signal handlers.
17: SLURM auto-requeueing enabled. Setting signal handlers.
41: SLURM auto-requeueing enabled. Setting signal handlers.
25: SLURM auto-requeueing enabled. Setting signal handlers.
36: SLURM auto-requeueing enabled. Setting signal handlers.
 9: SLURM auto-requeueing enabled. Setting signal handlers.
 4: SLURM auto-requeueing enabled. Setting signal handlers.
50: SLURM auto-requeueing enabled. Setting signal handlers.
58: SLURM auto-requeueing enabled. Setting signal handlers.
18: SLURM auto-requeueing enabled. Setting signal handlers.
42: SLURM auto-requeueing enabled. Setting signal handlers.
26: SLURM auto-requeueing enabled. Setting signal handlers.
37: SLURM auto-requeueing enabled. Setting signal handlers.
10: SLURM auto-requeueing enabled. Setting signal handlers.
 5: SLURM auto-requeueing enabled. Setting signal handlers.
51: SLURM auto-requeueing enabled. Setting signal handlers.
59: SLURM auto-requeueing enabled. Setting signal handlers.
19: SLURM auto-requeueing enabled. Setting signal handlers.
43: SLURM auto-requeueing enabled. Setting signal handlers.
27: SLURM auto-requeueing enabled. Setting signal handlers.
11: SLURM auto-requeueing enabled. Setting signal handlers.
 6: SLURM auto-requeueing enabled. Setting signal handlers.
53: SLURM auto-requeueing enabled. Setting signal handlers.
60: SLURM auto-requeueing enabled. Setting signal handlers.
20: SLURM auto-requeueing enabled. Setting signal handlers.
44: SLURM auto-requeueing enabled. Setting signal handlers.
28: SLURM auto-requeueing enabled. Setting signal handlers.
12: SLURM auto-requeueing enabled. Setting signal handlers.
 7: SLURM auto-requeueing enabled. Setting signal handlers.
52: SLURM auto-requeueing enabled. Setting signal handlers.
61: SLURM auto-requeueing enabled. Setting signal handlers.
21: SLURM auto-requeueing enabled. Setting signal handlers.
45: SLURM auto-requeueing enabled. Setting signal handlers.
29: SLURM auto-requeueing enabled. Setting signal handlers.
13: SLURM auto-requeueing enabled. Setting signal handlers.
55: SLURM auto-requeueing enabled. Setting signal handlers.
62: SLURM auto-requeueing enabled. Setting signal handlers.
31: SLURM auto-requeueing enabled. Setting signal handlers.
15: SLURM auto-requeueing enabled. Setting signal handlers.
54: SLURM auto-requeueing enabled. Setting signal handlers.
63: SLURM auto-requeueing enabled. Setting signal handlers.
30: SLURM auto-requeueing enabled. Setting signal handlers.
14: SLURM auto-requeueing enabled. Setting signal handlers.
38: SLURM auto-requeueing enabled. Setting signal handlers.
39: SLURM auto-requeueing enabled. Setting signal handlers.
22: SLURM auto-requeueing enabled. Setting signal handlers.
23: SLURM auto-requeueing enabled. Setting signal handlers.
46: SLURM auto-requeueing enabled. Setting signal handlers.
47: SLURM auto-requeueing enabled. Setting signal handlers.
 0: [AUX I 2025-10-10 09:07:06 data:291] Instantiating MegatronPretrainingSampler with total_samples: 38441516 and consumed_samples: 0
 0: [AUX I 2025-10-10 09:07:06 data:291] Instantiating MegatronPretrainingSampler with total_samples: 4803683 and consumed_samples: 0
 0: GPTModel(
 0:   (embedding): LanguageModelEmbedding(
 0:     (word_embeddings): VocabParallelEmbedding()
 0:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 0:   )
 0:   (rotary_pos_emb): RotaryEmbedding()
 0:   (decoder): TransformerBlock(
 0:     (layers): ModuleList(
 0:       (0-31): 32 x TransformerLayer(
 0:         (input_layernorm): IdentityOp()
 0:         (self_attention): SelfAttention(
 0:           (core_attention): TEDotProductAttention(
 0:             (flash_attention): FlashAttention()
 0:             (fused_attention): FusedAttention()
 0:             (unfused_attention): UnfusedDotProductAttention(
 0:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 0:               (attention_dropout): Dropout(p=0.0, inplace=False)
 0:             )
 0:           )
 0:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 0:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 0:           (q_layernorm): IdentityOp()
 0:           (k_layernorm): IdentityOp()
 0:         )
 0:         (pre_cross_attn_layernorm): IdentityOp()
 0:         (cross_attention): IdentityOp()
 0:         (cross_attn_bda): IdentityFuncOp()
 0:         (pre_mlp_layernorm): IdentityOp()
 0:         (mlp): TEFusedMLP(
 0:           (0): RMSNorm()
 0:           (1): Linear(
 0:             (basic_ops): ModuleList(
 0:               (0): BasicLinear()
 0:             )
 0:           )
 0:           (2): SwiGLU()
 0:           (3): Linear(
 0:             (basic_ops): ModuleList(
 0:               (0): BasicLinear()
 0:             )
 0:           )
 0:         )
 0:       )
 0:     )
 0:     (final_layernorm): RMSNorm()
 0:   )
 0:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 0: )
 0: 
 0: MCore config:
25: GPTModel(
25:   (embedding): LanguageModelEmbedding(
25:     (word_embeddings): VocabParallelEmbedding()
25:     (embedding_dropout): Dropout(p=0.0, inplace=False)
25:   )
25:   (rotary_pos_emb): RotaryEmbedding()
25:   (decoder): TransformerBlock(
25:     (layers): ModuleList(
25:       (0-31): 32 x TransformerLayer(
25:         (input_layernorm): IdentityOp()
25:         (self_attention): SelfAttention(
25:           (core_attention): TEDotProductAttention(
25:             (flash_attention): FlashAttention()
25:             (fused_attention): FusedAttention()
25:             (unfused_attention): UnfusedDotProductAttention(
25:               (scale_mask_softmax): FusedScaleMaskSoftmax()
25:               (attention_dropout): Dropout(p=0.0, inplace=False)
25:             )
25:           )
25:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
25:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
25:           (q_layernorm): IdentityOp()
25:           (k_layernorm): IdentityOp()
49: GPTModel(
49:   (embedding): LanguageModelEmbedding(
49:     (word_embeddings): VocabParallelEmbedding()
49:     (embedding_dropout): Dropout(p=0.0, inplace=False)
49:   )
49:   (rotary_pos_emb): RotaryEmbedding()
49:   (decoder): TransformerBlock(
49:     (layers): ModuleList(
49:       (0-31): 32 x TransformerLayer(
49:         (input_layernorm): IdentityOp()
49:         (self_attention): SelfAttention(
49:           (core_attention): TEDotProductAttention(
49:             (flash_attention): FlashAttention()
49:             (fused_attention): FusedAttention()
49:             (unfused_attention): UnfusedDotProductAttention(
49:               (scale_mask_softmax): FusedScaleMaskSoftmax()
49:               (attention_dropout): Dropout(p=0.0, inplace=False)
49:             )
49:           )
49:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
49:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
49:           (q_layernorm): IdentityOp()
49:           (k_layernorm): IdentityOp()
56: GPTModel(
56:   (embedding): LanguageModelEmbedding(
56:     (word_embeddings): VocabParallelEmbedding()
56:     (embedding_dropout): Dropout(p=0.0, inplace=False)
56:   )
56:   (rotary_pos_emb): RotaryEmbedding()
56:   (decoder): TransformerBlock(
56:     (layers): ModuleList(
56:       (0-31): 32 x TransformerLayer(
56:         (input_layernorm): IdentityOp()
56:         (self_attention): SelfAttention(
56:           (core_attention): TEDotProductAttention(
56:             (flash_attention): FlashAttention()
56:             (fused_attention): FusedAttention()
56:             (unfused_attention): UnfusedDotProductAttention(
56:               (scale_mask_softmax): FusedScaleMaskSoftmax()
56:               (attention_dropout): Dropout(p=0.0, inplace=False)
56:             )
56:           )
56:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
56:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
56:           (q_layernorm): IdentityOp()
56:           (k_layernorm): IdentityOp()
 1: GPTModel(
 1:   (embedding): LanguageModelEmbedding(
 1:     (word_embeddings): VocabParallelEmbedding()
 1:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 1:   )
 1:   (rotary_pos_emb): RotaryEmbedding()
 1:   (decoder): TransformerBlock(
 1:     (layers): ModuleList(
 1:       (0-31): 32 x TransformerLayer(
 1:         (input_layernorm): IdentityOp()
 1:         (self_attention): SelfAttention(
 1:           (core_attention): TEDotProductAttention(
 1:             (flash_attention): FlashAttention()
 1:             (fused_attention): FusedAttention()
 1:             (unfused_attention): UnfusedDotProductAttention(
 1:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 1:               (attention_dropout): Dropout(p=0.0, inplace=False)
 1:             )
 1:           )
 1:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 1:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 1:           (q_layernorm): IdentityOp()
 1:           (k_layernorm): IdentityOp()
49:         )
49:         (pre_cross_attn_layernorm): IdentityOp()
49:         (cross_attention): IdentityOp()
49:         (cross_attn_bda): IdentityFuncOp()
49:         (pre_mlp_layernorm): IdentityOp()
49:         (mlp): TEFusedMLP(
49:           (0): RMSNorm()
49:           (1): Linear(
49:             (basic_ops): ModuleList(
49:               (0): BasicLinear()
49:             )
49:           )
49:           (2): SwiGLU()
49:           (3): Linear(
49:             (basic_ops): ModuleList(
49:               (0): BasicLinear()
49:             )
49:           )
49:         )
49:       )
49:     )
49:     (final_layernorm): RMSNorm()
49:   )
49:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
49: )
56:         )
56:         (pre_cross_attn_layernorm): IdentityOp()
56:         (cross_attention): IdentityOp()
56:         (cross_attn_bda): IdentityFuncOp()
56:         (pre_mlp_layernorm): IdentityOp()
56:         (mlp): TEFusedMLP(
56:           (0): RMSNorm()
56:           (1): Linear(
56:             (basic_ops): ModuleList(
56:               (0): BasicLinear()
56:             )
56:           )
56:           (2): SwiGLU()
56:           (3): Linear(
56:             (basic_ops): ModuleList(
56:               (0): BasicLinear()
56:             )
56:           )
56:         )
56:       )
56:     )
56:     (final_layernorm): RMSNorm()
56:   )
56:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
56: )
 1:         )
 1:         (pre_cross_attn_layernorm): IdentityOp()
 1:         (cross_attention): IdentityOp()
 1:         (cross_attn_bda): IdentityFuncOp()
 1:         (pre_mlp_layernorm): IdentityOp()
 1:         (mlp): TEFusedMLP(
 1:           (0): RMSNorm()
 1:           (1): Linear(
 1:             (basic_ops): ModuleList(
 1:               (0): BasicLinear()
 1:             )
 1:           )
 1:           (2): SwiGLU()
 1:           (3): Linear(
 1:             (basic_ops): ModuleList(
 1:               (0): BasicLinear()
 1:             )
 1:           )
 1:         )
 1:       )
 1:     )
 1:     (final_layernorm): RMSNorm()
 1:   )
 1:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
48: GPTModel(
48:   (embedding): LanguageModelEmbedding(
48:     (word_embeddings): VocabParallelEmbedding()
48:     (embedding_dropout): Dropout(p=0.0, inplace=False)
48:   )
48:   (rotary_pos_emb): RotaryEmbedding()
48:   (decoder): TransformerBlock(
48:     (layers): ModuleList(
48:       (0-31): 32 x TransformerLayer(
48:         (input_layernorm): IdentityOp()
48:         (self_attention): SelfAttention(
48:           (core_attention): TEDotProductAttention(
48:             (flash_attention): FlashAttention()
48:             (fused_attention): FusedAttention()
48:             (unfused_attention): UnfusedDotProductAttention(
48:               (scale_mask_softmax): FusedScaleMaskSoftmax()
48:               (attention_dropout): Dropout(p=0.0, inplace=False)
48:             )
48:           )
48:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
48:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
48:           (q_layernorm): IdentityOp()
48:           (k_layernorm): IdentityOp()
25:         )
25:         (pre_cross_attn_layernorm): IdentityOp()
25:         (cross_attention): IdentityOp()
25:         (cross_attn_bda): IdentityFuncOp()
25:         (pre_mlp_layernorm): IdentityOp()
25:         (mlp): TEFusedMLP(
25:           (0): RMSNorm()
25:           (1): Linear(
25:             (basic_ops): ModuleList(
25:               (0): BasicLinear()
25:             )
25:           )
25:           (2): SwiGLU()
25:           (3): Linear(
25:             (basic_ops): ModuleList(
25:               (0): BasicLinear()
25:             )
25:           )
25:         )
25:       )
25:     )
25:     (final_layernorm): RMSNorm()
25:   )
25:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
25: )
 1: )
48:         )
48:         (pre_cross_attn_layernorm): IdentityOp()
48:         (cross_attention): IdentityOp()
48:         (cross_attn_bda): IdentityFuncOp()
48:         (pre_mlp_layernorm): IdentityOp()
48:         (mlp): TEFusedMLP(
48:           (0): RMSNorm()
48:           (1): Linear(
48:             (basic_ops): ModuleList(
48:               (0): BasicLinear()
48:             )
48:           )
48:           (2): SwiGLU()
48:           (3): Linear(
48:             (basic_ops): ModuleList(
48:               (0): BasicLinear()
48:             )
48:           )
48:         )
48:       )
48:     )
48:     (final_layernorm): RMSNorm()
48:   )
48:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
48: )
24: GPTModel(
24:   (embedding): LanguageModelEmbedding(
24:     (word_embeddings): VocabParallelEmbedding()
24:     (embedding_dropout): Dropout(p=0.0, inplace=False)
24:   )
24:   (rotary_pos_emb): RotaryEmbedding()
24:   (decoder): TransformerBlock(
24:     (layers): ModuleList(
24:       (0-31): 32 x TransformerLayer(
24:         (input_layernorm): IdentityOp()
24:         (self_attention): SelfAttention(
24:           (core_attention): TEDotProductAttention(
24:             (flash_attention): FlashAttention()
24:             (fused_attention): FusedAttention()
24:             (unfused_attention): UnfusedDotProductAttention(
24:               (scale_mask_softmax): FusedScaleMaskSoftmax()
24:               (attention_dropout): Dropout(p=0.0, inplace=False)
24:             )
24:           )
24:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
24:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
24:           (q_layernorm): IdentityOp()
24:           (k_layernorm): IdentityOp()
50: GPTModel(
50:   (embedding): LanguageModelEmbedding(
50:     (word_embeddings): VocabParallelEmbedding()
50:     (embedding_dropout): Dropout(p=0.0, inplace=False)
50:   )
50:   (rotary_pos_emb): RotaryEmbedding()
50:   (decoder): TransformerBlock(
50:     (layers): ModuleList(
50:       (0-31): 32 x TransformerLayer(
50:         (input_layernorm): IdentityOp()
50:         (self_attention): SelfAttention(
50:           (core_attention): TEDotProductAttention(
50:             (flash_attention): FlashAttention()
50:             (fused_attention): FusedAttention()
50:             (unfused_attention): UnfusedDotProductAttention(
50:               (scale_mask_softmax): FusedScaleMaskSoftmax()
50:               (attention_dropout): Dropout(p=0.0, inplace=False)
50:             )
50:           )
50:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
50:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
50:           (q_layernorm): IdentityOp()
50:           (k_layernorm): IdentityOp()
40: GPTModel(
40:   (embedding): LanguageModelEmbedding(
40:     (word_embeddings): VocabParallelEmbedding()
40:     (embedding_dropout): Dropout(p=0.0, inplace=False)
40:   )
40:   (rotary_pos_emb): RotaryEmbedding()
40:   (decoder): TransformerBlock(
40:     (layers): ModuleList(
40:       (0-31): 32 x TransformerLayer(
40:         (input_layernorm): IdentityOp()
40:         (self_attention): SelfAttention(
40:           (core_attention): TEDotProductAttention(
40:             (flash_attention): FlashAttention()
40:             (fused_attention): FusedAttention()
40:             (unfused_attention): UnfusedDotProductAttention(
40:               (scale_mask_softmax): FusedScaleMaskSoftmax()
40:               (attention_dropout): Dropout(p=0.0, inplace=False)
40:             )
40:           )
40:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
40:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
40:           (q_layernorm): IdentityOp()
40:           (k_layernorm): IdentityOp()
24:         )
24:         (pre_cross_attn_layernorm): IdentityOp()
24:         (cross_attention): IdentityOp()
24:         (cross_attn_bda): IdentityFuncOp()
24:         (pre_mlp_layernorm): IdentityOp()
24:         (mlp): TEFusedMLP(
24:           (0): RMSNorm()
24:           (1): Linear(
24:             (basic_ops): ModuleList(
24:               (0): BasicLinear()
24:             )
24:           )
24:           (2): SwiGLU()
24:           (3): Linear(
24:             (basic_ops): ModuleList(
24:               (0): BasicLinear()
24:             )
24:           )
24:         )
24:       )
24:     )
24:     (final_layernorm): RMSNorm()
24:   )
24:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
24: )
50:         )
50:         (pre_cross_attn_layernorm): IdentityOp()
50:         (cross_attention): IdentityOp()
50:         (cross_attn_bda): IdentityFuncOp()
50:         (pre_mlp_layernorm): IdentityOp()
50:         (mlp): TEFusedMLP(
50:           (0): RMSNorm()
50:           (1): Linear(
50:             (basic_ops): ModuleList(
50:               (0): BasicLinear()
50:             )
50:           )
50:           (2): SwiGLU()
50:           (3): Linear(
50:             (basic_ops): ModuleList(
50:               (0): BasicLinear()
50:             )
50:           )
50:         )
50:       )
50:     )
50:     (final_layernorm): RMSNorm()
50:   )
50:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
50: )
58: GPTModel(
58:   (embedding): LanguageModelEmbedding(
58:     (word_embeddings): VocabParallelEmbedding()
58:     (embedding_dropout): Dropout(p=0.0, inplace=False)
58:   )
58:   (rotary_pos_emb): RotaryEmbedding()
58:   (decoder): TransformerBlock(
58:     (layers): ModuleList(
58:       (0-31): 32 x TransformerLayer(
58:         (input_layernorm): IdentityOp()
58:         (self_attention): SelfAttention(
58:           (core_attention): TEDotProductAttention(
58:             (flash_attention): FlashAttention()
58:             (fused_attention): FusedAttention()
58:             (unfused_attention): UnfusedDotProductAttention(
58:               (scale_mask_softmax): FusedScaleMaskSoftmax()
58:               (attention_dropout): Dropout(p=0.0, inplace=False)
58:             )
58:           )
58:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
58:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
58:           (q_layernorm): IdentityOp()
58:           (k_layernorm): IdentityOp()
26: GPTModel(
26:   (embedding): LanguageModelEmbedding(
26:     (word_embeddings): VocabParallelEmbedding()
26:     (embedding_dropout): Dropout(p=0.0, inplace=False)
26:   )
26:   (rotary_pos_emb): RotaryEmbedding()
26:   (decoder): TransformerBlock(
26:     (layers): ModuleList(
26:       (0-31): 32 x TransformerLayer(
26:         (input_layernorm): IdentityOp()
26:         (self_attention): SelfAttention(
26:           (core_attention): TEDotProductAttention(
26:             (flash_attention): FlashAttention()
26:             (fused_attention): FusedAttention()
26:             (unfused_attention): UnfusedDotProductAttention(
26:               (scale_mask_softmax): FusedScaleMaskSoftmax()
26:               (attention_dropout): Dropout(p=0.0, inplace=False)
26:             )
26:           )
26:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
26:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
26:           (q_layernorm): IdentityOp()
26:           (k_layernorm): IdentityOp()
40:         )
40:         (pre_cross_attn_layernorm): IdentityOp()
40:         (cross_attention): IdentityOp()
40:         (cross_attn_bda): IdentityFuncOp()
40:         (pre_mlp_layernorm): IdentityOp()
40:         (mlp): TEFusedMLP(
40:           (0): RMSNorm()
40:           (1): Linear(
40:             (basic_ops): ModuleList(
40:               (0): BasicLinear()
40:             )
40:           )
40:           (2): SwiGLU()
40:           (3): Linear(
40:             (basic_ops): ModuleList(
40:               (0): BasicLinear()
40:             )
40:           )
40:         )
40:       )
40:     )
40:     (final_layernorm): RMSNorm()
40:   )
40:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
40: )
26:         )
26:         (pre_cross_attn_layernorm): IdentityOp()
26:         (cross_attention): IdentityOp()
26:         (cross_attn_bda): IdentityFuncOp()
26:         (pre_mlp_layernorm): IdentityOp()
26:         (mlp): TEFusedMLP(
26:           (0): RMSNorm()
26:           (1): Linear(
26:             (basic_ops): ModuleList(
26:               (0): BasicLinear()
26:             )
26:           )
26:           (2): SwiGLU()
26:           (3): Linear(
26:             (basic_ops): ModuleList(
26:               (0): BasicLinear()
26:             )
26:           )
26:         )
26:       )
26:     )
26:     (final_layernorm): RMSNorm()
26:   )
26:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
26: )
 2: GPTModel(
 2:   (embedding): LanguageModelEmbedding(
 2:     (word_embeddings): VocabParallelEmbedding()
 2:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 2:   )
 2:   (rotary_pos_emb): RotaryEmbedding()
 2:   (decoder): TransformerBlock(
 2:     (layers): ModuleList(
 2:       (0-31): 32 x TransformerLayer(
 2:         (input_layernorm): IdentityOp()
 2:         (self_attention): SelfAttention(
 2:           (core_attention): TEDotProductAttention(
 2:             (flash_attention): FlashAttention()
 2:             (fused_attention): FusedAttention()
 2:             (unfused_attention): UnfusedDotProductAttention(
 2:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 2:               (attention_dropout): Dropout(p=0.0, inplace=False)
 2:             )
 2:           )
 2:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 2:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 2:           (q_layernorm): IdentityOp()
 2:           (k_layernorm): IdentityOp()
16: GPTModel(
16:   (embedding): LanguageModelEmbedding(
16:     (word_embeddings): VocabParallelEmbedding()
16:     (embedding_dropout): Dropout(p=0.0, inplace=False)
16:   )
16:   (rotary_pos_emb): RotaryEmbedding()
16:   (decoder): TransformerBlock(
16:     (layers): ModuleList(
16:       (0-31): 32 x TransformerLayer(
16:         (input_layernorm): IdentityOp()
16:         (self_attention): SelfAttention(
16:           (core_attention): TEDotProductAttention(
16:             (flash_attention): FlashAttention()
16:             (fused_attention): FusedAttention()
16:             (unfused_attention): UnfusedDotProductAttention(
16:               (scale_mask_softmax): FusedScaleMaskSoftmax()
16:               (attention_dropout): Dropout(p=0.0, inplace=False)
16:             )
16:           )
16:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
16:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
16:           (q_layernorm): IdentityOp()
16:           (k_layernorm): IdentityOp()
41: GPTModel(
41:   (embedding): LanguageModelEmbedding(
41:     (word_embeddings): VocabParallelEmbedding()
41:     (embedding_dropout): Dropout(p=0.0, inplace=False)
41:   )
41:   (rotary_pos_emb): RotaryEmbedding()
41:   (decoder): TransformerBlock(
41:     (layers): ModuleList(
41:       (0-31): 32 x TransformerLayer(
41:         (input_layernorm): IdentityOp()
41:         (self_attention): SelfAttention(
41:           (core_attention): TEDotProductAttention(
41:             (flash_attention): FlashAttention()
41:             (fused_attention): FusedAttention()
41:             (unfused_attention): UnfusedDotProductAttention(
41:               (scale_mask_softmax): FusedScaleMaskSoftmax()
41:               (attention_dropout): Dropout(p=0.0, inplace=False)
41:             )
41:           )
41:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
41:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
41:           (q_layernorm): IdentityOp()
41:           (k_layernorm): IdentityOp()
 8: GPTModel(
 8:   (embedding): LanguageModelEmbedding(
 8:     (word_embeddings): VocabParallelEmbedding()
 8:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 8:   )
 8:   (rotary_pos_emb): RotaryEmbedding()
 8:   (decoder): TransformerBlock(
 8:     (layers): ModuleList(
 8:       (0-31): 32 x TransformerLayer(
 8:         (input_layernorm): IdentityOp()
 8:         (self_attention): SelfAttention(
 8:           (core_attention): TEDotProductAttention(
 8:             (flash_attention): FlashAttention()
 8:             (fused_attention): FusedAttention()
 8:             (unfused_attention): UnfusedDotProductAttention(
 8:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 8:               (attention_dropout): Dropout(p=0.0, inplace=False)
 8:             )
 8:           )
 8:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 8:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 8:           (q_layernorm): IdentityOp()
 8:           (k_layernorm): IdentityOp()
 2:         )
 2:         (pre_cross_attn_layernorm): IdentityOp()
 2:         (cross_attention): IdentityOp()
 2:         (cross_attn_bda): IdentityFuncOp()
 2:         (pre_mlp_layernorm): IdentityOp()
 2:         (mlp): TEFusedMLP(
 2:           (0): RMSNorm()
 2:           (1): Linear(
 2:             (basic_ops): ModuleList(
 2:               (0): BasicLinear()
 2:             )
 2:           )
 2:           (2): SwiGLU()
 2:           (3): Linear(
 2:             (basic_ops): ModuleList(
 2:               (0): BasicLinear()
 2:             )
 2:           )
 2:         )
 2:       )
 2:     )
 2:     (final_layernorm): RMSNorm()
 2:   )
 2:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 2: )
58:         )
58:         (pre_cross_attn_layernorm): IdentityOp()
58:         (cross_attention): IdentityOp()
58:         (cross_attn_bda): IdentityFuncOp()
58:         (pre_mlp_layernorm): IdentityOp()
58:         (mlp): TEFusedMLP(
58:           (0): RMSNorm()
58:           (1): Linear(
58:             (basic_ops): ModuleList(
58:               (0): BasicLinear()
58:             )
58:           )
58:           (2): SwiGLU()
58:           (3): Linear(
58:             (basic_ops): ModuleList(
58:               (0): BasicLinear()
58:             )
58:           )
58:         )
58:       )
58:     )
58:     (final_layernorm): RMSNorm()
58:   )
58:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
16:         )
16:         (pre_cross_attn_layernorm): IdentityOp()
16:         (cross_attention): IdentityOp()
16:         (cross_attn_bda): IdentityFuncOp()
16:         (pre_mlp_layernorm): IdentityOp()
16:         (mlp): TEFusedMLP(
16:           (0): RMSNorm()
16:           (1): Linear(
16:             (basic_ops): ModuleList(
16:               (0): BasicLinear()
16:             )
16:           )
16:           (2): SwiGLU()
16:           (3): Linear(
16:             (basic_ops): ModuleList(
16:               (0): BasicLinear()
16:             )
16:           )
16:         )
16:       )
16:     )
16:     (final_layernorm): RMSNorm()
16:   )
16:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
16: )
41:         )
41:         (pre_cross_attn_layernorm): IdentityOp()
41:         (cross_attention): IdentityOp()
41:         (cross_attn_bda): IdentityFuncOp()
41:         (pre_mlp_layernorm): IdentityOp()
41:         (mlp): TEFusedMLP(
41:           (0): RMSNorm()
41:           (1): Linear(
41:             (basic_ops): ModuleList(
41:               (0): BasicLinear()
41:             )
41:           )
41:           (2): SwiGLU()
41:           (3): Linear(
41:             (basic_ops): ModuleList(
41:               (0): BasicLinear()
41:             )
41:           )
41:         )
41:       )
41:     )
41:     (final_layernorm): RMSNorm()
41:   )
41:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
41: )
 8:         )
 8:         (pre_cross_attn_layernorm): IdentityOp()
 8:         (cross_attention): IdentityOp()
 8:         (cross_attn_bda): IdentityFuncOp()
 8:         (pre_mlp_layernorm): IdentityOp()
 8:         (mlp): TEFusedMLP(
 8:           (0): RMSNorm()
 8:           (1): Linear(
 8:             (basic_ops): ModuleList(
 8:               (0): BasicLinear()
 8:             )
 8:           )
 8:           (2): SwiGLU()
 8:           (3): Linear(
 8:             (basic_ops): ModuleList(
 8:               (0): BasicLinear()
 8:             )
 8:           )
 8:         )
 8:       )
 8:     )
 8:     (final_layernorm): RMSNorm()
 8:   )
 8:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 8: )
57: GPTModel(
57:   (embedding): LanguageModelEmbedding(
57:     (word_embeddings): VocabParallelEmbedding()
57:     (embedding_dropout): Dropout(p=0.0, inplace=False)
57:   )
57:   (rotary_pos_emb): RotaryEmbedding()
57:   (decoder): TransformerBlock(
57:     (layers): ModuleList(
57:       (0-31): 32 x TransformerLayer(
57:         (input_layernorm): IdentityOp()
57:         (self_attention): SelfAttention(
57:           (core_attention): TEDotProductAttention(
57:             (flash_attention): FlashAttention()
57:             (fused_attention): FusedAttention()
57:             (unfused_attention): UnfusedDotProductAttention(
57:               (scale_mask_softmax): FusedScaleMaskSoftmax()
57:               (attention_dropout): Dropout(p=0.0, inplace=False)
57:             )
57:           )
57:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
57:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
57:           (q_layernorm): IdentityOp()
57:           (k_layernorm): IdentityOp()
17: GPTModel(
17:   (embedding): LanguageModelEmbedding(
17:     (word_embeddings): VocabParallelEmbedding()
17:     (embedding_dropout): Dropout(p=0.0, inplace=False)
17:   )
17:   (rotary_pos_emb): RotaryEmbedding()
17:   (decoder): TransformerBlock(
17:     (layers): ModuleList(
17:       (0-31): 32 x TransformerLayer(
17:         (input_layernorm): IdentityOp()
17:         (self_attention): SelfAttention(
17:           (core_attention): TEDotProductAttention(
17:             (flash_attention): FlashAttention()
17:             (fused_attention): FusedAttention()
17:             (unfused_attention): UnfusedDotProductAttention(
17:               (scale_mask_softmax): FusedScaleMaskSoftmax()
17:               (attention_dropout): Dropout(p=0.0, inplace=False)
17:             )
17:           )
17:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
17:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
17:           (q_layernorm): IdentityOp()
17:           (k_layernorm): IdentityOp()
 9: GPTModel(
 9:   (embedding): LanguageModelEmbedding(
 9:     (word_embeddings): VocabParallelEmbedding()
 9:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 9:   )
 9:   (rotary_pos_emb): RotaryEmbedding()
 9:   (decoder): TransformerBlock(
 9:     (layers): ModuleList(
 9:       (0-31): 32 x TransformerLayer(
 9:         (input_layernorm): IdentityOp()
 9:         (self_attention): SelfAttention(
 9:           (core_attention): TEDotProductAttention(
 9:             (flash_attention): FlashAttention()
 9:             (fused_attention): FusedAttention()
 9:             (unfused_attention): UnfusedDotProductAttention(
 9:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 9:               (attention_dropout): Dropout(p=0.0, inplace=False)
 9:             )
 9:           )
 9:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 9:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 9:           (q_layernorm): IdentityOp()
 9:           (k_layernorm): IdentityOp()
57:         )
57:         (pre_cross_attn_layernorm): IdentityOp()
57:         (cross_attention): IdentityOp()
57:         (cross_attn_bda): IdentityFuncOp()
57:         (pre_mlp_layernorm): IdentityOp()
57:         (mlp): TEFusedMLP(
57:           (0): RMSNorm()
57:           (1): Linear(
57:             (basic_ops): ModuleList(
57:               (0): BasicLinear()
57:             )
57:           )
57:           (2): SwiGLU()
57:           (3): Linear(
57:             (basic_ops): ModuleList(
57:               (0): BasicLinear()
57:             )
57:           )
57:         )
57:       )
57:     )
57:     (final_layernorm): RMSNorm()
57:   )
57:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
17:         )
17:         (pre_cross_attn_layernorm): IdentityOp()
17:         (cross_attention): IdentityOp()
17:         (cross_attn_bda): IdentityFuncOp()
17:         (pre_mlp_layernorm): IdentityOp()
17:         (mlp): TEFusedMLP(
17:           (0): RMSNorm()
17:           (1): Linear(
17:             (basic_ops): ModuleList(
17:               (0): BasicLinear()
17:             )
17:           )
17:           (2): SwiGLU()
17:           (3): Linear(
17:             (basic_ops): ModuleList(
17:               (0): BasicLinear()
17:             )
17:           )
17:         )
17:       )
17:     )
17:     (final_layernorm): RMSNorm()
17:   )
17:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
17: )
 9:         )
 9:         (pre_cross_attn_layernorm): IdentityOp()
 9:         (cross_attention): IdentityOp()
 9:         (cross_attn_bda): IdentityFuncOp()
 9:         (pre_mlp_layernorm): IdentityOp()
 9:         (mlp): TEFusedMLP(
 9:           (0): RMSNorm()
 9:           (1): Linear(
 9:             (basic_ops): ModuleList(
 9:               (0): BasicLinear()
 9:             )
 9:           )
 9:           (2): SwiGLU()
 9:           (3): Linear(
 9:             (basic_ops): ModuleList(
 9:               (0): BasicLinear()
 9:             )
 9:           )
 9:         )
 9:       )
 9:     )
 9:     (final_layernorm): RMSNorm()
 9:   )
 9:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
58: )
18: GPTModel(
18:   (embedding): LanguageModelEmbedding(
18:     (word_embeddings): VocabParallelEmbedding()
18:     (embedding_dropout): Dropout(p=0.0, inplace=False)
18:   )
18:   (rotary_pos_emb): RotaryEmbedding()
18:   (decoder): TransformerBlock(
18:     (layers): ModuleList(
18:       (0-31): 32 x TransformerLayer(
18:         (input_layernorm): IdentityOp()
18:         (self_attention): SelfAttention(
18:           (core_attention): TEDotProductAttention(
18:             (flash_attention): FlashAttention()
18:             (fused_attention): FusedAttention()
18:             (unfused_attention): UnfusedDotProductAttention(
18:               (scale_mask_softmax): FusedScaleMaskSoftmax()
18:               (attention_dropout): Dropout(p=0.0, inplace=False)
18:             )
18:           )
18:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
18:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
18:           (q_layernorm): IdentityOp()
18:           (k_layernorm): IdentityOp()
 9: )
57: )
18:         )
18:         (pre_cross_attn_layernorm): IdentityOp()
18:         (cross_attention): IdentityOp()
18:         (cross_attn_bda): IdentityFuncOp()
18:         (pre_mlp_layernorm): IdentityOp()
18:         (mlp): TEFusedMLP(
18:           (0): RMSNorm()
18:           (1): Linear(
18:             (basic_ops): ModuleList(
18:               (0): BasicLinear()
18:             )
18:           )
18:           (2): SwiGLU()
18:           (3): Linear(
18:             (basic_ops): ModuleList(
18:               (0): BasicLinear()
18:             )
18:           )
18:         )
18:       )
18:     )
18:     (final_layernorm): RMSNorm()
18:   )
18:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
18: )
42: GPTModel(
42:   (embedding): LanguageModelEmbedding(
42:     (word_embeddings): VocabParallelEmbedding()
42:     (embedding_dropout): Dropout(p=0.0, inplace=False)
42:   )
42:   (rotary_pos_emb): RotaryEmbedding()
42:   (decoder): TransformerBlock(
42:     (layers): ModuleList(
42:       (0-31): 32 x TransformerLayer(
42:         (input_layernorm): IdentityOp()
42:         (self_attention): SelfAttention(
42:           (core_attention): TEDotProductAttention(
42:             (flash_attention): FlashAttention()
42:             (fused_attention): FusedAttention()
42:             (unfused_attention): UnfusedDotProductAttention(
42:               (scale_mask_softmax): FusedScaleMaskSoftmax()
42:               (attention_dropout): Dropout(p=0.0, inplace=False)
42:             )
42:           )
42:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
42:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
42:           (q_layernorm): IdentityOp()
42:           (k_layernorm): IdentityOp()
27: GPTModel(
27:   (embedding): LanguageModelEmbedding(
27:     (word_embeddings): VocabParallelEmbedding()
27:     (embedding_dropout): Dropout(p=0.0, inplace=False)
27:   )
27:   (rotary_pos_emb): RotaryEmbedding()
27:   (decoder): TransformerBlock(
27:     (layers): ModuleList(
27:       (0-31): 32 x TransformerLayer(
27:         (input_layernorm): IdentityOp()
27:         (self_attention): SelfAttention(
27:           (core_attention): TEDotProductAttention(
27:             (flash_attention): FlashAttention()
27:             (fused_attention): FusedAttention()
27:             (unfused_attention): UnfusedDotProductAttention(
27:               (scale_mask_softmax): FusedScaleMaskSoftmax()
27:               (attention_dropout): Dropout(p=0.0, inplace=False)
27:             )
27:           )
27:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
27:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
27:           (q_layernorm): IdentityOp()
27:           (k_layernorm): IdentityOp()
42:         )
42:         (pre_cross_attn_layernorm): IdentityOp()
42:         (cross_attention): IdentityOp()
42:         (cross_attn_bda): IdentityFuncOp()
42:         (pre_mlp_layernorm): IdentityOp()
42:         (mlp): TEFusedMLP(
42:           (0): RMSNorm()
42:           (1): Linear(
42:             (basic_ops): ModuleList(
42:               (0): BasicLinear()
42:             )
42:           )
42:           (2): SwiGLU()
42:           (3): Linear(
42:             (basic_ops): ModuleList(
42:               (0): BasicLinear()
42:             )
42:           )
42:         )
42:       )
42:     )
42:     (final_layernorm): RMSNorm()
42:   )
42:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
10: GPTModel(
10:   (embedding): LanguageModelEmbedding(
10:     (word_embeddings): VocabParallelEmbedding()
10:     (embedding_dropout): Dropout(p=0.0, inplace=False)
10:   )
10:   (rotary_pos_emb): RotaryEmbedding()
10:   (decoder): TransformerBlock(
10:     (layers): ModuleList(
10:       (0-31): 32 x TransformerLayer(
10:         (input_layernorm): IdentityOp()
10:         (self_attention): SelfAttention(
10:           (core_attention): TEDotProductAttention(
10:             (flash_attention): FlashAttention()
10:             (fused_attention): FusedAttention()
10:             (unfused_attention): UnfusedDotProductAttention(
10:               (scale_mask_softmax): FusedScaleMaskSoftmax()
10:               (attention_dropout): Dropout(p=0.0, inplace=False)
10:             )
10:           )
10:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
10:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
10:           (q_layernorm): IdentityOp()
10:           (k_layernorm): IdentityOp()
19: GPTModel(
19:   (embedding): LanguageModelEmbedding(
19:     (word_embeddings): VocabParallelEmbedding()
19:     (embedding_dropout): Dropout(p=0.0, inplace=False)
19:   )
19:   (rotary_pos_emb): RotaryEmbedding()
19:   (decoder): TransformerBlock(
19:     (layers): ModuleList(
19:       (0-31): 32 x TransformerLayer(
19:         (input_layernorm): IdentityOp()
19:         (self_attention): SelfAttention(
19:           (core_attention): TEDotProductAttention(
19:             (flash_attention): FlashAttention()
19:             (fused_attention): FusedAttention()
19:             (unfused_attention): UnfusedDotProductAttention(
19:               (scale_mask_softmax): FusedScaleMaskSoftmax()
19:               (attention_dropout): Dropout(p=0.0, inplace=False)
19:             )
19:           )
19:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
19:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
19:           (q_layernorm): IdentityOp()
19:           (k_layernorm): IdentityOp()
42: )
10:         )
10:         (pre_cross_attn_layernorm): IdentityOp()
10:         (cross_attention): IdentityOp()
10:         (cross_attn_bda): IdentityFuncOp()
10:         (pre_mlp_layernorm): IdentityOp()
10:         (mlp): TEFusedMLP(
10:           (0): RMSNorm()
10:           (1): Linear(
10:             (basic_ops): ModuleList(
10:               (0): BasicLinear()
10:             )
10:           )
10:           (2): SwiGLU()
10:           (3): Linear(
10:             (basic_ops): ModuleList(
10:               (0): BasicLinear()
10:             )
10:           )
10:         )
10:       )
10:     )
10:     (final_layernorm): RMSNorm()
10:   )
10:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
19:         )
19:         (pre_cross_attn_layernorm): IdentityOp()
19:         (cross_attention): IdentityOp()
19:         (cross_attn_bda): IdentityFuncOp()
19:         (pre_mlp_layernorm): IdentityOp()
19:         (mlp): TEFusedMLP(
19:           (0): RMSNorm()
19:           (1): Linear(
19:             (basic_ops): ModuleList(
19:               (0): BasicLinear()
19:             )
19:           )
19:           (2): SwiGLU()
19:           (3): Linear(
19:             (basic_ops): ModuleList(
19:               (0): BasicLinear()
19:             )
19:           )
19:         )
19:       )
19:     )
19:     (final_layernorm): RMSNorm()
19:   )
19:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
19: )
43: GPTModel(
43:   (embedding): LanguageModelEmbedding(
43:     (word_embeddings): VocabParallelEmbedding()
43:     (embedding_dropout): Dropout(p=0.0, inplace=False)
43:   )
43:   (rotary_pos_emb): RotaryEmbedding()
43:   (decoder): TransformerBlock(
43:     (layers): ModuleList(
43:       (0-31): 32 x TransformerLayer(
43:         (input_layernorm): IdentityOp()
43:         (self_attention): SelfAttention(
43:           (core_attention): TEDotProductAttention(
43:             (flash_attention): FlashAttention()
43:             (fused_attention): FusedAttention()
43:             (unfused_attention): UnfusedDotProductAttention(
43:               (scale_mask_softmax): FusedScaleMaskSoftmax()
43:               (attention_dropout): Dropout(p=0.0, inplace=False)
43:             )
43:           )
43:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
43:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
43:           (q_layernorm): IdentityOp()
43:           (k_layernorm): IdentityOp()
10: )
43:         )
43:         (pre_cross_attn_layernorm): IdentityOp()
43:         (cross_attention): IdentityOp()
43:         (cross_attn_bda): IdentityFuncOp()
43:         (pre_mlp_layernorm): IdentityOp()
43:         (mlp): TEFusedMLP(
43:           (0): RMSNorm()
43:           (1): Linear(
43:             (basic_ops): ModuleList(
43:               (0): BasicLinear()
43:             )
43:           )
43:           (2): SwiGLU()
43:           (3): Linear(
43:             (basic_ops): ModuleList(
43:               (0): BasicLinear()
43:             )
43:           )
43:         )
43:       )
43:     )
43:     (final_layernorm): RMSNorm()
43:   )
43:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
33: GPTModel(
33:   (embedding): LanguageModelEmbedding(
33:     (word_embeddings): VocabParallelEmbedding()
33:     (embedding_dropout): Dropout(p=0.0, inplace=False)
33:   )
33:   (rotary_pos_emb): RotaryEmbedding()
33:   (decoder): TransformerBlock(
33:     (layers): ModuleList(
33:       (0-31): 32 x TransformerLayer(
33:         (input_layernorm): IdentityOp()
33:         (self_attention): SelfAttention(
33:           (core_attention): TEDotProductAttention(
33:             (flash_attention): FlashAttention()
33:             (fused_attention): FusedAttention()
33:             (unfused_attention): UnfusedDotProductAttention(
33:               (scale_mask_softmax): FusedScaleMaskSoftmax()
33:               (attention_dropout): Dropout(p=0.0, inplace=False)
33:             )
33:           )
33:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
33:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
33:           (q_layernorm): IdentityOp()
33:           (k_layernorm): IdentityOp()
11: GPTModel(
11:   (embedding): LanguageModelEmbedding(
11:     (word_embeddings): VocabParallelEmbedding()
11:     (embedding_dropout): Dropout(p=0.0, inplace=False)
11:   )
11:   (rotary_pos_emb): RotaryEmbedding()
11:   (decoder): TransformerBlock(
11:     (layers): ModuleList(
11:       (0-31): 32 x TransformerLayer(
11:         (input_layernorm): IdentityOp()
11:         (self_attention): SelfAttention(
11:           (core_attention): TEDotProductAttention(
11:             (flash_attention): FlashAttention()
11:             (fused_attention): FusedAttention()
11:             (unfused_attention): UnfusedDotProductAttention(
11:               (scale_mask_softmax): FusedScaleMaskSoftmax()
11:               (attention_dropout): Dropout(p=0.0, inplace=False)
11:             )
11:           )
11:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
11:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
11:           (q_layernorm): IdentityOp()
11:           (k_layernorm): IdentityOp()
51: GPTModel(
51:   (embedding): LanguageModelEmbedding(
51:     (word_embeddings): VocabParallelEmbedding()
51:     (embedding_dropout): Dropout(p=0.0, inplace=False)
51:   )
51:   (rotary_pos_emb): RotaryEmbedding()
51:   (decoder): TransformerBlock(
51:     (layers): ModuleList(
51:       (0-31): 32 x TransformerLayer(
51:         (input_layernorm): IdentityOp()
51:         (self_attention): SelfAttention(
51:           (core_attention): TEDotProductAttention(
51:             (flash_attention): FlashAttention()
51:             (fused_attention): FusedAttention()
51:             (unfused_attention): UnfusedDotProductAttention(
51:               (scale_mask_softmax): FusedScaleMaskSoftmax()
51:               (attention_dropout): Dropout(p=0.0, inplace=False)
51:             )
51:           )
51:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
51:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
51:           (q_layernorm): IdentityOp()
51:           (k_layernorm): IdentityOp()
60: GPTModel(
60:   (embedding): LanguageModelEmbedding(
60:     (word_embeddings): VocabParallelEmbedding()
60:     (embedding_dropout): Dropout(p=0.0, inplace=False)
60:   )
60:   (rotary_pos_emb): RotaryEmbedding()
60:   (decoder): TransformerBlock(
60:     (layers): ModuleList(
60:       (0-31): 32 x TransformerLayer(
60:         (input_layernorm): IdentityOp()
60:         (self_attention): SelfAttention(
60:           (core_attention): TEDotProductAttention(
60:             (flash_attention): FlashAttention()
60:             (fused_attention): FusedAttention()
60:             (unfused_attention): UnfusedDotProductAttention(
60:               (scale_mask_softmax): FusedScaleMaskSoftmax()
60:               (attention_dropout): Dropout(p=0.0, inplace=False)
60:             )
60:           )
60:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
60:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
60:           (q_layernorm): IdentityOp()
60:           (k_layernorm): IdentityOp()
43: )
27:         )
27:         (pre_cross_attn_layernorm): IdentityOp()
27:         (cross_attention): IdentityOp()
27:         (cross_attn_bda): IdentityFuncOp()
27:         (pre_mlp_layernorm): IdentityOp()
27:         (mlp): TEFusedMLP(
27:           (0): RMSNorm()
27:           (1): Linear(
27:             (basic_ops): ModuleList(
27:               (0): BasicLinear()
27:             )
27:           )
27:           (2): SwiGLU()
27:           (3): Linear(
27:             (basic_ops): ModuleList(
27:               (0): BasicLinear()
27:             )
27:           )
27:         )
27:       )
27:     )
27:     (final_layernorm): RMSNorm()
27:   )
27:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
27: )
11:         )
11:         (pre_cross_attn_layernorm): IdentityOp()
11:         (cross_attention): IdentityOp()
11:         (cross_attn_bda): IdentityFuncOp()
11:         (pre_mlp_layernorm): IdentityOp()
11:         (mlp): TEFusedMLP(
11:           (0): RMSNorm()
11:           (1): Linear(
11:             (basic_ops): ModuleList(
11:               (0): BasicLinear()
11:             )
11:           )
11:           (2): SwiGLU()
11:           (3): Linear(
11:             (basic_ops): ModuleList(
11:               (0): BasicLinear()
11:             )
11:           )
11:         )
11:       )
11:     )
11:     (final_layernorm): RMSNorm()
11:   )
11:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
60:         )
60:         (pre_cross_attn_layernorm): IdentityOp()
60:         (cross_attention): IdentityOp()
60:         (cross_attn_bda): IdentityFuncOp()
60:         (pre_mlp_layernorm): IdentityOp()
60:         (mlp): TEFusedMLP(
60:           (0): RMSNorm()
60:           (1): Linear(
60:             (basic_ops): ModuleList(
60:               (0): BasicLinear()
60:             )
60:           )
60:           (2): SwiGLU()
60:           (3): Linear(
60:             (basic_ops): ModuleList(
60:               (0): BasicLinear()
60:             )
60:           )
60:         )
60:       )
60:     )
60:     (final_layernorm): RMSNorm()
60:   )
60:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
60: )
29: GPTModel(
29:   (embedding): LanguageModelEmbedding(
29:     (word_embeddings): VocabParallelEmbedding()
29:     (embedding_dropout): Dropout(p=0.0, inplace=False)
29:   )
29:   (rotary_pos_emb): RotaryEmbedding()
29:   (decoder): TransformerBlock(
29:     (layers): ModuleList(
29:       (0-31): 32 x TransformerLayer(
29:         (input_layernorm): IdentityOp()
29:         (self_attention): SelfAttention(
29:           (core_attention): TEDotProductAttention(
29:             (flash_attention): FlashAttention()
29:             (fused_attention): FusedAttention()
29:             (unfused_attention): UnfusedDotProductAttention(
29:               (scale_mask_softmax): FusedScaleMaskSoftmax()
29:               (attention_dropout): Dropout(p=0.0, inplace=False)
29:             )
29:           )
29:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
29:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
29:           (q_layernorm): IdentityOp()
29:           (k_layernorm): IdentityOp()
33:         )
33:         (pre_cross_attn_layernorm): IdentityOp()
33:         (cross_attention): IdentityOp()
33:         (cross_attn_bda): IdentityFuncOp()
33:         (pre_mlp_layernorm): IdentityOp()
33:         (mlp): TEFusedMLP(
33:           (0): RMSNorm()
33:           (1): Linear(
33:             (basic_ops): ModuleList(
33:               (0): BasicLinear()
33:             )
33:           )
33:           (2): SwiGLU()
33:           (3): Linear(
33:             (basic_ops): ModuleList(
33:               (0): BasicLinear()
33:             )
33:           )
33:         )
33:       )
33:     )
33:     (final_layernorm): RMSNorm()
33:   )
33:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
33: )
51:         )
51:         (pre_cross_attn_layernorm): IdentityOp()
51:         (cross_attention): IdentityOp()
51:         (cross_attn_bda): IdentityFuncOp()
51:         (pre_mlp_layernorm): IdentityOp()
51:         (mlp): TEFusedMLP(
51:           (0): RMSNorm()
51:           (1): Linear(
51:             (basic_ops): ModuleList(
51:               (0): BasicLinear()
51:             )
51:           )
51:           (2): SwiGLU()
51:           (3): Linear(
51:             (basic_ops): ModuleList(
51:               (0): BasicLinear()
51:             )
51:           )
51:         )
51:       )
51:     )
51:     (final_layernorm): RMSNorm()
51:   )
51:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
51: )
59: GPTModel(
59:   (embedding): LanguageModelEmbedding(
59:     (word_embeddings): VocabParallelEmbedding()
59:     (embedding_dropout): Dropout(p=0.0, inplace=False)
59:   )
59:   (rotary_pos_emb): RotaryEmbedding()
59:   (decoder): TransformerBlock(
59:     (layers): ModuleList(
59:       (0-31): 32 x TransformerLayer(
59:         (input_layernorm): IdentityOp()
59:         (self_attention): SelfAttention(
59:           (core_attention): TEDotProductAttention(
59:             (flash_attention): FlashAttention()
59:             (fused_attention): FusedAttention()
59:             (unfused_attention): UnfusedDotProductAttention(
59:               (scale_mask_softmax): FusedScaleMaskSoftmax()
59:               (attention_dropout): Dropout(p=0.0, inplace=False)
59:             )
59:           )
59:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
59:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
59:           (q_layernorm): IdentityOp()
59:           (k_layernorm): IdentityOp()
29:         )
29:         (pre_cross_attn_layernorm): IdentityOp()
29:         (cross_attention): IdentityOp()
29:         (cross_attn_bda): IdentityFuncOp()
29:         (pre_mlp_layernorm): IdentityOp()
29:         (mlp): TEFusedMLP(
29:           (0): RMSNorm()
29:           (1): Linear(
29:             (basic_ops): ModuleList(
29:               (0): BasicLinear()
29:             )
29:           )
29:           (2): SwiGLU()
29:           (3): Linear(
29:             (basic_ops): ModuleList(
29:               (0): BasicLinear()
29:             )
29:           )
29:         )
29:       )
29:     )
29:     (final_layernorm): RMSNorm()
29:   )
29:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
29: )
 3: GPTModel(
 3:   (embedding): LanguageModelEmbedding(
 3:     (word_embeddings): VocabParallelEmbedding()
 3:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 3:   )
 3:   (rotary_pos_emb): RotaryEmbedding()
 3:   (decoder): TransformerBlock(
 3:     (layers): ModuleList(
 3:       (0-31): 32 x TransformerLayer(
 3:         (input_layernorm): IdentityOp()
 3:         (self_attention): SelfAttention(
 3:           (core_attention): TEDotProductAttention(
 3:             (flash_attention): FlashAttention()
 3:             (fused_attention): FusedAttention()
 3:             (unfused_attention): UnfusedDotProductAttention(
 3:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 3:               (attention_dropout): Dropout(p=0.0, inplace=False)
 3:             )
 3:           )
 3:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 3:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 3:           (q_layernorm): IdentityOp()
 3:           (k_layernorm): IdentityOp()
52: GPTModel(
52:   (embedding): LanguageModelEmbedding(
52:     (word_embeddings): VocabParallelEmbedding()
52:     (embedding_dropout): Dropout(p=0.0, inplace=False)
52:   )
52:   (rotary_pos_emb): RotaryEmbedding()
52:   (decoder): TransformerBlock(
52:     (layers): ModuleList(
52:       (0-31): 32 x TransformerLayer(
52:         (input_layernorm): IdentityOp()
52:         (self_attention): SelfAttention(
52:           (core_attention): TEDotProductAttention(
52:             (flash_attention): FlashAttention()
52:             (fused_attention): FusedAttention()
52:             (unfused_attention): UnfusedDotProductAttention(
52:               (scale_mask_softmax): FusedScaleMaskSoftmax()
52:               (attention_dropout): Dropout(p=0.0, inplace=False)
52:             )
52:           )
52:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
52:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
52:           (q_layernorm): IdentityOp()
52:           (k_layernorm): IdentityOp()
59:         )
59:         (pre_cross_attn_layernorm): IdentityOp()
59:         (cross_attention): IdentityOp()
59:         (cross_attn_bda): IdentityFuncOp()
59:         (pre_mlp_layernorm): IdentityOp()
59:         (mlp): TEFusedMLP(
59:           (0): RMSNorm()
59:           (1): Linear(
59:             (basic_ops): ModuleList(
59:               (0): BasicLinear()
59:             )
59:           )
59:           (2): SwiGLU()
59:           (3): Linear(
59:             (basic_ops): ModuleList(
59:               (0): BasicLinear()
59:             )
59:           )
59:         )
59:       )
59:     )
59:     (final_layernorm): RMSNorm()
59:   )
59:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
59: )
30: GPTModel(
30:   (embedding): LanguageModelEmbedding(
30:     (word_embeddings): VocabParallelEmbedding()
30:     (embedding_dropout): Dropout(p=0.0, inplace=False)
30:   )
30:   (rotary_pos_emb): RotaryEmbedding()
30:   (decoder): TransformerBlock(
30:     (layers): ModuleList(
30:       (0-31): 32 x TransformerLayer(
30:         (input_layernorm): IdentityOp()
30:         (self_attention): SelfAttention(
30:           (core_attention): TEDotProductAttention(
30:             (flash_attention): FlashAttention()
30:             (fused_attention): FusedAttention()
30:             (unfused_attention): UnfusedDotProductAttention(
30:               (scale_mask_softmax): FusedScaleMaskSoftmax()
30:               (attention_dropout): Dropout(p=0.0, inplace=False)
30:             )
30:           )
30:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
30:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
30:           (q_layernorm): IdentityOp()
30:           (k_layernorm): IdentityOp()
 3:         )
 3:         (pre_cross_attn_layernorm): IdentityOp()
 3:         (cross_attention): IdentityOp()
 3:         (cross_attn_bda): IdentityFuncOp()
 3:         (pre_mlp_layernorm): IdentityOp()
 3:         (mlp): TEFusedMLP(
 3:           (0): RMSNorm()
 3:           (1): Linear(
 3:             (basic_ops): ModuleList(
 3:               (0): BasicLinear()
 3:             )
 3:           )
 3:           (2): SwiGLU()
 3:           (3): Linear(
 3:             (basic_ops): ModuleList(
 3:               (0): BasicLinear()
 3:             )
 3:           )
 3:         )
 3:       )
 3:     )
 3:     (final_layernorm): RMSNorm()
 3:   )
 3:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
52:         )
52:         (pre_cross_attn_layernorm): IdentityOp()
52:         (cross_attention): IdentityOp()
52:         (cross_attn_bda): IdentityFuncOp()
52:         (pre_mlp_layernorm): IdentityOp()
52:         (mlp): TEFusedMLP(
52:           (0): RMSNorm()
52:           (1): Linear(
52:             (basic_ops): ModuleList(
52:               (0): BasicLinear()
52:             )
52:           )
52:           (2): SwiGLU()
52:           (3): Linear(
52:             (basic_ops): ModuleList(
52:               (0): BasicLinear()
52:             )
52:           )
52:         )
52:       )
52:     )
52:     (final_layernorm): RMSNorm()
52:   )
52:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
52: )
61: GPTModel(
61:   (embedding): LanguageModelEmbedding(
61:     (word_embeddings): VocabParallelEmbedding()
61:     (embedding_dropout): Dropout(p=0.0, inplace=False)
61:   )
61:   (rotary_pos_emb): RotaryEmbedding()
61:   (decoder): TransformerBlock(
61:     (layers): ModuleList(
61:       (0-31): 32 x TransformerLayer(
61:         (input_layernorm): IdentityOp()
61:         (self_attention): SelfAttention(
61:           (core_attention): TEDotProductAttention(
61:             (flash_attention): FlashAttention()
61:             (fused_attention): FusedAttention()
61:             (unfused_attention): UnfusedDotProductAttention(
61:               (scale_mask_softmax): FusedScaleMaskSoftmax()
61:               (attention_dropout): Dropout(p=0.0, inplace=False)
61:             )
61:           )
61:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
61:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
61:           (q_layernorm): IdentityOp()
61:           (k_layernorm): IdentityOp()
30:         )
30:         (pre_cross_attn_layernorm): IdentityOp()
30:         (cross_attention): IdentityOp()
30:         (cross_attn_bda): IdentityFuncOp()
30:         (pre_mlp_layernorm): IdentityOp()
30:         (mlp): TEFusedMLP(
30:           (0): RMSNorm()
30:           (1): Linear(
30:             (basic_ops): ModuleList(
30:               (0): BasicLinear()
30:             )
30:           )
30:           (2): SwiGLU()
30:           (3): Linear(
30:             (basic_ops): ModuleList(
30:               (0): BasicLinear()
30:             )
30:           )
30:         )
30:       )
30:     )
30:     (final_layernorm): RMSNorm()
30:   )
30:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
30: )
 4: GPTModel(
 4:   (embedding): LanguageModelEmbedding(
 4:     (word_embeddings): VocabParallelEmbedding()
 4:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 4:   )
 4:   (rotary_pos_emb): RotaryEmbedding()
 4:   (decoder): TransformerBlock(
 4:     (layers): ModuleList(
 4:       (0-31): 32 x TransformerLayer(
 4:         (input_layernorm): IdentityOp()
 4:         (self_attention): SelfAttention(
 4:           (core_attention): TEDotProductAttention(
 4:             (flash_attention): FlashAttention()
 4:             (fused_attention): FusedAttention()
 4:             (unfused_attention): UnfusedDotProductAttention(
 4:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 4:               (attention_dropout): Dropout(p=0.0, inplace=False)
 4:             )
 4:           )
 4:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 4:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 4:           (q_layernorm): IdentityOp()
 4:           (k_layernorm): IdentityOp()
53: GPTModel(
53:   (embedding): LanguageModelEmbedding(
53:     (word_embeddings): VocabParallelEmbedding()
53:     (embedding_dropout): Dropout(p=0.0, inplace=False)
53:   )
53:   (rotary_pos_emb): RotaryEmbedding()
53:   (decoder): TransformerBlock(
53:     (layers): ModuleList(
53:       (0-31): 32 x TransformerLayer(
53:         (input_layernorm): IdentityOp()
53:         (self_attention): SelfAttention(
53:           (core_attention): TEDotProductAttention(
53:             (flash_attention): FlashAttention()
53:             (fused_attention): FusedAttention()
53:             (unfused_attention): UnfusedDotProductAttention(
53:               (scale_mask_softmax): FusedScaleMaskSoftmax()
53:               (attention_dropout): Dropout(p=0.0, inplace=False)
53:             )
53:           )
53:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
53:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
53:           (q_layernorm): IdentityOp()
53:           (k_layernorm): IdentityOp()
61:         )
61:         (pre_cross_attn_layernorm): IdentityOp()
61:         (cross_attention): IdentityOp()
61:         (cross_attn_bda): IdentityFuncOp()
61:         (pre_mlp_layernorm): IdentityOp()
61:         (mlp): TEFusedMLP(
61:           (0): RMSNorm()
61:           (1): Linear(
61:             (basic_ops): ModuleList(
61:               (0): BasicLinear()
61:             )
61:           )
61:           (2): SwiGLU()
61:           (3): Linear(
61:             (basic_ops): ModuleList(
61:               (0): BasicLinear()
61:             )
61:           )
61:         )
61:       )
61:     )
61:     (final_layernorm): RMSNorm()
61:   )
61:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
28: GPTModel(
28:   (embedding): LanguageModelEmbedding(
28:     (word_embeddings): VocabParallelEmbedding()
28:     (embedding_dropout): Dropout(p=0.0, inplace=False)
28:   )
28:   (rotary_pos_emb): RotaryEmbedding()
28:   (decoder): TransformerBlock(
28:     (layers): ModuleList(
28:       (0-31): 32 x TransformerLayer(
28:         (input_layernorm): IdentityOp()
28:         (self_attention): SelfAttention(
28:           (core_attention): TEDotProductAttention(
28:             (flash_attention): FlashAttention()
28:             (fused_attention): FusedAttention()
28:             (unfused_attention): UnfusedDotProductAttention(
28:               (scale_mask_softmax): FusedScaleMaskSoftmax()
28:               (attention_dropout): Dropout(p=0.0, inplace=False)
28:             )
28:           )
28:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
28:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
28:           (q_layernorm): IdentityOp()
28:           (k_layernorm): IdentityOp()
 4:         )
 4:         (pre_cross_attn_layernorm): IdentityOp()
 4:         (cross_attention): IdentityOp()
 4:         (cross_attn_bda): IdentityFuncOp()
 4:         (pre_mlp_layernorm): IdentityOp()
 4:         (mlp): TEFusedMLP(
 4:           (0): RMSNorm()
 4:           (1): Linear(
 4:             (basic_ops): ModuleList(
 4:               (0): BasicLinear()
 4:             )
 4:           )
 4:           (2): SwiGLU()
 4:           (3): Linear(
 4:             (basic_ops): ModuleList(
 4:               (0): BasicLinear()
 4:             )
 4:           )
 4:         )
 4:       )
 4:     )
 4:     (final_layernorm): RMSNorm()
 4:   )
 4:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 4: )
53:         )
53:         (pre_cross_attn_layernorm): IdentityOp()
53:         (cross_attention): IdentityOp()
53:         (cross_attn_bda): IdentityFuncOp()
53:         (pre_mlp_layernorm): IdentityOp()
53:         (mlp): TEFusedMLP(
53:           (0): RMSNorm()
53:           (1): Linear(
53:             (basic_ops): ModuleList(
53:               (0): BasicLinear()
53:             )
53:           )
53:           (2): SwiGLU()
53:           (3): Linear(
53:             (basic_ops): ModuleList(
53:               (0): BasicLinear()
53:             )
53:           )
53:         )
53:       )
53:     )
53:     (final_layernorm): RMSNorm()
53:   )
53:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
53: )
61: )
44: GPTModel(
44:   (embedding): LanguageModelEmbedding(
44:     (word_embeddings): VocabParallelEmbedding()
44:     (embedding_dropout): Dropout(p=0.0, inplace=False)
44:   )
44:   (rotary_pos_emb): RotaryEmbedding()
44:   (decoder): TransformerBlock(
44:     (layers): ModuleList(
44:       (0-31): 32 x TransformerLayer(
44:         (input_layernorm): IdentityOp()
44:         (self_attention): SelfAttention(
44:           (core_attention): TEDotProductAttention(
44:             (flash_attention): FlashAttention()
44:             (fused_attention): FusedAttention()
44:             (unfused_attention): UnfusedDotProductAttention(
44:               (scale_mask_softmax): FusedScaleMaskSoftmax()
44:               (attention_dropout): Dropout(p=0.0, inplace=False)
44:             )
44:           )
44:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
44:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
44:           (q_layernorm): IdentityOp()
44:           (k_layernorm): IdentityOp()
28:         )
28:         (pre_cross_attn_layernorm): IdentityOp()
28:         (cross_attention): IdentityOp()
28:         (cross_attn_bda): IdentityFuncOp()
28:         (pre_mlp_layernorm): IdentityOp()
28:         (mlp): TEFusedMLP(
28:           (0): RMSNorm()
28:           (1): Linear(
28:             (basic_ops): ModuleList(
28:               (0): BasicLinear()
28:             )
28:           )
28:           (2): SwiGLU()
28:           (3): Linear(
28:             (basic_ops): ModuleList(
28:               (0): BasicLinear()
28:             )
28:           )
28:         )
28:       )
28:     )
28:     (final_layernorm): RMSNorm()
28:   )
28:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
28: )
36: GPTModel(
36:   (embedding): LanguageModelEmbedding(
36:     (word_embeddings): VocabParallelEmbedding()
36:     (embedding_dropout): Dropout(p=0.0, inplace=False)
36:   )
36:   (rotary_pos_emb): RotaryEmbedding()
36:   (decoder): TransformerBlock(
36:     (layers): ModuleList(
36:       (0-31): 32 x TransformerLayer(
36:         (input_layernorm): IdentityOp()
36:         (self_attention): SelfAttention(
36:           (core_attention): TEDotProductAttention(
36:             (flash_attention): FlashAttention()
36:             (fused_attention): FusedAttention()
36:             (unfused_attention): UnfusedDotProductAttention(
36:               (scale_mask_softmax): FusedScaleMaskSoftmax()
36:               (attention_dropout): Dropout(p=0.0, inplace=False)
36:             )
36:           )
36:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
36:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
36:           (q_layernorm): IdentityOp()
36:           (k_layernorm): IdentityOp()
12: GPTModel(
12:   (embedding): LanguageModelEmbedding(
12:     (word_embeddings): VocabParallelEmbedding()
12:     (embedding_dropout): Dropout(p=0.0, inplace=False)
12:   )
12:   (rotary_pos_emb): RotaryEmbedding()
12:   (decoder): TransformerBlock(
12:     (layers): ModuleList(
12:       (0-31): 32 x TransformerLayer(
12:         (input_layernorm): IdentityOp()
12:         (self_attention): SelfAttention(
12:           (core_attention): TEDotProductAttention(
12:             (flash_attention): FlashAttention()
12:             (fused_attention): FusedAttention()
12:             (unfused_attention): UnfusedDotProductAttention(
12:               (scale_mask_softmax): FusedScaleMaskSoftmax()
12:               (attention_dropout): Dropout(p=0.0, inplace=False)
12:             )
12:           )
12:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
12:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
12:           (q_layernorm): IdentityOp()
12:           (k_layernorm): IdentityOp()
 3: )
54: GPTModel(
54:   (embedding): LanguageModelEmbedding(
54:     (word_embeddings): VocabParallelEmbedding()
54:     (embedding_dropout): Dropout(p=0.0, inplace=False)
54:   )
54:   (rotary_pos_emb): RotaryEmbedding()
54:   (decoder): TransformerBlock(
54:     (layers): ModuleList(
54:       (0-31): 32 x TransformerLayer(
54:         (input_layernorm): IdentityOp()
54:         (self_attention): SelfAttention(
54:           (core_attention): TEDotProductAttention(
54:             (flash_attention): FlashAttention()
54:             (fused_attention): FusedAttention()
54:             (unfused_attention): UnfusedDotProductAttention(
54:               (scale_mask_softmax): FusedScaleMaskSoftmax()
54:               (attention_dropout): Dropout(p=0.0, inplace=False)
54:             )
54:           )
54:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
54:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
54:           (q_layernorm): IdentityOp()
54:           (k_layernorm): IdentityOp()
62: GPTModel(
62:   (embedding): LanguageModelEmbedding(
62:     (word_embeddings): VocabParallelEmbedding()
62:     (embedding_dropout): Dropout(p=0.0, inplace=False)
62:   )
62:   (rotary_pos_emb): RotaryEmbedding()
62:   (decoder): TransformerBlock(
62:     (layers): ModuleList(
62:       (0-31): 32 x TransformerLayer(
62:         (input_layernorm): IdentityOp()
62:         (self_attention): SelfAttention(
62:           (core_attention): TEDotProductAttention(
62:             (flash_attention): FlashAttention()
62:             (fused_attention): FusedAttention()
62:             (unfused_attention): UnfusedDotProductAttention(
62:               (scale_mask_softmax): FusedScaleMaskSoftmax()
62:               (attention_dropout): Dropout(p=0.0, inplace=False)
62:             )
62:           )
62:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
62:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
62:           (q_layernorm): IdentityOp()
62:           (k_layernorm): IdentityOp()
20: GPTModel(
20:   (embedding): LanguageModelEmbedding(
20:     (word_embeddings): VocabParallelEmbedding()
20:     (embedding_dropout): Dropout(p=0.0, inplace=False)
20:   )
20:   (rotary_pos_emb): RotaryEmbedding()
20:   (decoder): TransformerBlock(
20:     (layers): ModuleList(
20:       (0-31): 32 x TransformerLayer(
20:         (input_layernorm): IdentityOp()
20:         (self_attention): SelfAttention(
20:           (core_attention): TEDotProductAttention(
20:             (flash_attention): FlashAttention()
20:             (fused_attention): FusedAttention()
20:             (unfused_attention): UnfusedDotProductAttention(
20:               (scale_mask_softmax): FusedScaleMaskSoftmax()
20:               (attention_dropout): Dropout(p=0.0, inplace=False)
20:             )
20:           )
20:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
20:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
20:           (q_layernorm): IdentityOp()
20:           (k_layernorm): IdentityOp()
31: GPTModel(
31:   (embedding): LanguageModelEmbedding(
31:     (word_embeddings): VocabParallelEmbedding()
31:     (embedding_dropout): Dropout(p=0.0, inplace=False)
31:   )
31:   (rotary_pos_emb): RotaryEmbedding()
31:   (decoder): TransformerBlock(
31:     (layers): ModuleList(
31:       (0-31): 32 x TransformerLayer(
31:         (input_layernorm): IdentityOp()
31:         (self_attention): SelfAttention(
31:           (core_attention): TEDotProductAttention(
31:             (flash_attention): FlashAttention()
31:             (fused_attention): FusedAttention()
31:             (unfused_attention): UnfusedDotProductAttention(
31:               (scale_mask_softmax): FusedScaleMaskSoftmax()
31:               (attention_dropout): Dropout(p=0.0, inplace=False)
31:             )
31:           )
31:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
31:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
31:           (q_layernorm): IdentityOp()
31:           (k_layernorm): IdentityOp()
12:         )
12:         (pre_cross_attn_layernorm): IdentityOp()
12:         (cross_attention): IdentityOp()
12:         (cross_attn_bda): IdentityFuncOp()
12:         (pre_mlp_layernorm): IdentityOp()
12:         (mlp): TEFusedMLP(
12:           (0): RMSNorm()
12:           (1): Linear(
12:             (basic_ops): ModuleList(
12:               (0): BasicLinear()
12:             )
12:           )
12:           (2): SwiGLU()
12:           (3): Linear(
12:             (basic_ops): ModuleList(
12:               (0): BasicLinear()
12:             )
12:           )
12:         )
12:       )
12:     )
12:     (final_layernorm): RMSNorm()
12:   )
12:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
12: )
 7: GPTModel(
 7:   (embedding): LanguageModelEmbedding(
 7:     (word_embeddings): VocabParallelEmbedding()
 7:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 7:   )
 7:   (rotary_pos_emb): RotaryEmbedding()
 7:   (decoder): TransformerBlock(
 7:     (layers): ModuleList(
 7:       (0-31): 32 x TransformerLayer(
 7:         (input_layernorm): IdentityOp()
 7:         (self_attention): SelfAttention(
 7:           (core_attention): TEDotProductAttention(
 7:             (flash_attention): FlashAttention()
 7:             (fused_attention): FusedAttention()
 7:             (unfused_attention): UnfusedDotProductAttention(
 7:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 7:               (attention_dropout): Dropout(p=0.0, inplace=False)
 7:             )
 7:           )
 7:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 7:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 7:           (q_layernorm): IdentityOp()
 7:           (k_layernorm): IdentityOp()
54:         )
54:         (pre_cross_attn_layernorm): IdentityOp()
54:         (cross_attention): IdentityOp()
54:         (cross_attn_bda): IdentityFuncOp()
54:         (pre_mlp_layernorm): IdentityOp()
54:         (mlp): TEFusedMLP(
54:           (0): RMSNorm()
54:           (1): Linear(
54:             (basic_ops): ModuleList(
54:               (0): BasicLinear()
54:             )
54:           )
54:           (2): SwiGLU()
54:           (3): Linear(
54:             (basic_ops): ModuleList(
54:               (0): BasicLinear()
54:             )
54:           )
54:         )
54:       )
54:     )
54:     (final_layernorm): RMSNorm()
54:   )
54:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
54: )
62:         )
62:         (pre_cross_attn_layernorm): IdentityOp()
62:         (cross_attention): IdentityOp()
62:         (cross_attn_bda): IdentityFuncOp()
62:         (pre_mlp_layernorm): IdentityOp()
62:         (mlp): TEFusedMLP(
62:           (0): RMSNorm()
62:           (1): Linear(
62:             (basic_ops): ModuleList(
62:               (0): BasicLinear()
62:             )
62:           )
62:           (2): SwiGLU()
62:           (3): Linear(
62:             (basic_ops): ModuleList(
62:               (0): BasicLinear()
62:             )
62:           )
62:         )
62:       )
62:     )
62:     (final_layernorm): RMSNorm()
62:   )
62:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
62: )
20:         )
20:         (pre_cross_attn_layernorm): IdentityOp()
20:         (cross_attention): IdentityOp()
20:         (cross_attn_bda): IdentityFuncOp()
20:         (pre_mlp_layernorm): IdentityOp()
20:         (mlp): TEFusedMLP(
20:           (0): RMSNorm()
20:           (1): Linear(
20:             (basic_ops): ModuleList(
20:               (0): BasicLinear()
20:             )
20:           )
20:           (2): SwiGLU()
20:           (3): Linear(
20:             (basic_ops): ModuleList(
20:               (0): BasicLinear()
20:             )
20:           )
20:         )
20:       )
20:     )
20:     (final_layernorm): RMSNorm()
20:   )
20:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
20: )
44:         )
44:         (pre_cross_attn_layernorm): IdentityOp()
44:         (cross_attention): IdentityOp()
44:         (cross_attn_bda): IdentityFuncOp()
44:         (pre_mlp_layernorm): IdentityOp()
44:         (mlp): TEFusedMLP(
44:           (0): RMSNorm()
44:           (1): Linear(
44:             (basic_ops): ModuleList(
44:               (0): BasicLinear()
44:             )
44:           )
44:           (2): SwiGLU()
44:           (3): Linear(
44:             (basic_ops): ModuleList(
44:               (0): BasicLinear()
44:             )
44:           )
44:         )
44:       )
44:     )
44:     (final_layernorm): RMSNorm()
44:   )
44:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
44: )
31:         )
31:         (pre_cross_attn_layernorm): IdentityOp()
31:         (cross_attention): IdentityOp()
31:         (cross_attn_bda): IdentityFuncOp()
31:         (pre_mlp_layernorm): IdentityOp()
31:         (mlp): TEFusedMLP(
31:           (0): RMSNorm()
31:           (1): Linear(
31:             (basic_ops): ModuleList(
31:               (0): BasicLinear()
31:             )
31:           )
31:           (2): SwiGLU()
31:           (3): Linear(
31:             (basic_ops): ModuleList(
31:               (0): BasicLinear()
31:             )
31:           )
31:         )
31:       )
31:     )
31:     (final_layernorm): RMSNorm()
31:   )
31:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
31: )
36:         )
36:         (pre_cross_attn_layernorm): IdentityOp()
36:         (cross_attention): IdentityOp()
36:         (cross_attn_bda): IdentityFuncOp()
36:         (pre_mlp_layernorm): IdentityOp()
36:         (mlp): TEFusedMLP(
36:           (0): RMSNorm()
36:           (1): Linear(
36:             (basic_ops): ModuleList(
36:               (0): BasicLinear()
36:             )
36:           )
36:           (2): SwiGLU()
36:           (3): Linear(
36:             (basic_ops): ModuleList(
36:               (0): BasicLinear()
36:             )
36:           )
36:         )
36:       )
36:     )
36:     (final_layernorm): RMSNorm()
36:   )
36:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
36: )
13: GPTModel(
13:   (embedding): LanguageModelEmbedding(
13:     (word_embeddings): VocabParallelEmbedding()
13:     (embedding_dropout): Dropout(p=0.0, inplace=False)
13:   )
13:   (rotary_pos_emb): RotaryEmbedding()
13:   (decoder): TransformerBlock(
13:     (layers): ModuleList(
13:       (0-31): 32 x TransformerLayer(
13:         (input_layernorm): IdentityOp()
13:         (self_attention): SelfAttention(
13:           (core_attention): TEDotProductAttention(
13:             (flash_attention): FlashAttention()
13:             (fused_attention): FusedAttention()
13:             (unfused_attention): UnfusedDotProductAttention(
13:               (scale_mask_softmax): FusedScaleMaskSoftmax()
13:               (attention_dropout): Dropout(p=0.0, inplace=False)
13:             )
13:           )
13:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
13:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
13:           (q_layernorm): IdentityOp()
13:           (k_layernorm): IdentityOp()
 7:         )
 7:         (pre_cross_attn_layernorm): IdentityOp()
 7:         (cross_attention): IdentityOp()
 7:         (cross_attn_bda): IdentityFuncOp()
 7:         (pre_mlp_layernorm): IdentityOp()
 7:         (mlp): TEFusedMLP(
 7:           (0): RMSNorm()
 7:           (1): Linear(
 7:             (basic_ops): ModuleList(
 7:               (0): BasicLinear()
 7:             )
 7:           )
 7:           (2): SwiGLU()
 7:           (3): Linear(
 7:             (basic_ops): ModuleList(
 7:               (0): BasicLinear()
 7:             )
 7:           )
 7:         )
 7:       )
 7:     )
 7:     (final_layernorm): RMSNorm()
 7:   )
 7:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 7: )
55: GPTModel(
55:   (embedding): LanguageModelEmbedding(
55:     (word_embeddings): VocabParallelEmbedding()
55:     (embedding_dropout): Dropout(p=0.0, inplace=False)
55:   )
55:   (rotary_pos_emb): RotaryEmbedding()
55:   (decoder): TransformerBlock(
55:     (layers): ModuleList(
55:       (0-31): 32 x TransformerLayer(
55:         (input_layernorm): IdentityOp()
55:         (self_attention): SelfAttention(
55:           (core_attention): TEDotProductAttention(
55:             (flash_attention): FlashAttention()
55:             (fused_attention): FusedAttention()
55:             (unfused_attention): UnfusedDotProductAttention(
55:               (scale_mask_softmax): FusedScaleMaskSoftmax()
55:               (attention_dropout): Dropout(p=0.0, inplace=False)
55:             )
55:           )
55:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
55:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
55:           (q_layernorm): IdentityOp()
55:           (k_layernorm): IdentityOp()
23: GPTModel(
23:   (embedding): LanguageModelEmbedding(
23:     (word_embeddings): VocabParallelEmbedding()
23:     (embedding_dropout): Dropout(p=0.0, inplace=False)
23:   )
23:   (rotary_pos_emb): RotaryEmbedding()
23:   (decoder): TransformerBlock(
23:     (layers): ModuleList(
23:       (0-31): 32 x TransformerLayer(
23:         (input_layernorm): IdentityOp()
23:         (self_attention): SelfAttention(
23:           (core_attention): TEDotProductAttention(
23:             (flash_attention): FlashAttention()
23:             (fused_attention): FusedAttention()
23:             (unfused_attention): UnfusedDotProductAttention(
23:               (scale_mask_softmax): FusedScaleMaskSoftmax()
23:               (attention_dropout): Dropout(p=0.0, inplace=False)
23:             )
23:           )
23:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
23:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
23:           (q_layernorm): IdentityOp()
23:           (k_layernorm): IdentityOp()
45: GPTModel(
45:   (embedding): LanguageModelEmbedding(
45:     (word_embeddings): VocabParallelEmbedding()
45:     (embedding_dropout): Dropout(p=0.0, inplace=False)
45:   )
45:   (rotary_pos_emb): RotaryEmbedding()
45:   (decoder): TransformerBlock(
45:     (layers): ModuleList(
45:       (0-31): 32 x TransformerLayer(
45:         (input_layernorm): IdentityOp()
45:         (self_attention): SelfAttention(
45:           (core_attention): TEDotProductAttention(
45:             (flash_attention): FlashAttention()
45:             (fused_attention): FusedAttention()
45:             (unfused_attention): UnfusedDotProductAttention(
45:               (scale_mask_softmax): FusedScaleMaskSoftmax()
45:               (attention_dropout): Dropout(p=0.0, inplace=False)
45:             )
45:           )
45:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
45:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
45:           (q_layernorm): IdentityOp()
45:           (k_layernorm): IdentityOp()
39: GPTModel(
39:   (embedding): LanguageModelEmbedding(
39:     (word_embeddings): VocabParallelEmbedding()
39:     (embedding_dropout): Dropout(p=0.0, inplace=False)
39:   )
39:   (rotary_pos_emb): RotaryEmbedding()
39:   (decoder): TransformerBlock(
39:     (layers): ModuleList(
39:       (0-31): 32 x TransformerLayer(
39:         (input_layernorm): IdentityOp()
39:         (self_attention): SelfAttention(
39:           (core_attention): TEDotProductAttention(
39:             (flash_attention): FlashAttention()
39:             (fused_attention): FusedAttention()
39:             (unfused_attention): UnfusedDotProductAttention(
39:               (scale_mask_softmax): FusedScaleMaskSoftmax()
39:               (attention_dropout): Dropout(p=0.0, inplace=False)
39:             )
39:           )
39:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
39:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
39:           (q_layernorm): IdentityOp()
39:           (k_layernorm): IdentityOp()
13:         )
13:         (pre_cross_attn_layernorm): IdentityOp()
13:         (cross_attention): IdentityOp()
13:         (cross_attn_bda): IdentityFuncOp()
13:         (pre_mlp_layernorm): IdentityOp()
13:         (mlp): TEFusedMLP(
13:           (0): RMSNorm()
13:           (1): Linear(
13:             (basic_ops): ModuleList(
13:               (0): BasicLinear()
13:             )
13:           )
13:           (2): SwiGLU()
13:           (3): Linear(
13:             (basic_ops): ModuleList(
13:               (0): BasicLinear()
13:             )
13:           )
13:         )
13:       )
13:     )
13:     (final_layernorm): RMSNorm()
13:   )
13:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
13: )
 5: GPTModel(
 5:   (embedding): LanguageModelEmbedding(
 5:     (word_embeddings): VocabParallelEmbedding()
 5:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 5:   )
 5:   (rotary_pos_emb): RotaryEmbedding()
 5:   (decoder): TransformerBlock(
 5:     (layers): ModuleList(
 5:       (0-31): 32 x TransformerLayer(
 5:         (input_layernorm): IdentityOp()
 5:         (self_attention): SelfAttention(
 5:           (core_attention): TEDotProductAttention(
 5:             (flash_attention): FlashAttention()
 5:             (fused_attention): FusedAttention()
 5:             (unfused_attention): UnfusedDotProductAttention(
 5:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 5:               (attention_dropout): Dropout(p=0.0, inplace=False)
 5:             )
 5:           )
 5:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 5:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 5:           (q_layernorm): IdentityOp()
 5:           (k_layernorm): IdentityOp()
55:         )
55:         (pre_cross_attn_layernorm): IdentityOp()
55:         (cross_attention): IdentityOp()
55:         (cross_attn_bda): IdentityFuncOp()
55:         (pre_mlp_layernorm): IdentityOp()
55:         (mlp): TEFusedMLP(
55:           (0): RMSNorm()
55:           (1): Linear(
55:             (basic_ops): ModuleList(
55:               (0): BasicLinear()
55:             )
55:           )
55:           (2): SwiGLU()
55:           (3): Linear(
55:             (basic_ops): ModuleList(
55:               (0): BasicLinear()
55:             )
55:           )
55:         )
55:       )
55:     )
55:     (final_layernorm): RMSNorm()
55:   )
55:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
55: )
23:         )
23:         (pre_cross_attn_layernorm): IdentityOp()
23:         (cross_attention): IdentityOp()
23:         (cross_attn_bda): IdentityFuncOp()
23:         (pre_mlp_layernorm): IdentityOp()
23:         (mlp): TEFusedMLP(
23:           (0): RMSNorm()
23:           (1): Linear(
23:             (basic_ops): ModuleList(
23:               (0): BasicLinear()
23:             )
23:           )
23:           (2): SwiGLU()
23:           (3): Linear(
23:             (basic_ops): ModuleList(
23:               (0): BasicLinear()
23:             )
23:           )
23:         )
23:       )
23:     )
23:     (final_layernorm): RMSNorm()
23:   )
23:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
23: )
45:         )
45:         (pre_cross_attn_layernorm): IdentityOp()
45:         (cross_attention): IdentityOp()
45:         (cross_attn_bda): IdentityFuncOp()
45:         (pre_mlp_layernorm): IdentityOp()
45:         (mlp): TEFusedMLP(
45:           (0): RMSNorm()
45:           (1): Linear(
45:             (basic_ops): ModuleList(
45:               (0): BasicLinear()
45:             )
45:           )
45:           (2): SwiGLU()
45:           (3): Linear(
45:             (basic_ops): ModuleList(
45:               (0): BasicLinear()
45:             )
45:           )
45:         )
45:       )
45:     )
45:     (final_layernorm): RMSNorm()
45:   )
45:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
45: )
39:         )
39:         (pre_cross_attn_layernorm): IdentityOp()
39:         (cross_attention): IdentityOp()
39:         (cross_attn_bda): IdentityFuncOp()
39:         (pre_mlp_layernorm): IdentityOp()
39:         (mlp): TEFusedMLP(
39:           (0): RMSNorm()
39:           (1): Linear(
39:             (basic_ops): ModuleList(
39:               (0): BasicLinear()
39:             )
39:           )
39:           (2): SwiGLU()
39:           (3): Linear(
39:             (basic_ops): ModuleList(
39:               (0): BasicLinear()
39:             )
39:           )
39:         )
39:       )
39:     )
39:     (final_layernorm): RMSNorm()
39:   )
39:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
39: )
11: )
 5:         )
 5:         (pre_cross_attn_layernorm): IdentityOp()
 5:         (cross_attention): IdentityOp()
 5:         (cross_attn_bda): IdentityFuncOp()
 5:         (pre_mlp_layernorm): IdentityOp()
 5:         (mlp): TEFusedMLP(
 5:           (0): RMSNorm()
 5:           (1): Linear(
 5:             (basic_ops): ModuleList(
 5:               (0): BasicLinear()
 5:             )
 5:           )
 5:           (2): SwiGLU()
 5:           (3): Linear(
 5:             (basic_ops): ModuleList(
 5:               (0): BasicLinear()
 5:             )
 5:           )
 5:         )
 5:       )
 5:     )
 5:     (final_layernorm): RMSNorm()
 5:   )
 5:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 5: )
21: GPTModel(
21:   (embedding): LanguageModelEmbedding(
21:     (word_embeddings): VocabParallelEmbedding()
21:     (embedding_dropout): Dropout(p=0.0, inplace=False)
21:   )
21:   (rotary_pos_emb): RotaryEmbedding()
21:   (decoder): TransformerBlock(
21:     (layers): ModuleList(
21:       (0-31): 32 x TransformerLayer(
21:         (input_layernorm): IdentityOp()
21:         (self_attention): SelfAttention(
21:           (core_attention): TEDotProductAttention(
21:             (flash_attention): FlashAttention()
21:             (fused_attention): FusedAttention()
21:             (unfused_attention): UnfusedDotProductAttention(
21:               (scale_mask_softmax): FusedScaleMaskSoftmax()
21:               (attention_dropout): Dropout(p=0.0, inplace=False)
21:             )
21:           )
21:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
21:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
21:           (q_layernorm): IdentityOp()
21:           (k_layernorm): IdentityOp()
46: GPTModel(
46:   (embedding): LanguageModelEmbedding(
46:     (word_embeddings): VocabParallelEmbedding()
46:     (embedding_dropout): Dropout(p=0.0, inplace=False)
46:   )
46:   (rotary_pos_emb): RotaryEmbedding()
46:   (decoder): TransformerBlock(
46:     (layers): ModuleList(
46:       (0-31): 32 x TransformerLayer(
46:         (input_layernorm): IdentityOp()
46:         (self_attention): SelfAttention(
46:           (core_attention): TEDotProductAttention(
46:             (flash_attention): FlashAttention()
46:             (fused_attention): FusedAttention()
46:             (unfused_attention): UnfusedDotProductAttention(
46:               (scale_mask_softmax): FusedScaleMaskSoftmax()
46:               (attention_dropout): Dropout(p=0.0, inplace=False)
46:             )
46:           )
46:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
46:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
46:           (q_layernorm): IdentityOp()
46:           (k_layernorm): IdentityOp()
35: GPTModel(
35:   (embedding): LanguageModelEmbedding(
35:     (word_embeddings): VocabParallelEmbedding()
35:     (embedding_dropout): Dropout(p=0.0, inplace=False)
35:   )
35:   (rotary_pos_emb): RotaryEmbedding()
35:   (decoder): TransformerBlock(
35:     (layers): ModuleList(
35:       (0-31): 32 x TransformerLayer(
35:         (input_layernorm): IdentityOp()
35:         (self_attention): SelfAttention(
35:           (core_attention): TEDotProductAttention(
35:             (flash_attention): FlashAttention()
35:             (fused_attention): FusedAttention()
35:             (unfused_attention): UnfusedDotProductAttention(
35:               (scale_mask_softmax): FusedScaleMaskSoftmax()
35:               (attention_dropout): Dropout(p=0.0, inplace=False)
35:             )
35:           )
35:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
35:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
35:           (q_layernorm): IdentityOp()
35:           (k_layernorm): IdentityOp()
14: GPTModel(
14:   (embedding): LanguageModelEmbedding(
14:     (word_embeddings): VocabParallelEmbedding()
14:     (embedding_dropout): Dropout(p=0.0, inplace=False)
14:   )
14:   (rotary_pos_emb): RotaryEmbedding()
14:   (decoder): TransformerBlock(
14:     (layers): ModuleList(
14:       (0-31): 32 x TransformerLayer(
14:         (input_layernorm): IdentityOp()
14:         (self_attention): SelfAttention(
14:           (core_attention): TEDotProductAttention(
14:             (flash_attention): FlashAttention()
14:             (fused_attention): FusedAttention()
14:             (unfused_attention): UnfusedDotProductAttention(
14:               (scale_mask_softmax): FusedScaleMaskSoftmax()
14:               (attention_dropout): Dropout(p=0.0, inplace=False)
14:             )
14:           )
14:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
14:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
14:           (q_layernorm): IdentityOp()
14:           (k_layernorm): IdentityOp()
 6: GPTModel(
 6:   (embedding): LanguageModelEmbedding(
 6:     (word_embeddings): VocabParallelEmbedding()
 6:     (embedding_dropout): Dropout(p=0.0, inplace=False)
 6:   )
 6:   (rotary_pos_emb): RotaryEmbedding()
 6:   (decoder): TransformerBlock(
 6:     (layers): ModuleList(
 6:       (0-31): 32 x TransformerLayer(
 6:         (input_layernorm): IdentityOp()
 6:         (self_attention): SelfAttention(
 6:           (core_attention): TEDotProductAttention(
 6:             (flash_attention): FlashAttention()
 6:             (fused_attention): FusedAttention()
 6:             (unfused_attention): UnfusedDotProductAttention(
 6:               (scale_mask_softmax): FusedScaleMaskSoftmax()
 6:               (attention_dropout): Dropout(p=0.0, inplace=False)
 6:             )
 6:           )
 6:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 6:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 6:           (q_layernorm): IdentityOp()
 6:           (k_layernorm): IdentityOp()
21:         )
21:         (pre_cross_attn_layernorm): IdentityOp()
21:         (cross_attention): IdentityOp()
21:         (cross_attn_bda): IdentityFuncOp()
21:         (pre_mlp_layernorm): IdentityOp()
21:         (mlp): TEFusedMLP(
21:           (0): RMSNorm()
21:           (1): Linear(
21:             (basic_ops): ModuleList(
21:               (0): BasicLinear()
21:             )
21:           )
21:           (2): SwiGLU()
21:           (3): Linear(
21:             (basic_ops): ModuleList(
21:               (0): BasicLinear()
21:             )
21:           )
21:         )
21:       )
21:     )
21:     (final_layernorm): RMSNorm()
21:   )
21:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
21: )
46:         )
46:         (pre_cross_attn_layernorm): IdentityOp()
46:         (cross_attention): IdentityOp()
46:         (cross_attn_bda): IdentityFuncOp()
46:         (pre_mlp_layernorm): IdentityOp()
46:         (mlp): TEFusedMLP(
46:           (0): RMSNorm()
46:           (1): Linear(
46:             (basic_ops): ModuleList(
46:               (0): BasicLinear()
46:             )
46:           )
46:           (2): SwiGLU()
46:           (3): Linear(
46:             (basic_ops): ModuleList(
46:               (0): BasicLinear()
46:             )
46:           )
46:         )
46:       )
46:     )
46:     (final_layernorm): RMSNorm()
46:   )
46:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
46: )
35:         )
35:         (pre_cross_attn_layernorm): IdentityOp()
35:         (cross_attention): IdentityOp()
35:         (cross_attn_bda): IdentityFuncOp()
35:         (pre_mlp_layernorm): IdentityOp()
35:         (mlp): TEFusedMLP(
35:           (0): RMSNorm()
35:           (1): Linear(
35:             (basic_ops): ModuleList(
35:               (0): BasicLinear()
35:             )
35:           )
35:           (2): SwiGLU()
35:           (3): Linear(
35:             (basic_ops): ModuleList(
35:               (0): BasicLinear()
35:             )
35:           )
35:         )
35:       )
35:     )
35:     (final_layernorm): RMSNorm()
35:   )
35:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
35: )
14:         )
14:         (pre_cross_attn_layernorm): IdentityOp()
14:         (cross_attention): IdentityOp()
14:         (cross_attn_bda): IdentityFuncOp()
14:         (pre_mlp_layernorm): IdentityOp()
14:         (mlp): TEFusedMLP(
14:           (0): RMSNorm()
14:           (1): Linear(
14:             (basic_ops): ModuleList(
14:               (0): BasicLinear()
14:             )
14:           )
14:           (2): SwiGLU()
14:           (3): Linear(
14:             (basic_ops): ModuleList(
14:               (0): BasicLinear()
14:             )
14:           )
14:         )
14:       )
14:     )
14:     (final_layernorm): RMSNorm()
14:   )
14:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
14: )
 6:         )
 6:         (pre_cross_attn_layernorm): IdentityOp()
 6:         (cross_attention): IdentityOp()
 6:         (cross_attn_bda): IdentityFuncOp()
 6:         (pre_mlp_layernorm): IdentityOp()
 6:         (mlp): TEFusedMLP(
 6:           (0): RMSNorm()
 6:           (1): Linear(
 6:             (basic_ops): ModuleList(
 6:               (0): BasicLinear()
 6:             )
 6:           )
 6:           (2): SwiGLU()
 6:           (3): Linear(
 6:             (basic_ops): ModuleList(
 6:               (0): BasicLinear()
 6:             )
 6:           )
 6:         )
 6:       )
 6:     )
 6:     (final_layernorm): RMSNorm()
 6:   )
 6:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 6: )
22: GPTModel(
22:   (embedding): LanguageModelEmbedding(
22:     (word_embeddings): VocabParallelEmbedding()
22:     (embedding_dropout): Dropout(p=0.0, inplace=False)
22:   )
22:   (rotary_pos_emb): RotaryEmbedding()
22:   (decoder): TransformerBlock(
22:     (layers): ModuleList(
22:       (0-31): 32 x TransformerLayer(
22:         (input_layernorm): IdentityOp()
22:         (self_attention): SelfAttention(
22:           (core_attention): TEDotProductAttention(
22:             (flash_attention): FlashAttention()
22:             (fused_attention): FusedAttention()
22:             (unfused_attention): UnfusedDotProductAttention(
22:               (scale_mask_softmax): FusedScaleMaskSoftmax()
22:               (attention_dropout): Dropout(p=0.0, inplace=False)
22:             )
22:           )
22:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
22:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
22:           (q_layernorm): IdentityOp()
22:           (k_layernorm): IdentityOp()
47: GPTModel(
47:   (embedding): LanguageModelEmbedding(
47:     (word_embeddings): VocabParallelEmbedding()
47:     (embedding_dropout): Dropout(p=0.0, inplace=False)
47:   )
47:   (rotary_pos_emb): RotaryEmbedding()
47:   (decoder): TransformerBlock(
47:     (layers): ModuleList(
47:       (0-31): 32 x TransformerLayer(
47:         (input_layernorm): IdentityOp()
47:         (self_attention): SelfAttention(
47:           (core_attention): TEDotProductAttention(
47:             (flash_attention): FlashAttention()
47:             (fused_attention): FusedAttention()
47:             (unfused_attention): UnfusedDotProductAttention(
47:               (scale_mask_softmax): FusedScaleMaskSoftmax()
47:               (attention_dropout): Dropout(p=0.0, inplace=False)
47:             )
47:           )
47:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
47:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
47:           (q_layernorm): IdentityOp()
47:           (k_layernorm): IdentityOp()
37: GPTModel(
37:   (embedding): LanguageModelEmbedding(
37:     (word_embeddings): VocabParallelEmbedding()
37:     (embedding_dropout): Dropout(p=0.0, inplace=False)
37:   )
37:   (rotary_pos_emb): RotaryEmbedding()
37:   (decoder): TransformerBlock(
37:     (layers): ModuleList(
37:       (0-31): 32 x TransformerLayer(
37:         (input_layernorm): IdentityOp()
37:         (self_attention): SelfAttention(
37:           (core_attention): TEDotProductAttention(
37:             (flash_attention): FlashAttention()
37:             (fused_attention): FusedAttention()
37:             (unfused_attention): UnfusedDotProductAttention(
37:               (scale_mask_softmax): FusedScaleMaskSoftmax()
37:               (attention_dropout): Dropout(p=0.0, inplace=False)
37:             )
37:           )
37:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
37:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
37:           (q_layernorm): IdentityOp()
37:           (k_layernorm): IdentityOp()
15: GPTModel(
15:   (embedding): LanguageModelEmbedding(
15:     (word_embeddings): VocabParallelEmbedding()
15:     (embedding_dropout): Dropout(p=0.0, inplace=False)
15:   )
15:   (rotary_pos_emb): RotaryEmbedding()
15:   (decoder): TransformerBlock(
15:     (layers): ModuleList(
15:       (0-31): 32 x TransformerLayer(
15:         (input_layernorm): IdentityOp()
15:         (self_attention): SelfAttention(
15:           (core_attention): TEDotProductAttention(
15:             (flash_attention): FlashAttention()
15:             (fused_attention): FusedAttention()
15:             (unfused_attention): UnfusedDotProductAttention(
15:               (scale_mask_softmax): FusedScaleMaskSoftmax()
15:               (attention_dropout): Dropout(p=0.0, inplace=False)
15:             )
15:           )
15:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
15:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
15:           (q_layernorm): IdentityOp()
15:           (k_layernorm): IdentityOp()
22:         )
22:         (pre_cross_attn_layernorm): IdentityOp()
22:         (cross_attention): IdentityOp()
22:         (cross_attn_bda): IdentityFuncOp()
22:         (pre_mlp_layernorm): IdentityOp()
22:         (mlp): TEFusedMLP(
22:           (0): RMSNorm()
22:           (1): Linear(
22:             (basic_ops): ModuleList(
22:               (0): BasicLinear()
22:             )
22:           )
22:           (2): SwiGLU()
22:           (3): Linear(
22:             (basic_ops): ModuleList(
22:               (0): BasicLinear()
22:             )
22:           )
22:         )
22:       )
22:     )
22:     (final_layernorm): RMSNorm()
22:   )
22:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
22: )
47:         )
47:         (pre_cross_attn_layernorm): IdentityOp()
47:         (cross_attention): IdentityOp()
47:         (cross_attn_bda): IdentityFuncOp()
47:         (pre_mlp_layernorm): IdentityOp()
47:         (mlp): TEFusedMLP(
47:           (0): RMSNorm()
47:           (1): Linear(
47:             (basic_ops): ModuleList(
47:               (0): BasicLinear()
47:             )
47:           )
47:           (2): SwiGLU()
47:           (3): Linear(
47:             (basic_ops): ModuleList(
47:               (0): BasicLinear()
47:             )
47:           )
47:         )
47:       )
47:     )
47:     (final_layernorm): RMSNorm()
47:   )
47:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
47: )
37:         )
37:         (pre_cross_attn_layernorm): IdentityOp()
37:         (cross_attention): IdentityOp()
37:         (cross_attn_bda): IdentityFuncOp()
37:         (pre_mlp_layernorm): IdentityOp()
37:         (mlp): TEFusedMLP(
37:           (0): RMSNorm()
37:           (1): Linear(
37:             (basic_ops): ModuleList(
37:               (0): BasicLinear()
37:             )
37:           )
37:           (2): SwiGLU()
37:           (3): Linear(
37:             (basic_ops): ModuleList(
37:               (0): BasicLinear()
37:             )
37:           )
37:         )
37:       )
37:     )
37:     (final_layernorm): RMSNorm()
37:   )
37:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
37: )
15:         )
15:         (pre_cross_attn_layernorm): IdentityOp()
15:         (cross_attention): IdentityOp()
15:         (cross_attn_bda): IdentityFuncOp()
15:         (pre_mlp_layernorm): IdentityOp()
15:         (mlp): TEFusedMLP(
15:           (0): RMSNorm()
15:           (1): Linear(
15:             (basic_ops): ModuleList(
15:               (0): BasicLinear()
15:             )
15:           )
15:           (2): SwiGLU()
15:           (3): Linear(
15:             (basic_ops): ModuleList(
15:               (0): BasicLinear()
15:             )
15:           )
15:         )
15:       )
15:     )
15:     (final_layernorm): RMSNorm()
15:   )
15:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
38: GPTModel(
38:   (embedding): LanguageModelEmbedding(
38:     (word_embeddings): VocabParallelEmbedding()
38:     (embedding_dropout): Dropout(p=0.0, inplace=False)
38:   )
38:   (rotary_pos_emb): RotaryEmbedding()
38:   (decoder): TransformerBlock(
38:     (layers): ModuleList(
38:       (0-31): 32 x TransformerLayer(
38:         (input_layernorm): IdentityOp()
38:         (self_attention): SelfAttention(
38:           (core_attention): TEDotProductAttention(
38:             (flash_attention): FlashAttention()
38:             (fused_attention): FusedAttention()
38:             (unfused_attention): UnfusedDotProductAttention(
38:               (scale_mask_softmax): FusedScaleMaskSoftmax()
38:               (attention_dropout): Dropout(p=0.0, inplace=False)
38:             )
38:           )
38:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
38:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
38:           (q_layernorm): IdentityOp()
38:           (k_layernorm): IdentityOp()
15: )
38:         )
38:         (pre_cross_attn_layernorm): IdentityOp()
38:         (cross_attention): IdentityOp()
38:         (cross_attn_bda): IdentityFuncOp()
38:         (pre_mlp_layernorm): IdentityOp()
38:         (mlp): TEFusedMLP(
38:           (0): RMSNorm()
38:           (1): Linear(
38:             (basic_ops): ModuleList(
38:               (0): BasicLinear()
38:             )
38:           )
38:           (2): SwiGLU()
38:           (3): Linear(
38:             (basic_ops): ModuleList(
38:               (0): BasicLinear()
38:             )
38:           )
38:         )
38:       )
38:     )
38:     (final_layernorm): RMSNorm()
38:   )
38:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
38: )
32: GPTModel(
32:   (embedding): LanguageModelEmbedding(
32:     (word_embeddings): VocabParallelEmbedding()
32:     (embedding_dropout): Dropout(p=0.0, inplace=False)
32:   )
32:   (rotary_pos_emb): RotaryEmbedding()
32:   (decoder): TransformerBlock(
32:     (layers): ModuleList(
32:       (0-31): 32 x TransformerLayer(
32:         (input_layernorm): IdentityOp()
32:         (self_attention): SelfAttention(
32:           (core_attention): TEDotProductAttention(
32:             (flash_attention): FlashAttention()
32:             (fused_attention): FusedAttention()
32:             (unfused_attention): UnfusedDotProductAttention(
32:               (scale_mask_softmax): FusedScaleMaskSoftmax()
32:               (attention_dropout): Dropout(p=0.0, inplace=False)
32:             )
32:           )
32:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
32:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
32:           (q_layernorm): IdentityOp()
32:           (k_layernorm): IdentityOp()
32:         )
32:         (pre_cross_attn_layernorm): IdentityOp()
32:         (cross_attention): IdentityOp()
32:         (cross_attn_bda): IdentityFuncOp()
32:         (pre_mlp_layernorm): IdentityOp()
32:         (mlp): TEFusedMLP(
32:           (0): RMSNorm()
32:           (1): Linear(
32:             (basic_ops): ModuleList(
32:               (0): BasicLinear()
32:             )
32:           )
32:           (2): SwiGLU()
32:           (3): Linear(
32:             (basic_ops): ModuleList(
32:               (0): BasicLinear()
32:             )
32:           )
32:         )
32:       )
32:     )
32:     (final_layernorm): RMSNorm()
32:   )
32:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
32: )
34: GPTModel(
34:   (embedding): LanguageModelEmbedding(
34:     (word_embeddings): VocabParallelEmbedding()
34:     (embedding_dropout): Dropout(p=0.0, inplace=False)
34:   )
34:   (rotary_pos_emb): RotaryEmbedding()
34:   (decoder): TransformerBlock(
34:     (layers): ModuleList(
34:       (0-31): 32 x TransformerLayer(
34:         (input_layernorm): IdentityOp()
34:         (self_attention): SelfAttention(
34:           (core_attention): TEDotProductAttention(
34:             (flash_attention): FlashAttention()
34:             (fused_attention): FusedAttention()
34:             (unfused_attention): UnfusedDotProductAttention(
34:               (scale_mask_softmax): FusedScaleMaskSoftmax()
34:               (attention_dropout): Dropout(p=0.0, inplace=False)
34:             )
34:           )
34:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
34:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
34:           (q_layernorm): IdentityOp()
34:           (k_layernorm): IdentityOp()
34:         )
34:         (pre_cross_attn_layernorm): IdentityOp()
34:         (cross_attention): IdentityOp()
34:         (cross_attn_bda): IdentityFuncOp()
34:         (pre_mlp_layernorm): IdentityOp()
34:         (mlp): TEFusedMLP(
34:           (0): RMSNorm()
34:           (1): Linear(
34:             (basic_ops): ModuleList(
34:               (0): BasicLinear()
34:             )
34:           )
34:           (2): SwiGLU()
34:           (3): Linear(
34:             (basic_ops): ModuleList(
34:               (0): BasicLinear()
34:             )
34:           )
34:         )
34:       )
34:     )
34:     (final_layernorm): RMSNorm()
34:   )
34:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
34: )
63: GPTModel(
63:   (embedding): LanguageModelEmbedding(
63:     (word_embeddings): VocabParallelEmbedding()
63:     (embedding_dropout): Dropout(p=0.0, inplace=False)
63:   )
63:   (rotary_pos_emb): RotaryEmbedding()
63:   (decoder): TransformerBlock(
63:     (layers): ModuleList(
63:       (0-31): 32 x TransformerLayer(
63:         (input_layernorm): IdentityOp()
63:         (self_attention): SelfAttention(
63:           (core_attention): TEDotProductAttention(
63:             (flash_attention): FlashAttention()
63:             (fused_attention): FusedAttention()
63:             (unfused_attention): UnfusedDotProductAttention(
63:               (scale_mask_softmax): FusedScaleMaskSoftmax()
63:               (attention_dropout): Dropout(p=0.0, inplace=False)
63:             )
63:           )
63:           (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
63:           (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
63:           (q_layernorm): IdentityOp()
63:           (k_layernorm): IdentityOp()
 0: Llama31Config8B(tensor_model_parallel_size=1,
 0:                 pipeline_model_parallel_comm_backend=None,
63:         )
63:         (pre_cross_attn_layernorm): IdentityOp()
63:         (cross_attention): IdentityOp()
63:         (cross_attn_bda): IdentityFuncOp()
63:         (pre_mlp_layernorm): IdentityOp()
63:         (mlp): TEFusedMLP(
63:           (0): RMSNorm()
63:           (1): Linear(
63:             (basic_ops): ModuleList(
63:               (0): BasicLinear()
63:             )
63:           )
63:           (2): SwiGLU()
63:           (3): Linear(
63:             (basic_ops): ModuleList(
63:               (0): BasicLinear()
63:             )
63:           )
63:         )
63:       )
63:     )
63:     (final_layernorm): RMSNorm()
63:   )
63:   (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
63: )
 0:                 pipeline_model_parallel_size=1,
 0:                 virtual_pipeline_model_parallel_size=None,
 0:                 sequence_parallel=False,
 0:                 context_parallel_size=2,
 0:                 hierarchical_context_parallel_sizes=None,
 0:                 expert_model_parallel_size=1,
 0:                 expert_tensor_parallel_size=2,
 0:                 moe_extended_tp=False,
 0:                 perform_initialization=True,
 0:                 use_cpu_initialization=False,
 0:                 fp16=False,
 0:                 bf16=True,
 0:                 params_dtype=torch.bfloat16,
 0:                 timers=<megatron.core.timers.Timers object at 0x7ef975fd8a40>,
 0:                 finalize_model_grads_func=<function MegatronOptimizerModule.on_fit_start.<locals>.finalize_model_grads_func at 0x7ef9489fd440>,
 0:                 grad_scale_func=None,
 0:                 no_sync_func=<bound method DistributedDataParallel.no_sync of DDP(
 0:   (module): Float16Module(
 0:     (module): GPTModel(
 0:       (embedding): LanguageModelEmbedding(
 0:         (word_embeddings): VocabParallelEmbedding()
 0:         (embedding_dropout): Dropout(p=0.0, inplace=False)
 0:       )
 0:       (rotary_pos_emb): RotaryEmbedding()
 0:       (decoder): TransformerBlock(
 0:         (layers): ModuleList(
 0:           (0-31): 32 x TransformerLayer(
 0:             (input_layernorm): IdentityOp()
 0:             (self_attention): SelfAttention(
 0:               (core_attention): TEDotProductAttention(
 0:                 (flash_attention): FlashAttention()
 0:                 (fused_attention): FusedAttention()
 0:                 (unfused_attention): UnfusedDotProductAttention(
 0:                   (scale_mask_softmax): FusedScaleMaskSoftmax()
 0:                   (attention_dropout): Dropout(p=0.0, inplace=False)
 0:                 )
 0:               )
 0:               (linear_proj): TERowParallelLinear(in_features=4096, out_features=4096, bias=False, TP=1)
 0:               (linear_qkv): TELayerNormColumnParallelLinear(in_features=4096, out_features=6144, bias=False, TP=1)
 0:               (q_layernorm): IdentityOp()
 0:               (k_layernorm): IdentityOp()
 0:             )
 0:             (pre_cross_attn_layernorm): IdentityOp()
 0:             (cross_attention): IdentityOp()
 0:             (cross_attn_bda): IdentityFuncOp()
 0:             (pre_mlp_layernorm): IdentityOp()
 0:             (mlp): TEFusedMLP(
 0:               (0): RMSNorm()
 0:               (1): Linear(
 0:                 (basic_ops): ModuleList(
 0:                   (0): BasicLinear()
 0:                 )
 0:               )
 0:               (2): SwiGLU()
 0:               (3): Linear(
 0:                 (basic_ops): ModuleList(
 0:                   (0): BasicLinear()
 0:                 )
 0:               )
 0:             )
 0:           )
 0:         )
 0:         (final_layernorm): RMSNorm()
 0:       )
 0:       (output_layer): ColumnParallelLinear(in_features=4096, out_features=128256, bias=False, TP=1)
 0:     )
 0:   )
 0: )>,
 0:                 grad_sync_func=None,
 0:                 param_sync_func=None,
 0:                 deterministic_mode=False,
 0:                 enable_autocast=False,
 0:                 autocast_dtype=torch.bfloat16,
 0:                 num_microbatches_with_partial_activation_checkpoints=None,
 0:                 gradient_accumulation_fusion=True,
 0:                 async_tensor_model_parallel_allreduce=False,
 0:                 use_te_rng_tracker=(True,),
 0:                 tp_comm_overlap=False,
 0:                 tp_comm_bulk_wgrad=True,
 0:                 tp_comm_bulk_dgrad=True,
 0:                 tp_comm_overlap_ag=True,
 0:                 tp_comm_overlap_rs=True,
 0:                 tp_comm_overlap_rs_dgrad=False,
 0:                 tp_comm_split_ag=True,
 0:                 tp_comm_atomic_ag=False,
 0:                 tp_comm_split_rs=True,
 0:                 tp_comm_atomic_rs=False,
 0:                 cross_entropy_loss_fusion=True,
 0:                 cross_entropy_fusion_impl='te',
 0:                 tp_comm_overlap_disable_qkv=False,
 0:                 tp_comm_overlap_disable_fc1=False,
 0:                 tp_comm_bootstrap_backend=None,
 0:                 overlap_moe_expert_parallel_comm=False,
 0:                 delay_wgrad_compute=False,
 0:                 pipeline_dtype=torch.bfloat16,
 0:                 variable_seq_lengths=False,
 0:                 overlap_p2p_comm=True,
 0:                 batch_p2p_comm=False,
 0:                 batch_p2p_sync=True,
 0:                 use_ring_exchange_p2p=False,
 0:                 deallocate_pipeline_outputs=True,
 0:                 defer_embedding_wgrad_compute=False,
 0:                 wgrad_deferral_limit=50,
 0:                 overlap_p2p_comm_warmup_flush=False,
 0:                 microbatch_group_size_per_vp_stage=1,
 0:                 cpu_offloading=False,
 0:                 cpu_offloading_num_layers=0,
 0:                 _cpu_offloading_context=None,
 0:                 cpu_offloading_activations=True,
 0:                 cpu_offloading_weights=True,
 0:                 barrier_with_L1_time=True,
 0:                 num_layers=32,
 0:                 mtp_num_layers=None,
 0:                 mtp_loss_scaling_factor=None,
 0:                 num_layers_in_first_pipeline_stage=None,
 0:                 num_layers_in_last_pipeline_stage=None,
 0:                 pipeline_model_parallel_layout=None,
 0:                 account_for_embedding_in_pipeline_split=False,
 0:                 account_for_loss_in_pipeline_split=False,
 0:                 hidden_size=4096,
 0:                 num_attention_heads=32,
 0:                 attention_backend=<AttnBackend.auto: 5>,
 0:                 softmax_scale=None,
 0:                 num_query_groups=8,
 0:                 ffn_hidden_size=14336,
 0:                 kv_channels=128,
 0:                 hidden_dropout=0.0,
 0:                 attention_dropout=0.0,
 0:                 fp32_residual_connection=False,
 0:                 apply_residual_connection_post_layernorm=False,
 0:                 layernorm_epsilon=1e-05,
 0:                 layernorm_zero_centered_gamma=False,
 0:                 add_bias_linear=False,
 0:                 add_qkv_bias=False,
 0:                 gated_linear_unit=True,
 0:                 activation_func=<function silu at 0x7efc7aa9c540>,
 0:                 activation_func_fp8_input_store=False,
 0:                 num_moe_experts=None,
 0:                 rotary_interleaved=False,
 0:                 window_size=None,
 0:                 normalization='RMSNorm',
 0:                 qk_layernorm=False,
 0:                 test_mode=False,
 0:                 calculate_per_token_loss=False,
 0:                 multi_latent_attention=False,
 0:                 no_rope_freq=None,
 0:                 moe_deepep_num_sms=20,
 0:                 init_method=functools.partial(<function normal_ at 0x7efc7a928fe0>, mean=0.0, std=0.02),
 0:                 output_layer_init_method=functools.partial(<function normal_ at 0x7efc7a928fe0>, mean=0.0, std=0.0025),
 0:                 init_method_std=0.02,
 0:                 embedding_init_method=functools.partial(<function normal_ at 0x7efc7a928fe0>, mean=0.0, std=0.02),
 0:                 embedding_init_method_std=0.02,
 0:                 init_model_with_meta_device=False,
 0:                 apply_query_key_layer_scaling=False,
 0:                 attention_softmax_in_fp32=False,
 0:                 disable_bf16_reduced_precision_matmul=False,
 0:                 bias_activation_fusion=True,
 0:                 masked_softmax_fusion=True,
 0:                 persist_layer_norm=True,
 0:                 memory_efficient_layer_norm=False,
 0:                 bias_dropout_fusion=True,
 0:                 apply_rope_fusion=True,
 0:                 use_fused_weighted_squared_relu=False,
 0:                 recompute_granularity=None,
 0:                 recompute_method=None,
 0:                 recompute_num_layers=None,
 0:                 distribute_saved_activations=None,
 0:                 recompute_modules=['core_attn'],
 0:                 fp8='hybrid',
 0:                 fp8_recipe='tensorwise',
 0:                 fp8_param=True,
 0:                 fp8_margin=0,
 0:                 fp8_interval=1,
 0:                 fp8_amax_history_len=1,
 0:                 fp8_amax_compute_algo='most_recent',
 0:                 fp8_wgrad=True,
 0:                 fp8_dot_product_attention=False,
 0:                 fp8_multi_head_attention=False,
 0:                 tp_only_amax_red=True,
 0:                 first_last_layers_bf16=False,
 0:                 num_layers_at_start_in_bf16=0,
 0:                 num_layers_at_end_in_bf16=0,
 0:                 use_kitchen=False,
 0:                 moe_shared_expert_intermediate_size=None,
 0:                 moe_shared_expert_overlap=False,
 0:                 moe_layer_freq=1,
 0:                 moe_ffn_hidden_size=None,
 0:                 moe_router_load_balancing_type='aux_loss',
 0:                 moe_router_topk=2,
 0:                 moe_router_topk_limited_devices=None,
 0:                 moe_router_padding_for_fp8=False,
 0:                 moe_router_num_groups=None,
 0:                 moe_router_group_topk=None,
 0:                 moe_router_pre_softmax=False,
 0:                 moe_router_topk_scaling_factor=None,
 0:                 moe_router_score_function='softmax',
 0:                 moe_router_dtype=None,
 0:                 moe_router_enable_expert_bias=False,
 0:                 moe_router_bias_update_rate=0.001,
 0:                 moe_router_force_load_balancing=False,
 0:                 moe_grouped_gemm=False,
 0:                 moe_use_legacy_grouped_gemm=False,
 0:                 moe_aux_loss_coeff=0.0,
 0:                 moe_z_loss_coeff=None,
 0:                 moe_input_jitter_eps=None,
 0:                 moe_token_dropping=False,
 0:                 moe_token_dispatcher_type='allgather',
 0:                 moe_enable_deepep=False,
 0:                 moe_per_layer_logging=False,
 0:                 moe_expert_capacity_factor=None,
 0:                 moe_pad_expert_input_to_capacity=False,
 0:                 moe_token_drop_policy='probs',
 0:                 moe_layer_recompute=False,
 0:                 moe_permute_fusion=False,
 0:                 moe_router_fusion=False,
 0:                 moe_apply_probs_on_input=False,
 0:                 cp_comm_type=None,
 0:                 enable_cuda_graph=1,
 0:                 cuda_graph_use_single_mempool=False,
 0:                 cuda_graph_retain_backward_graph=False,
 0:                 cuda_graph_warmup_steps=3,
 0:                 external_cuda_graph=False,
 0:                 cuda_graph_scope='full_iteration',
 0:                 clone_scatter_output_in_embedding=True,
 0:                 disable_parameter_transpose_cache=False,
 0:                 config_logger_dir='',
 0:                 flash_decode=False,
 0:                 inference_rng_tracker=False,
 0:                 symmetric_ar_type=None,
 0:                 mrope_section=None,
 0:                 is_hybrid_model=False,
 0:                 mamba_state_dim=128,
 0:                 mamba_head_dim=64,
 0:                 mamba_num_groups=8,
 0:                 mamba_num_heads=None,
 0:                 use_mamba_mem_eff_path=True,
 0:                 mlp_chunks_for_prefill=1,
 0:                 heterogeneous_block_specs=False,
 0:                 hetereogenous_dist_checkpoint=False,
 0:                 quant_recipe=None,
 0:                 fp16_lm_cross_entropy=False,
 0:                 parallel_output=True,
 0:                 share_embeddings_and_output_weights=False,
 0:                 make_vocab_size_divisible_by=128,
 0:                 position_embedding_type='rope',
 0:                 rotary_base=500000,
 0:                 rotary_percent=1.0,
 0:                 seq_len_interpolation_factor=None,
 0:                 seq_length=8192,
 0:                 scatter_embedding_sequence_parallel=True,
 0:                 use_transformer_engine_full_layer_spec=False,
 0:                 transformer_layer_spec=<function default_layer_spec at 0x7ef9769b8ea0>,
 0:                 forward_step_fn=<function gpt_forward_step at 0x7ef976b336a0>,
 0:                 data_step_fn=<function gpt_data_step at 0x7ef976b33420>,
 0:                 generation_config=None,
 0:                 vocab_size=None,
 0:                 tp_comm_overlap_cfg=None,
 0:                 use_transformer_engine_op_fuser=True,
 0:                 scale_factor=8.0,
 0:                 low_freq_factor=1.0,
 0:                 high_freq_factor=4.0,
 0:                 old_context_len=8192)
 0: [AUX I 2025-10-10 09:07:06 data:291] Instantiating MegatronPretrainingSampler with total_samples: 10000000 and consumed_samples: 0
27: [rank27]:[W1010 09:07:06.241075031 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 248 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
30: [rank30]:[W1010 09:07:06.241432558 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 257 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
28: [rank28]:[W1010 09:07:06.241735339 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 251 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
29: [rank29]:[W1010 09:07:06.241760152 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 254 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
24: [rank24]:[W1010 09:07:06.242151615 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 239 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
31: [rank31]:[W1010 09:07:06.242174082 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 260 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 7: [rank7]:[W1010 09:07:06.291832987 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 188 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
25: [rank25]:[W1010 09:07:06.242962511 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 242 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
26: [rank26]:[W1010 09:07:06.243003684 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 245 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 6: [rank6]:[W1010 09:07:06.292648843 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 185 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 5: [rank5]:[W1010 09:07:06.293279142 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 182 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 4: [rank4]:[W1010 09:07:06.293400959 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 179 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 3: [rank3]:[W1010 09:07:06.300058660 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 176 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 2: [rank2]:[W1010 09:07:06.300164564 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 173 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 1: [rank1]:[W1010 09:07:06.302956254 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 170 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
46: [rank46]:[W1010 09:07:06.386137152 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 305 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
45: [rank45]:[W1010 09:07:06.386525601 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 302 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
44: [rank44]:[W1010 09:07:06.388175340 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 299 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
57: [rank57]:[W1010 09:07:06.267103111 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 338 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
54: [rank54]:[W1010 09:07:06.251467475 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 329 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
63: [rank63]:[W1010 09:07:06.267800144 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 356 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
55: [rank55]:[W1010 09:07:06.252156892 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 332 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
56: [rank56]:[W1010 09:07:06.268446820 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 335 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
52: [rank52]:[W1010 09:07:06.252877623 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 323 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
38: [rank38]:[W1010 09:07:06.168692003 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 281 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
39: [rank39]:[W1010 09:07:06.169031745 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 284 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
10: [rank10]:[W1010 09:07:06.386610235 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 197 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
14: [rank14]:[W1010 09:07:06.386616994 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 209 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
47: [rank47]:[W1010 09:07:06.390839756 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 308 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
51: [rank51]:[W1010 09:07:06.253610485 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 320 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
62: [rank62]:[W1010 09:07:06.269537287 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 353 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
49: [rank49]:[W1010 09:07:06.253683492 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 314 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
12: [rank12]:[W1010 09:07:06.386796869 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 203 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
48: [rank48]:[W1010 09:07:06.254251925 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 311 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
59: [rank59]:[W1010 09:07:06.270152356 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 344 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
60: [rank60]:[W1010 09:07:06.270233995 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 347 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
36: [rank36]:[W1010 09:07:06.170338338 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 275 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 8: [rank8]:[W1010 09:07:06.387712810 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 191 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
13: [rank13]:[W1010 09:07:06.387921391 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 206 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
58: [rank58]:[W1010 09:07:06.270733543 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 341 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
37: [rank37]:[W1010 09:07:06.170675382 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 278 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
15: [rank15]:[W1010 09:07:06.388373731 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 212 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
50: [rank50]:[W1010 09:07:06.255408528 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 317 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
22: [rank22]:[W1010 09:07:06.272921592 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 233 Rank 0]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
40: [rank40]:[W1010 09:07:06.393303877 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 287 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
53: [rank53]:[W1010 09:07:06.256345420 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 326 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
43: [rank43]:[W1010 09:07:06.394105050 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 296 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
41: [rank41]:[W1010 09:07:06.394419180 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 290 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
21: [rank21]:[W1010 09:07:06.274287485 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 230 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
23: [rank23]:[W1010 09:07:06.274438289 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 236 Rank 0]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
20: [rank20]:[W1010 09:07:06.274461652 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 227 Rank 0]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
33: [rank33]:[W1010 09:07:06.173892944 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 266 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
42: [rank42]:[W1010 09:07:06.395547925 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 293 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
11: [rank11]:[W1010 09:07:06.393100186 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 200 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 0: [rank0]:[W1010 09:07:06.314596200 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 167 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
19: [rank19]:[W1010 09:07:06.277532060 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 224 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
61: [rank61]:[W1010 09:07:06.277001891 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 350 Rank 0]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
17: [rank17]:[W1010 09:07:06.278333795 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 218 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
35: [rank35]:[W1010 09:07:06.177094880 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 272 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
18: [rank18]:[W1010 09:07:06.278616103 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 221 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 9: [rank9]:[W1010 09:07:06.395836950 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 194 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
16: [rank16]:[W1010 09:07:06.285820513 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 215 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
34: [rank34]:[W1010 09:07:06.225449583 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 269 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
32: [rank32]:[W1010 09:07:06.228764625 ProcessGroupNCCL.cpp:4952] [PG ID 6 PG GUID 263 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
 0: [AUX I 2025-10-10 09:07:07 custom_callbacks:129] Starting training warmup
 0: [AUX I 2025-10-10 09:07:07 custom_callbacks:133]     Starting warmup step 0
 0: [AUX I 2025-10-10 09:07:12 custom_callbacks:150]     Finished warmup step 0, takes 5.660604000091553 s
 0: [AUX I 2025-10-10 09:07:12 custom_callbacks:133]     Starting warmup step 1
 0: [NeMo I 2025-10-10 09:07:12 full_cuda_graph:161] Capture CUDA graph for training!!!
 0: [NeMo I 2025-10-10 09:07:13 full_cuda_graph:179] CUDA graph capture done!!!
 0: [AUX I 2025-10-10 09:07:13 custom_callbacks:150]     Finished warmup step 1, takes 1.16432785987854 s
 0: [AUX I 2025-10-10 09:07:13 custom_callbacks:157] Finished training warmup: 6.829141855239868 s. 
 0: [AUX I 2025-10-10 09:07:13 custom_callbacks:176] Starting validation warmups
 0: [NeMo I 2025-10-10 09:07:13 full_cuda_graph:161] Capture CUDA graph for validation!!!
 0: [NeMo I 2025-10-10 09:07:14 full_cuda_graph:179] CUDA graph capture done!!!
 0: [AUX I 2025-10-10 09:07:14 custom_callbacks:195] Finished validation warmup: 0.9527969360351562 s. 
 0: [AUX I 2025-10-10 09:07:14 custom_callbacks:202] Finished training warmup: 0.9540982246398926 s. 
 0: [AUX I 2025-10-10 09:07:14 custom_callbacks:212] Time spent in run_training_warmup: 0.9583017826080322s
 0: :::MLLOG {"namespace": "", "time_ms": 1760105234797, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"warmup_time": 63.97669270215556}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105234836, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"init_finished": 0.039219729136675596}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105234836, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105234837, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105234837, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105245740, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.33825206756591797, "reduced_train_loss": 8.117958068847656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 31.0, "samples_count": 1024.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105256653, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3448195457458496, "reduced_train_loss": 7.734314441680908}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 63.0, "samples_count": 2048.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105267784, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.34981346130371094, "reduced_train_loss": 7.58493185043335}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 95.0, "samples_count": 3072.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105278946, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.34760594367980957, "reduced_train_loss": 7.26324987411499}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 127.0, "samples_count": 4096.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105290160, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3476855754852295, "reduced_train_loss": 6.809709548950195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 159.0, "samples_count": 5120.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105301391, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35166311264038086, "reduced_train_loss": 6.701955795288086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 191.0, "samples_count": 6144.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105312648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35362863540649414, "reduced_train_loss": 6.561970233917236}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 223.0, "samples_count": 7168.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105323930, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3509485721588135, "reduced_train_loss": 6.390021800994873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 255.0, "samples_count": 8192.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324147, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3488691617221775}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324147, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324147, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 8192, "step": 256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324230, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3057868480682373}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 0, "samples_count": 32}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324331, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10142374038696289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1, "samples_count": 64}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324418, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08652424812316895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2, "samples_count": 96}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324503, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08552074432373047}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3, "samples_count": 128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324588, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08448433876037598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4, "samples_count": 160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08465909957885742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5, "samples_count": 192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324758, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08588457107543945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6, "samples_count": 224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324843, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08466815948486328}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 7, "samples_count": 256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105324927, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08432340621948242}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 8, "samples_count": 288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325013, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08599591255187988}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 9, "samples_count": 320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325112, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09830713272094727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 10, "samples_count": 352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325213, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10075807571411133}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 11, "samples_count": 384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325306, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09349465370178223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 12, "samples_count": 416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325391, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08546209335327148}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 13, "samples_count": 448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08825469017028809}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 14, "samples_count": 480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325567, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08761048316955566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 15, "samples_count": 512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325653, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.085205078125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 16, "samples_count": 544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08620023727416992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 17, "samples_count": 576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325825, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08605265617370605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 18, "samples_count": 608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105325912, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08723592758178711}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 19, "samples_count": 640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326001, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0885927677154541}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 20, "samples_count": 672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326096, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09496712684631348}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 21, "samples_count": 704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326192, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09629440307617188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 22, "samples_count": 736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326282, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08975505828857422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 23, "samples_count": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326372, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09019303321838379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 24, "samples_count": 800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08969831466674805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 25, "samples_count": 832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326547, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08547067642211914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 26, "samples_count": 864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326633, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08615660667419434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 27, "samples_count": 896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326718, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08523225784301758}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 28, "samples_count": 928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326806, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08804798126220703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 29, "samples_count": 960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08685755729675293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 30, "samples_count": 992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326981, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08801054954528809}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 31, "samples_count": 1024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326985, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 6.411334037780762, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326985, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.838679360691458}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326985, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 8192, "step": 256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105326985, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105338286, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3542287349700928, "reduced_train_loss": 6.286690711975098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 287.0, "samples_count": 9216.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105349570, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3534574508666992, "reduced_train_loss": 6.131308078765869}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 319.0, "samples_count": 10240.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105360862, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3547554016113281, "reduced_train_loss": 6.139093399047852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 351.0, "samples_count": 11264.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105372157, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35256409645080566, "reduced_train_loss": 5.903268814086914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 383.0, "samples_count": 12288.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105383459, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35316038131713867, "reduced_train_loss": 5.863667964935303}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 415.0, "samples_count": 13312.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105394755, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.352771520614624, "reduced_train_loss": 5.624549388885498}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 447.0, "samples_count": 14336.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105406060, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35571837425231934, "reduced_train_loss": 5.554986953735352}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 479.0, "samples_count": 15360.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105417362, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3529045581817627, "reduced_train_loss": 5.449661731719971}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 511.0, "samples_count": 16384.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105417593, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3539365248325339}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105417593, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105417593, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 16384, "step": 512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105417674, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.31839585304260254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 32, "samples_count": 1056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105417760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08610296249389648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 33, "samples_count": 1088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105417848, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08791971206665039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 34, "samples_count": 1120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105417935, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08703160285949707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 35, "samples_count": 1152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418025, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08981537818908691}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 36, "samples_count": 1184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418110, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08499026298522949}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 37, "samples_count": 1216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418195, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08542728424072266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 38, "samples_count": 1248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418283, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08788418769836426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 39, "samples_count": 1280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418370, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0871577262878418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 40, "samples_count": 1312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418463, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09212374687194824}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 41, "samples_count": 1344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418570, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10779428482055664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 42, "samples_count": 1376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418657, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08712363243103027}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 43, "samples_count": 1408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418745, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08776664733886719}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 44, "samples_count": 1440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418835, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08983635902404785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 45, "samples_count": 1472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105418923, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0877230167388916}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 46, "samples_count": 1504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419008, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08540916442871094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 47, "samples_count": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419096, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08772015571594238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 48, "samples_count": 1568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419187, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09128952026367188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 49, "samples_count": 1600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08685708045959473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 50, "samples_count": 1632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419360, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08579325675964355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 51, "samples_count": 1664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419454, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09429168701171875}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 52, "samples_count": 1696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419549, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09437084197998047}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 53, "samples_count": 1728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419639, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09035086631774902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 54, "samples_count": 1760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09066486358642578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 55, "samples_count": 1792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419815, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08552742004394531}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 56, "samples_count": 1824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419908, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09293198585510254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 57, "samples_count": 1856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105419994, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08585596084594727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 58, "samples_count": 1888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420082, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08804106712341309}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 59, "samples_count": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420170, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08826851844787598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 60, "samples_count": 1952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420257, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08734321594238281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 61, "samples_count": 1984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0884089469909668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 62, "samples_count": 2016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420435, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0889291763305664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 63, "samples_count": 2048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420440, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 5.502070426940918, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 16384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.847148146945983}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420440, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 16384, "step": 512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105420440, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105431746, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35179924964904785, "reduced_train_loss": 5.417407035827637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 543.0, "samples_count": 17408.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105443045, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3555924892425537, "reduced_train_loss": 5.302902698516846}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 575.0, "samples_count": 18432.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105454332, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35372471809387207, "reduced_train_loss": 5.355218887329102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 607.0, "samples_count": 19456.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105465637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3562438488006592, "reduced_train_loss": 5.230789661407471}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 639.0, "samples_count": 20480.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105476921, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3528127670288086, "reduced_train_loss": 5.069894790649414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 671.0, "samples_count": 21504.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105488224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3535165786743164, "reduced_train_loss": 5.0802507400512695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 703.0, "samples_count": 22528.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105499530, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35274195671081543, "reduced_train_loss": 5.017484664916992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 735.0, "samples_count": 23552.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105510829, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3531675338745117, "reduced_train_loss": 4.97712516784668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 767.0, "samples_count": 24576.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511056, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35396828870761965}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511056, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511056, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 24576, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511138, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3164217472076416}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 64, "samples_count": 2080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511229, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09113097190856934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 65, "samples_count": 2112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511315, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08612370491027832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 66, "samples_count": 2144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511403, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08733367919921875}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 67, "samples_count": 2176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08740091323852539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 68, "samples_count": 2208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511579, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0888967514038086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 69, "samples_count": 2240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511669, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08952641487121582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 70, "samples_count": 2272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511753, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08477592468261719}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 71, "samples_count": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511843, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08921313285827637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 72, "samples_count": 2336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105511930, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08694767951965332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 73, "samples_count": 2368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512034, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10483694076538086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 74, "samples_count": 2400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512136, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10195183753967285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 75, "samples_count": 2432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512230, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09320998191833496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 76, "samples_count": 2464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08677816390991211}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 77, "samples_count": 2496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512405, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08876514434814453}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 78, "samples_count": 2528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512493, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08839797973632812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 79, "samples_count": 2560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08638119697570801}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 80, "samples_count": 2592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512668, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08771014213562012}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 81, "samples_count": 2624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512755, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08788156509399414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 82, "samples_count": 2656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512845, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08932685852050781}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 83, "samples_count": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105512934, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08961915969848633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 84, "samples_count": 2720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513032, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09796619415283203}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 85, "samples_count": 2752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513122, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09003686904907227}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 86, "samples_count": 2784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0915067195892334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 87, "samples_count": 2816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513305, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09064674377441406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 88, "samples_count": 2848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513393, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08890867233276367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 89, "samples_count": 2880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513481, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08714413642883301}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 90, "samples_count": 2912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513569, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08852767944335938}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 91, "samples_count": 2944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513658, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08849358558654785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 92, "samples_count": 2976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513748, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09073185920715332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 93, "samples_count": 3008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513836, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08789396286010742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 94, "samples_count": 3040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513925, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0886690616607666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 95, "samples_count": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513930, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 4.918043613433838, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 24576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513930, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.874388881959021}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513930, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 24576, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105513930, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105525230, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3531177043914795, "reduced_train_loss": 4.769730567932129}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 799.0, "samples_count": 25600.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105536513, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3527507781982422, "reduced_train_loss": 4.753397464752197}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 831.0, "samples_count": 26624.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105547801, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35295748710632324, "reduced_train_loss": 4.734390735626221}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 863.0, "samples_count": 27648.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105559095, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35190725326538086, "reduced_train_loss": 4.6655683517456055}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 895.0, "samples_count": 28672.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105570382, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3522214889526367, "reduced_train_loss": 4.618110656738281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 927.0, "samples_count": 29696.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105581685, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35378599166870117, "reduced_train_loss": 4.537898063659668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 959.0, "samples_count": 30720.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105592985, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3514096736907959, "reduced_train_loss": 4.546258449554443}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 991.0, "samples_count": 31744.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604280, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3544149398803711, "reduced_train_loss": 4.477992057800293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1023.0, "samples_count": 32768.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604513, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35383896915300284}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604514, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 1024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604514, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 32768, "step": 1024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604595, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.321185827255249}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 96, "samples_count": 3104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604685, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0896756649017334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 97, "samples_count": 3136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604770, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08543825149536133}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 98, "samples_count": 3168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604855, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08440327644348145}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 99, "samples_count": 3200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105604943, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08810806274414062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 100, "samples_count": 3232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08643889427185059}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 101, "samples_count": 3264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08755660057067871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 102, "samples_count": 3296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605207, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09027552604675293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 103, "samples_count": 3328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605294, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0866994857788086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 104, "samples_count": 3360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605383, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08953261375427246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 105, "samples_count": 3392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605489, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10544490814208984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 106, "samples_count": 3424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08862042427062988}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 107, "samples_count": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605664, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08643174171447754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 108, "samples_count": 3488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605753, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08917641639709473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 109, "samples_count": 3520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605843, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09020209312438965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 110, "samples_count": 3552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105605931, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08746600151062012}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 111, "samples_count": 3584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08783793449401855}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 112, "samples_count": 3616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606109, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0900583267211914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 113, "samples_count": 3648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606195, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0867462158203125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 114, "samples_count": 3680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606284, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08897662162780762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 115, "samples_count": 3712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606375, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09043049812316895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 116, "samples_count": 3744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606472, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0972139835357666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 117, "samples_count": 3776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606560, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08834171295166016}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 118, "samples_count": 3808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606649, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08897233009338379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 119, "samples_count": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606741, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09212470054626465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 120, "samples_count": 3872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606833, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09136581420898438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 121, "samples_count": 3904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105606921, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08786821365356445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 122, "samples_count": 3936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607006, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08492374420166016}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 123, "samples_count": 3968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607093, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08760643005371094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 124, "samples_count": 4000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607182, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08877062797546387}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 125, "samples_count": 4032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08654665946960449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 126, "samples_count": 4064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09051942825317383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 127, "samples_count": 4096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607364, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 4.450746536254883, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 32768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607364, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8514154688455164}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607365, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 32768, "step": 1024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105607365, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 1024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105618662, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3527226448059082, "reduced_train_loss": 4.380725860595703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1055.0, "samples_count": 33792.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105629955, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35475921630859375, "reduced_train_loss": 4.404891014099121}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1087.0, "samples_count": 34816.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105641259, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35295963287353516, "reduced_train_loss": 4.3889360427856445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1119.0, "samples_count": 35840.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105652568, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3519120216369629, "reduced_train_loss": 4.510530471801758}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1151.0, "samples_count": 36864.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105663864, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35254693031311035, "reduced_train_loss": 4.312621593475342}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1183.0, "samples_count": 37888.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105675156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3533792495727539, "reduced_train_loss": 4.279033660888672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1215.0, "samples_count": 38912.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105686459, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35209178924560547, "reduced_train_loss": 4.292619705200195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1247.0, "samples_count": 39936.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105697754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35390233993530273, "reduced_train_loss": 4.200900077819824}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1279.0, "samples_count": 40960.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105697987, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3539939946440427}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105697987, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 1280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105697987, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 40960, "step": 1280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698070, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3218393325805664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 128, "samples_count": 4128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698155, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0853579044342041}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 129, "samples_count": 4160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698241, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08573770523071289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 130, "samples_count": 4192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698325, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08474516868591309}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 131, "samples_count": 4224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698412, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08695125579833984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 132, "samples_count": 4256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698499, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08666205406188965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 133, "samples_count": 4288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08748841285705566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 134, "samples_count": 4320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08622217178344727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 135, "samples_count": 4352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698762, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08902478218078613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 136, "samples_count": 4384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698854, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09270548820495605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 137, "samples_count": 4416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105698958, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10402846336364746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 138, "samples_count": 4448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08804631233215332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 139, "samples_count": 4480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699134, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08797597885131836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 140, "samples_count": 4512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699227, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09250950813293457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 141, "samples_count": 4544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699315, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0877225399017334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 142, "samples_count": 4576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699405, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09035205841064453}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 143, "samples_count": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08650708198547363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 144, "samples_count": 4640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08798074722290039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 145, "samples_count": 4672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699666, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08694338798522949}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 146, "samples_count": 4704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08767390251159668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 147, "samples_count": 4736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699851, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0968008041381836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 148, "samples_count": 4768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105699943, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09179329872131348}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 149, "samples_count": 4800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700034, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0910496711730957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 150, "samples_count": 4832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700123, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08874082565307617}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 151, "samples_count": 4864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700209, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08628177642822266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 152, "samples_count": 4896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700300, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09073281288146973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 153, "samples_count": 4928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700390, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08997488021850586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 154, "samples_count": 4960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700478, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0884103775024414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 155, "samples_count": 4992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700567, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0893545150756836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 156, "samples_count": 5024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700653, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08572721481323242}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 157, "samples_count": 5056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700742, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08935761451721191}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 158, "samples_count": 5088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700833, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09046745300292969}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 159, "samples_count": 5120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700838, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 4.2217559814453125, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 40960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700838, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.85138053400442}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700838, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 40960, "step": 1280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105700838, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 1280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105712139, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35276222229003906, "reduced_train_loss": 4.233739376068115}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1311.0, "samples_count": 41984.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105723432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35353732109069824, "reduced_train_loss": 4.1878461837768555}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1343.0, "samples_count": 43008.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105734748, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35254621505737305, "reduced_train_loss": 4.14547061920166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1375.0, "samples_count": 44032.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105746041, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35376405715942383, "reduced_train_loss": 4.17747688293457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1407.0, "samples_count": 45056.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105757352, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35402512550354004, "reduced_train_loss": 4.04708194732666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1439.0, "samples_count": 46080.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105768645, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3509705066680908, "reduced_train_loss": 4.250134468078613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1471.0, "samples_count": 47104.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105779950, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3538193702697754, "reduced_train_loss": 3.9940524101257324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1503.0, "samples_count": 48128.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791252, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3527987003326416, "reduced_train_loss": 3.9696452617645264}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1535.0, "samples_count": 49152.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35409655658986594}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791488, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791488, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 49152, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791570, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.32405853271484375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 160, "samples_count": 5152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08949112892150879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 161, "samples_count": 5184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791746, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08650612831115723}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 162, "samples_count": 5216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791832, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08566665649414062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 163, "samples_count": 5248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105791919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08679604530334473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 164, "samples_count": 5280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792007, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08869099617004395}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 165, "samples_count": 5312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792094, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0863337516784668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 166, "samples_count": 5344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792179, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08535218238830566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 167, "samples_count": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08916711807250977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 168, "samples_count": 5408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792356, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08819770812988281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 169, "samples_count": 5440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792459, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10226297378540039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 170, "samples_count": 5472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792550, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09168696403503418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 171, "samples_count": 5504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792641, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09049820899963379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 172, "samples_count": 5536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792732, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09097623825073242}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 173, "samples_count": 5568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792818, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0859074592590332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 174, "samples_count": 5600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792904, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0862894058227539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 175, "samples_count": 5632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105792991, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08735537528991699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 176, "samples_count": 5664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793080, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08887863159179688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 177, "samples_count": 5696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793169, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08824968338012695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 178, "samples_count": 5728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793255, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08641934394836426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 179, "samples_count": 5760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793349, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09392428398132324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 180, "samples_count": 5792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793441, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09196114540100098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 181, "samples_count": 5824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793533, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09227299690246582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 182, "samples_count": 5856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793622, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0888369083404541}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 183, "samples_count": 5888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793713, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09063172340393066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 184, "samples_count": 5920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793802, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08978533744812012}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 185, "samples_count": 5952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793888, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08602190017700195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 186, "samples_count": 5984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105793976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08786153793334961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 187, "samples_count": 6016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105794066, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08955860137939453}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 188, "samples_count": 6048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105794153, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08712387084960938}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 189, "samples_count": 6080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105794245, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0915381908416748}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 190, "samples_count": 6112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105794335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09082627296447754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 191, "samples_count": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105794336, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 4.056166648864746, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 49152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105794336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.848900855053216}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105794336, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 49152, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105794336, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105805643, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3523728847503662, "reduced_train_loss": 4.026395320892334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1567.0, "samples_count": 50176.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105816936, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3549160957336426, "reduced_train_loss": 4.020368576049805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1599.0, "samples_count": 51200.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105828238, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3544323444366455, "reduced_train_loss": 4.130483150482178}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1631.0, "samples_count": 52224.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105839535, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.352020263671875, "reduced_train_loss": 3.966149091720581}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1663.0, "samples_count": 53248.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105850840, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3563530445098877, "reduced_train_loss": 4.016151428222656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1695.0, "samples_count": 54272.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105862144, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3521604537963867, "reduced_train_loss": 4.045505046844482}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1727.0, "samples_count": 55296.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105873443, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35367655754089355, "reduced_train_loss": 3.950021982192993}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1759.0, "samples_count": 56320.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105884732, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3529846668243408, "reduced_train_loss": 3.9819204807281494}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1791.0, "samples_count": 57344.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105884964, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540142259298591}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105884964, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 1792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105884964, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 57344, "step": 1792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.32086849212646484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 192, "samples_count": 6176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885136, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09015345573425293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 193, "samples_count": 6208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885227, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09074592590332031}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 194, "samples_count": 6240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885312, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08483362197875977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 195, "samples_count": 6272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885400, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08758044242858887}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 196, "samples_count": 6304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08732199668884277}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 197, "samples_count": 6336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885575, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08774662017822266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 198, "samples_count": 6368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885662, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08711457252502441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 199, "samples_count": 6400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885748, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08625674247741699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 200, "samples_count": 6432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885839, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09091401100158691}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 201, "samples_count": 6464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105885938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09926176071166992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 202, "samples_count": 6496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09124088287353516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 203, "samples_count": 6528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08709931373596191}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 204, "samples_count": 6560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886207, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09044122695922852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 205, "samples_count": 6592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886295, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08770227432250977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 206, "samples_count": 6624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08964323997497559}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 207, "samples_count": 6656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886473, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08844184875488281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 208, "samples_count": 6688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886562, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08871746063232422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 209, "samples_count": 6720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886649, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08760952949523926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 210, "samples_count": 6752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886736, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08644413948059082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 211, "samples_count": 6784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886828, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09274172782897949}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 212, "samples_count": 6816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105886922, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09347248077392578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 213, "samples_count": 6848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887015, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09305477142333984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 214, "samples_count": 6880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887109, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0943763256072998}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 215, "samples_count": 6912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887199, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08969783782958984}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 216, "samples_count": 6944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887285, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0864098072052002}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 217, "samples_count": 6976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887372, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0868833065032959}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 218, "samples_count": 7008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887461, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08858847618103027}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 219, "samples_count": 7040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887552, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0914762020111084}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 220, "samples_count": 7072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887644, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09124970436096191}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 221, "samples_count": 7104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887731, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08752894401550293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 222, "samples_count": 7136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887821, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08981919288635254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 223, "samples_count": 7168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887823, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.9456937313079834, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 57344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887823, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8592314198613167}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 1792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887823, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 57344, "step": 1792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105887823, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 1792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105899147, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35338807106018066, "reduced_train_loss": 3.894916534423828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1823.0, "samples_count": 58368.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105910453, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.351534366607666, "reduced_train_loss": 3.932715892791748}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1855.0, "samples_count": 59392.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105921749, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35325121879577637, "reduced_train_loss": 3.9914562702178955}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1887.0, "samples_count": 60416.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105933056, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35248851776123047, "reduced_train_loss": 3.9463393688201904}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1919.0, "samples_count": 61440.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105944363, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3520691394805908, "reduced_train_loss": 3.968397378921509}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1951.0, "samples_count": 62464.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105955668, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35131263732910156, "reduced_train_loss": 3.879831314086914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 1983.0, "samples_count": 63488.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105966969, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35297203063964844, "reduced_train_loss": 3.8438644409179688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2015.0, "samples_count": 64512.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978267, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3534398078918457, "reduced_train_loss": 3.754565477371216}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2047.0, "samples_count": 65536.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978504, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3542215146608214}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978504, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 2048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978504, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 65536, "step": 2048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978585, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3245201110839844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 224, "samples_count": 7200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978670, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08520817756652832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 225, "samples_count": 7232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08395791053771973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 226, "samples_count": 7264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0883479118347168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 227, "samples_count": 7296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105978928, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08532261848449707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 228, "samples_count": 7328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979014, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08613276481628418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 229, "samples_count": 7360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979102, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0882563591003418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 230, "samples_count": 7392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979187, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08501362800598145}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 231, "samples_count": 7424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979275, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08790016174316406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 232, "samples_count": 7456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979367, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09166407585144043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 233, "samples_count": 7488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0975942611694336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 234, "samples_count": 7520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979558, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0938570499420166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 235, "samples_count": 7552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979649, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09071636199951172}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 236, "samples_count": 7584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979735, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.086029052734375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 237, "samples_count": 7616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979823, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08828496932983398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 238, "samples_count": 7648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979910, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0868380069732666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 239, "samples_count": 7680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105979998, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08796572685241699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 240, "samples_count": 7712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980086, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08816766738891602}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 241, "samples_count": 7744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980174, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08821463584899902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 242, "samples_count": 7776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980263, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08803176879882812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 243, "samples_count": 7808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980353, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09062862396240234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 244, "samples_count": 7840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0964207649230957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 245, "samples_count": 7872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980539, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0891563892364502}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 246, "samples_count": 7904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980630, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09160447120666504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 247, "samples_count": 7936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980719, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08870148658752441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 248, "samples_count": 7968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980807, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08783817291259766}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 249, "samples_count": 8000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0893862247467041}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 250, "samples_count": 8032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105980989, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0922842025756836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 251, "samples_count": 8064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105981079, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09014272689819336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 252, "samples_count": 8096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105981167, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08834195137023926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 253, "samples_count": 8128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105981258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09079527854919434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 254, "samples_count": 8160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105981349, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09158945083618164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 255, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105981350, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.856095790863037, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 65536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105981350, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.846451277844608}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 2048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105981350, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 65536, "step": 2048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105981350, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 2048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760105992661, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35366058349609375, "reduced_train_loss": 3.8245127201080322}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2079.0, "samples_count": 66560.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106003959, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35242390632629395, "reduced_train_loss": 3.672203540802002}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2111.0, "samples_count": 67584.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106015260, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3533744812011719, "reduced_train_loss": 3.7084131240844727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2143.0, "samples_count": 68608.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106026561, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3530097007751465, "reduced_train_loss": 3.8478541374206543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2175.0, "samples_count": 69632.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106037867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3515899181365967, "reduced_train_loss": 3.824169635772705}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2207.0, "samples_count": 70656.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106049172, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35204148292541504, "reduced_train_loss": 3.778747320175171}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2239.0, "samples_count": 71680.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106060465, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3526344299316406, "reduced_train_loss": 3.804265260696411}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2271.0, "samples_count": 72704.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106071762, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35361146926879883, "reduced_train_loss": 3.743419647216797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2303.0, "samples_count": 73728.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106071992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35406838275412156}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106071992, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106071992, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 73728, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072075, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3190131187438965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 256, "samples_count": 8224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072162, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08756494522094727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 257, "samples_count": 8256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072249, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08692336082458496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 258, "samples_count": 8288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08700966835021973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 259, "samples_count": 8320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072424, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08756637573242188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 260, "samples_count": 8352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072511, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08761978149414062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 261, "samples_count": 8384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072598, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08638906478881836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 262, "samples_count": 8416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072684, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08677840232849121}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 263, "samples_count": 8448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072773, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08830070495605469}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 264, "samples_count": 8480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072864, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09078001976013184}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 265, "samples_count": 8512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106072967, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10307669639587402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 266, "samples_count": 8544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073061, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09417581558227539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 267, "samples_count": 8576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073149, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08809685707092285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 268, "samples_count": 8608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073237, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08822989463806152}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 269, "samples_count": 8640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0900571346282959}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 270, "samples_count": 8672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073414, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08718419075012207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 271, "samples_count": 8704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073506, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09172868728637695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 272, "samples_count": 8736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073593, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08685660362243652}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 273, "samples_count": 8768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073682, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08893489837646484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 274, "samples_count": 8800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073770, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0882420539855957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 275, "samples_count": 8832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073860, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09013772010803223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 276, "samples_count": 8864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106073951, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09090900421142578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 277, "samples_count": 8896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09311199188232422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 278, "samples_count": 8928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074134, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08998346328735352}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 279, "samples_count": 8960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08974456787109375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 280, "samples_count": 8992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08696937561035156}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 281, "samples_count": 9024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074400, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08861970901489258}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 282, "samples_count": 9056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074488, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08822798728942871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 283, "samples_count": 9088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0890340805053711}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 284, "samples_count": 9120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074667, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09014773368835449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 285, "samples_count": 9152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074756, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08850288391113281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 286, "samples_count": 9184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074846, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09078383445739746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 287, "samples_count": 9216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074848, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.777604579925537, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 73728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074848, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.856612174306065}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074848, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 73728, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106074848, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106086166, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3505103588104248, "reduced_train_loss": 3.7060368061065674}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2335.0, "samples_count": 74752.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106097464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35321569442749023, "reduced_train_loss": 3.6727116107940674}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2367.0, "samples_count": 75776.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106108767, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35269975662231445, "reduced_train_loss": 3.681400775909424}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2399.0, "samples_count": 76800.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106120079, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35384535789489746, "reduced_train_loss": 3.794908285140991}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2431.0, "samples_count": 77824.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106131382, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35260534286499023, "reduced_train_loss": 3.729538917541504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2463.0, "samples_count": 78848.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106142688, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35485076904296875, "reduced_train_loss": 3.704171895980835}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2495.0, "samples_count": 79872.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106153984, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35098719596862793, "reduced_train_loss": 3.734158515930176}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2527.0, "samples_count": 80896.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165279, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3546156883239746, "reduced_train_loss": 3.733109951019287}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2559.0, "samples_count": 81920.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165511, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35415233937419544}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165512, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 2560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165512, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 81920, "step": 2560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165594, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3210611343383789}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 288, "samples_count": 9248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165679, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08556914329528809}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 289, "samples_count": 9280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165769, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08984541893005371}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 290, "samples_count": 9312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165855, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08564949035644531}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 291, "samples_count": 9344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106165943, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08758068084716797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 292, "samples_count": 9376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08717513084411621}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 293, "samples_count": 9408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0883328914642334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 294, "samples_count": 9440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166207, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0886538028717041}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 295, "samples_count": 9472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166294, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08744263648986816}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 296, "samples_count": 9504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08956193923950195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 297, "samples_count": 9536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166484, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10070300102233887}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 298, "samples_count": 9568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09279870986938477}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 299, "samples_count": 9600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166667, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08966398239135742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 300, "samples_count": 9632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166753, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08610749244689941}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 301, "samples_count": 9664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08927488327026367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 302, "samples_count": 9696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106166929, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08627820014953613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 303, "samples_count": 9728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167016, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08720755577087402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 304, "samples_count": 9760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167106, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09017610549926758}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 305, "samples_count": 9792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167192, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08645963668823242}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 306, "samples_count": 9824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167281, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08881711959838867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 307, "samples_count": 9856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167371, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0895986557006836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 308, "samples_count": 9888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167467, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09600329399108887}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 309, "samples_count": 9920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09036588668823242}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 310, "samples_count": 9952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167647, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09028363227844238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 311, "samples_count": 9984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167735, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08728933334350586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 312, "samples_count": 10016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09207892417907715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 313, "samples_count": 10048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106167914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08726692199707031}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 314, "samples_count": 10080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168005, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09117889404296875}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 315, "samples_count": 10112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168091, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08538103103637695}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 316, "samples_count": 10144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168179, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0884542465209961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 317, "samples_count": 10176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08846759796142578}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 318, "samples_count": 10208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168358, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09036397933959961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 319, "samples_count": 10240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168363, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.7215006351470947, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 81920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168363, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.85203227493912}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 2560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168363, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 81920, "step": 2560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106168363, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 2560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106179676, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3524625301361084, "reduced_train_loss": 3.759106397628784}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2591.0, "samples_count": 82944.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106190970, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35422301292419434, "reduced_train_loss": 3.7762439250946045}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2623.0, "samples_count": 83968.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106202263, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3520660400390625, "reduced_train_loss": 3.7511520385742188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2655.0, "samples_count": 84992.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106213565, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3520627021789551, "reduced_train_loss": 3.7002973556518555}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2687.0, "samples_count": 86016.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106224861, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35445165634155273, "reduced_train_loss": 3.647879123687744}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2719.0, "samples_count": 87040.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106236152, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35254502296447754, "reduced_train_loss": 3.6974875926971436}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2751.0, "samples_count": 88064.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106247454, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3530616760253906, "reduced_train_loss": 3.6409873962402344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2783.0, "samples_count": 89088.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106258749, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35229969024658203, "reduced_train_loss": 3.75242018699646}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2815.0, "samples_count": 90112.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106258983, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35398382565290376}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106258983, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 2816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106258984, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 90112, "step": 2816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259065, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.32208824157714844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 320, "samples_count": 10272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259150, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08534693717956543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 321, "samples_count": 10304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259237, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08693838119506836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 322, "samples_count": 10336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259325, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08742427825927734}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 323, "samples_count": 10368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08633828163146973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 324, "samples_count": 10400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08565855026245117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 325, "samples_count": 10432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08689165115356445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 326, "samples_count": 10464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259671, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0875539779663086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 327, "samples_count": 10496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259759, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08741879463195801}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 328, "samples_count": 10528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259849, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09001994132995605}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 329, "samples_count": 10560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106259949, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10090827941894531}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 330, "samples_count": 10592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260039, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09000420570373535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 331, "samples_count": 10624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260130, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0908517837524414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 332, "samples_count": 10656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260220, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08961796760559082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 333, "samples_count": 10688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09067797660827637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 334, "samples_count": 10720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260397, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08614730834960938}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 335, "samples_count": 10752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260486, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08960342407226562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 336, "samples_count": 10784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260571, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08497452735900879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 337, "samples_count": 10816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08881878852844238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 338, "samples_count": 10848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260746, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08558273315429688}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 339, "samples_count": 10880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260839, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09320616722106934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 340, "samples_count": 10912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106260935, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09610199928283691}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 341, "samples_count": 10944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09161567687988281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 342, "samples_count": 10976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09195399284362793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 343, "samples_count": 11008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261208, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08888554573059082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 344, "samples_count": 11040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09056520462036133}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 345, "samples_count": 11072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0857551097869873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 346, "samples_count": 11104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261470, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0863344669342041}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 347, "samples_count": 11136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261558, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08791923522949219}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 348, "samples_count": 11168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261643, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08490657806396484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 349, "samples_count": 11200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261732, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08893799781799316}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 350, "samples_count": 11232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261823, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09084129333496094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 351, "samples_count": 11264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261827, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.6689820289611816, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 90112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8441387889906764}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 2816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261827, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 90112, "step": 2816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106261827, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 2816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106273144, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3528633117675781, "reduced_train_loss": 3.617783308029175}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2847.0, "samples_count": 91136.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106284440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35417962074279785, "reduced_train_loss": 3.727307081222534}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2879.0, "samples_count": 92160.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106295738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3532743453979492, "reduced_train_loss": 3.5987792015075684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2911.0, "samples_count": 93184.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106307035, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35628485679626465, "reduced_train_loss": 3.6990716457366943}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2943.0, "samples_count": 94208.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106318338, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3522639274597168, "reduced_train_loss": 3.7083804607391357}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 2975.0, "samples_count": 95232.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106329635, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3513615131378174, "reduced_train_loss": 3.592226505279541}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3007.0, "samples_count": 96256.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106340938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3547687530517578, "reduced_train_loss": 3.5911307334899902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3039.0, "samples_count": 97280.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352230, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3531060218811035, "reduced_train_loss": 3.551156997680664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3071.0, "samples_count": 98304.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352468, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540648351681739}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352468, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352468, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 98304, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352551, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.32827162742614746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 352, "samples_count": 11296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09148430824279785}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 353, "samples_count": 11328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352728, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0861365795135498}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 354, "samples_count": 11360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352816, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08759117126464844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 355, "samples_count": 11392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352903, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0876009464263916}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 356, "samples_count": 11424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106352990, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08676767349243164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 357, "samples_count": 11456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08641719818115234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 358, "samples_count": 11488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353167, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09040260314941406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 359, "samples_count": 11520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353252, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08475923538208008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 360, "samples_count": 11552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353340, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08831143379211426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 361, "samples_count": 11584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353441, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.100921630859375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 362, "samples_count": 11616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353534, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09348630905151367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 363, "samples_count": 11648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353626, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09139561653137207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 364, "samples_count": 11680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0847468376159668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 365, "samples_count": 11712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353799, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08794283866882324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 366, "samples_count": 11744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08856940269470215}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 367, "samples_count": 11776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106353974, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08678030967712402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 368, "samples_count": 11808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354063, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08896160125732422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 369, "samples_count": 11840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354147, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08429646492004395}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 370, "samples_count": 11872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354234, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08720636367797852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 371, "samples_count": 11904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354324, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09005379676818848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 372, "samples_count": 11936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354415, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09038758277893066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 373, "samples_count": 11968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354509, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09421658515930176}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 374, "samples_count": 12000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354602, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09263205528259277}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 375, "samples_count": 12032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354691, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08888101577758789}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 376, "samples_count": 12064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354777, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08650565147399902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 377, "samples_count": 12096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08998298645019531}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 378, "samples_count": 12128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106354956, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0894162654876709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 379, "samples_count": 12160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106355044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0878899097442627}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 380, "samples_count": 12192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106355132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08742117881774902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 381, "samples_count": 12224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106355222, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09005999565124512}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 382, "samples_count": 12256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106355313, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09133195877075195}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 383, "samples_count": 12288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106355316, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.613114595413208, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 98304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106355316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8482487429864705}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106355316, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 98304, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106355316, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106366628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3534665107727051, "reduced_train_loss": 3.6592676639556885}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3103.0, "samples_count": 99328.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106377932, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3538031578063965, "reduced_train_loss": 3.5773167610168457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3135.0, "samples_count": 100352.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106389234, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3522074222564697, "reduced_train_loss": 3.530303478240967}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3167.0, "samples_count": 101376.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106400527, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3510575294494629, "reduced_train_loss": 3.5250742435455322}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3199.0, "samples_count": 102400.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106411819, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35446858406066895, "reduced_train_loss": 3.6381919384002686}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3231.0, "samples_count": 103424.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106423135, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3561100959777832, "reduced_train_loss": 3.501692056655884}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3263.0, "samples_count": 104448.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106434423, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35095977783203125, "reduced_train_loss": 3.6047873497009277}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3295.0, "samples_count": 105472.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106445726, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3526499271392822, "reduced_train_loss": 3.531562328338623}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3327.0, "samples_count": 106496.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106445961, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540819154404744}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106445961, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 3328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106445962, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 106496, "step": 3328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446043, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3229062557220459}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 384, "samples_count": 12320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446126, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08424210548400879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 385, "samples_count": 12352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446213, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08677411079406738}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 386, "samples_count": 12384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446300, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08659005165100098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 387, "samples_count": 12416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446387, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08711385726928711}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 388, "samples_count": 12448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446474, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08685898780822754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 389, "samples_count": 12480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446564, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09041213989257812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 390, "samples_count": 12512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0843203067779541}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 391, "samples_count": 12544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446735, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08637690544128418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 392, "samples_count": 12576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446822, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08717966079711914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 393, "samples_count": 12608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106446923, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10076546669006348}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 394, "samples_count": 12640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447018, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09490561485290527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 395, "samples_count": 12672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08978867530822754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 396, "samples_count": 12704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447196, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08840513229370117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 397, "samples_count": 12736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447285, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08894705772399902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 398, "samples_count": 12768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08819913864135742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 399, "samples_count": 12800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08849573135375977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 400, "samples_count": 12832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447549, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08789229393005371}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 401, "samples_count": 12864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08615279197692871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 402, "samples_count": 12896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447723, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08771920204162598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 403, "samples_count": 12928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447817, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09402823448181152}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 404, "samples_count": 12960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106447909, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09200787544250488}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 405, "samples_count": 12992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448000, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09029078483581543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 406, "samples_count": 13024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448091, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0910334587097168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 407, "samples_count": 13056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08733296394348145}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 408, "samples_count": 13088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08949971199035645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 409, "samples_count": 13120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448356, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08815240859985352}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 410, "samples_count": 13152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448444, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08829474449157715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 411, "samples_count": 13184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448532, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08835554122924805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 412, "samples_count": 13216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448622, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08981466293334961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 413, "samples_count": 13248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448710, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08777093887329102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 414, "samples_count": 13280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448800, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09058427810668945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 415, "samples_count": 13312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448805, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.5676867961883545, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 106496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448805, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.844536740332842}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448806, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 106496, "step": 3328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106448806, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 3328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106460118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540818691253662, "reduced_train_loss": 3.5409390926361084}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3359.0, "samples_count": 107520.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106471424, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35294318199157715, "reduced_train_loss": 3.5287024974823}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3391.0, "samples_count": 108544.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106482720, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.353534460067749, "reduced_train_loss": 3.513711929321289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3423.0, "samples_count": 109568.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106494021, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3549337387084961, "reduced_train_loss": 3.4869847297668457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3455.0, "samples_count": 110592.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106505314, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3525879383087158, "reduced_train_loss": 3.4259214401245117}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3487.0, "samples_count": 111616.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106516605, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3530263900756836, "reduced_train_loss": 3.5299649238586426}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3519.0, "samples_count": 112640.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106527901, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3535475730895996, "reduced_train_loss": 3.5395278930664062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3551.0, "samples_count": 113664.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539194, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3529367446899414, "reduced_train_loss": 3.4675838947296143}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3583.0, "samples_count": 114688.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539428, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3539950479280378}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539429, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 3584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539429, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 114688, "step": 3584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539511, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3236260414123535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 416, "samples_count": 13344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539596, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08483481407165527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 417, "samples_count": 13376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539683, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08674860000610352}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 418, "samples_count": 13408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539773, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09048938751220703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 419, "samples_count": 13440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539860, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08623290061950684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 420, "samples_count": 13472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106539946, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08679580688476562}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 421, "samples_count": 13504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540032, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08587336540222168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 422, "samples_count": 13536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08642101287841797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 423, "samples_count": 13568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540206, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08783364295959473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 424, "samples_count": 13600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540297, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09068131446838379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 425, "samples_count": 13632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540401, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10401344299316406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 426, "samples_count": 13664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540493, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09193277359008789}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 427, "samples_count": 13696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09084129333496094}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 428, "samples_count": 13728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540670, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0864105224609375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 429, "samples_count": 13760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08958721160888672}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 430, "samples_count": 13792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540845, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08505558967590332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 431, "samples_count": 13824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106540933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08797311782836914}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 432, "samples_count": 13856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541021, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08808135986328125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 433, "samples_count": 13888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08591437339782715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 434, "samples_count": 13920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541194, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08720970153808594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 435, "samples_count": 13952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541284, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0895853042602539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 436, "samples_count": 13984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541378, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09423375129699707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 437, "samples_count": 14016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541467, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08923745155334473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 438, "samples_count": 14048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541560, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09258532524108887}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 439, "samples_count": 14080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541650, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08974123001098633}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 440, "samples_count": 14112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541737, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08757138252258301}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 441, "samples_count": 14144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541829, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09233641624450684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 442, "samples_count": 14176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106541919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08911824226379395}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 443, "samples_count": 14208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106542008, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08939647674560547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 444, "samples_count": 14240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106542093, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08544254302978516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 445, "samples_count": 14272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106542182, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08849072456359863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 446, "samples_count": 14304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106542273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09113454818725586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 447, "samples_count": 14336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106542276, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.5264806747436523, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 114688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106542276, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.847989885136485}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106542276, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 114688, "step": 3584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106542276, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 3584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106553595, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.351701021194458, "reduced_train_loss": 3.537248134613037}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3615.0, "samples_count": 115712.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106564894, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35349440574645996, "reduced_train_loss": 3.524799108505249}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3647.0, "samples_count": 116736.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106576196, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3531503677368164, "reduced_train_loss": 3.528653860092163}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3679.0, "samples_count": 117760.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106587499, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3535268306732178, "reduced_train_loss": 3.475771427154541}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3711.0, "samples_count": 118784.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106598804, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540325164794922, "reduced_train_loss": 3.501488208770752}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3743.0, "samples_count": 119808.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106610102, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3524284362792969, "reduced_train_loss": 3.4631175994873047}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3775.0, "samples_count": 120832.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106621401, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3529496192932129, "reduced_train_loss": 3.544555902481079}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3807.0, "samples_count": 121856.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106632708, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35361409187316895, "reduced_train_loss": 3.5345678329467773}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3839.0, "samples_count": 122880.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106632939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35415256248052174}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106632940, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106632940, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 122880, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3190314769744873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 448, "samples_count": 14368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633114, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09404253959655762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 449, "samples_count": 14400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633205, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09137153625488281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 450, "samples_count": 14432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633290, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08538222312927246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 451, "samples_count": 14464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633376, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08583402633666992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 452, "samples_count": 14496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08588218688964844}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 453, "samples_count": 14528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633549, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0866541862487793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 454, "samples_count": 14560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633635, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08631730079650879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 455, "samples_count": 14592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633722, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08635401725769043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 456, "samples_count": 14624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633809, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0877995491027832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 457, "samples_count": 14656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106633913, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10318684577941895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 458, "samples_count": 14688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634008, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09595918655395508}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 459, "samples_count": 14720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634094, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08585739135742188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 460, "samples_count": 14752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634186, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09210824966430664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 461, "samples_count": 14784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08683919906616211}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 462, "samples_count": 14816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634364, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09095001220703125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 463, "samples_count": 14848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634449, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08453893661499023}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 464, "samples_count": 14880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634535, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0863344669342041}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 465, "samples_count": 14912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634623, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08763837814331055}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 466, "samples_count": 14944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634708, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08554506301879883}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 467, "samples_count": 14976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634802, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09344625473022461}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 468, "samples_count": 15008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634894, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09232282638549805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 469, "samples_count": 15040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106634988, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09398388862609863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 470, "samples_count": 15072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08879709243774414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 471, "samples_count": 15104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09144020080566406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 472, "samples_count": 15136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635255, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08719086647033691}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 473, "samples_count": 15168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635345, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0891871452331543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 474, "samples_count": 15200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635431, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08679437637329102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 475, "samples_count": 15232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635518, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0861203670501709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 476, "samples_count": 15264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635606, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0883932113647461}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 477, "samples_count": 15296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635693, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08721446990966797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 478, "samples_count": 15328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635783, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09023213386535645}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 479, "samples_count": 15360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635788, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.4947867393493652, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 122880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635788, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.849147971253842}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635788, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 122880, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106635789, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 3840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106647110, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35408592224121094, "reduced_train_loss": 3.5799694061279297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3871.0, "samples_count": 123904.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106658416, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3521850109100342, "reduced_train_loss": 3.456392765045166}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3903.0, "samples_count": 124928.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106669707, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3524341583251953, "reduced_train_loss": 3.5282599925994873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3935.0, "samples_count": 125952.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106680998, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35285282135009766, "reduced_train_loss": 3.5260300636291504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3967.0, "samples_count": 126976.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106692280, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35289669036865234, "reduced_train_loss": 3.4486477375030518}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 3999.0, "samples_count": 128000.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106703567, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35267043113708496, "reduced_train_loss": 3.5091898441314697}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4031.0, "samples_count": 129024.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106714859, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35389256477355957, "reduced_train_loss": 3.4937500953674316}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4063.0, "samples_count": 130048.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3515012264251709, "reduced_train_loss": 3.4493699073791504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4095.0, "samples_count": 131072.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726388, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3539025713780575}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726388, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 4096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726388, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 131072, "step": 4096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726470, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3215808868408203}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 480, "samples_count": 15392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726560, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09042191505432129}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 481, "samples_count": 15424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726646, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08617568016052246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 482, "samples_count": 15456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726735, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08843016624450684}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 483, "samples_count": 15488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726821, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08648157119750977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 484, "samples_count": 15520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726907, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08612608909606934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 485, "samples_count": 15552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106726995, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08727860450744629}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 486, "samples_count": 15584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727082, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08774399757385254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 487, "samples_count": 15616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727167, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08484601974487305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 488, "samples_count": 15648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727257, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08978605270385742}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 489, "samples_count": 15680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10172080993652344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 490, "samples_count": 15712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727455, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09588074684143066}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 491, "samples_count": 15744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727545, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09051203727722168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 492, "samples_count": 15776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0912163257598877}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 493, "samples_count": 15808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727722, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08568286895751953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 494, "samples_count": 15840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727807, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0848088264465332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 495, "samples_count": 15872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727894, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08756399154663086}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 496, "samples_count": 15904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106727984, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08935141563415527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 497, "samples_count": 15936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728071, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08697938919067383}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 498, "samples_count": 15968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728159, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08821392059326172}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 499, "samples_count": 16000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728246, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08664417266845703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 500, "samples_count": 16032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728338, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09261298179626465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 501, "samples_count": 16064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728435, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09642386436462402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 502, "samples_count": 16096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728525, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09029006958007812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 503, "samples_count": 16128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728614, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08915877342224121}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 504, "samples_count": 16160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728702, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08822894096374512}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 505, "samples_count": 16192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728788, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08594560623168945}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 506, "samples_count": 16224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728876, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08776235580444336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 507, "samples_count": 16256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106728964, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08834695816040039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 508, "samples_count": 16288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106729052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0879814624786377}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 509, "samples_count": 16320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106729142, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08926892280578613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 510, "samples_count": 16352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106729232, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09015059471130371}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 511, "samples_count": 16384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106729235, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.464704751968384, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 131072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106729235, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8478582790121436}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106729235, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 131072, "step": 4096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106729235, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 4096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106740542, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3526787757873535, "reduced_train_loss": 3.5049073696136475}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4127.0, "samples_count": 132096.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106751847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35257840156555176, "reduced_train_loss": 3.5255532264709473}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4159.0, "samples_count": 133120.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106763141, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.353682279586792, "reduced_train_loss": 3.4349799156188965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4191.0, "samples_count": 134144.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106774449, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3539607524871826, "reduced_train_loss": 3.4455666542053223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4223.0, "samples_count": 135168.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106785735, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35788393020629883, "reduced_train_loss": 3.473918914794922}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4255.0, "samples_count": 136192.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106797032, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3512098789215088, "reduced_train_loss": 3.4662697315216064}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4287.0, "samples_count": 137216.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106808326, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35248851776123047, "reduced_train_loss": 3.4382059574127197}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4319.0, "samples_count": 138240.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106819624, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3537149429321289, "reduced_train_loss": 3.4122180938720703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4351.0, "samples_count": 139264.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106819857, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35398876762883447}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106819857, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 4352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106819857, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 139264, "step": 4352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106819939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3204212188720703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 512, "samples_count": 16416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09087538719177246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 513, "samples_count": 16448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0882411003112793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 514, "samples_count": 16480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820205, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08726167678833008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 515, "samples_count": 16512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820292, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08649277687072754}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 516, "samples_count": 16544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820379, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08741354942321777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 517, "samples_count": 16576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820465, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08562898635864258}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 518, "samples_count": 16608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820550, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08529543876647949}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 519, "samples_count": 16640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820636, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08655714988708496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 520, "samples_count": 16672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09308910369873047}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 521, "samples_count": 16704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820828, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0982666015625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 522, "samples_count": 16736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106820922, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09378218650817871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 523, "samples_count": 16768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821009, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08688616752624512}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 524, "samples_count": 16800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821100, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09134697914123535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 525, "samples_count": 16832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821186, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08603596687316895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 526, "samples_count": 16864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08809161186218262}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 527, "samples_count": 16896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821363, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08952975273132324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 528, "samples_count": 16928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08648943901062012}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 529, "samples_count": 16960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821539, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08875536918640137}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 530, "samples_count": 16992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821629, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08993649482727051}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 531, "samples_count": 17024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821720, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09093379974365234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 532, "samples_count": 17056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821812, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09287071228027344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 533, "samples_count": 17088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821908, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0951533317565918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 534, "samples_count": 17120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106821995, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08700203895568848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 535, "samples_count": 17152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822088, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09384799003601074}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 536, "samples_count": 17184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08935761451721191}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 537, "samples_count": 17216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09002327919006348}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 538, "samples_count": 17248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822354, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08659529685974121}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 539, "samples_count": 17280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822444, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08952069282531738}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 540, "samples_count": 17312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822531, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08699560165405273}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 541, "samples_count": 17344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822618, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08731365203857422}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 542, "samples_count": 17376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09250378608703613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 543, "samples_count": 17408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822713, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.4371635913848877, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 139264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822713, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8562166541814804}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822713, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 139264, "step": 4352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106822713, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 4352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106834018, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3512849807739258, "reduced_train_loss": 3.463613510131836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4383.0, "samples_count": 140288.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106845322, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3532381057739258, "reduced_train_loss": 3.353487491607666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4415.0, "samples_count": 141312.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106856627, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3554980754852295, "reduced_train_loss": 3.5075390338897705}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4447.0, "samples_count": 142336.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106867921, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3519001007080078, "reduced_train_loss": 3.323495388031006}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4479.0, "samples_count": 143360.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106879214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35425853729248047, "reduced_train_loss": 3.3687996864318848}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4511.0, "samples_count": 144384.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106890517, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35370922088623047, "reduced_train_loss": 3.4359490871429443}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4543.0, "samples_count": 145408.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106901819, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3538937568664551, "reduced_train_loss": 3.3918774127960205}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4575.0, "samples_count": 146432.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913121, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35350465774536133, "reduced_train_loss": 3.41562557220459}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4607.0, "samples_count": 147456.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913357, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35407733554166043}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913357, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913357, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 147456, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913437, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3227419853210449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 544, "samples_count": 17440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913525, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08835577964782715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 545, "samples_count": 17472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913610, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08494997024536133}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 546, "samples_count": 17504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08607053756713867}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 547, "samples_count": 17536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913785, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0888829231262207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 548, "samples_count": 17568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913870, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08474969863891602}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 549, "samples_count": 17600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106913956, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08633947372436523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 550, "samples_count": 17632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914045, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08875393867492676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 551, "samples_count": 17664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914131, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08553504943847656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 552, "samples_count": 17696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09399175643920898}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 553, "samples_count": 17728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10262322425842285}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 554, "samples_count": 17760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914415, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08787727355957031}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 555, "samples_count": 17792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914503, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08805465698242188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 556, "samples_count": 17824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914590, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08694052696228027}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 557, "samples_count": 17856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914680, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08997082710266113}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 558, "samples_count": 17888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914769, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08856868743896484}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 559, "samples_count": 17920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914856, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08694958686828613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 560, "samples_count": 17952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106914944, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0887606143951416}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 561, "samples_count": 17984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915031, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08670663833618164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 562, "samples_count": 18016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915121, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0898442268371582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 563, "samples_count": 18048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915213, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09256172180175781}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 564, "samples_count": 18080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915310, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09699368476867676}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 565, "samples_count": 18112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915399, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08843684196472168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 566, "samples_count": 18144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08824729919433594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 567, "samples_count": 18176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915576, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08854293823242188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 568, "samples_count": 18208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915667, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09102153778076172}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 569, "samples_count": 18240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08743023872375488}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 570, "samples_count": 18272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915844, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08953285217285156}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 571, "samples_count": 18304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106915930, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08670282363891602}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 572, "samples_count": 18336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106916018, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08789539337158203}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 573, "samples_count": 18368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106916107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08919095993041992}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 574, "samples_count": 18400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106916198, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09106993675231934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 575, "samples_count": 18432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106916203, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.412179946899414, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 147456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106916203, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8462608233094215}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106916203, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 147456, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106916203, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 4608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106927514, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3545396327972412, "reduced_train_loss": 3.364262580871582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4639.0, "samples_count": 148480.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106938820, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35075831413269043, "reduced_train_loss": 3.3331661224365234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4671.0, "samples_count": 149504.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106950117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3520169258117676, "reduced_train_loss": 3.4528613090515137}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4703.0, "samples_count": 150528.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106961415, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3520970344543457, "reduced_train_loss": 3.445148229598999}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4735.0, "samples_count": 151552.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106972713, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35311126708984375, "reduced_train_loss": 3.4369759559631348}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4767.0, "samples_count": 152576.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106984008, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.350766658782959, "reduced_train_loss": 3.4694230556488037}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4799.0, "samples_count": 153600.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760106995304, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35445713996887207, "reduced_train_loss": 3.4207494258880615}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4831.0, "samples_count": 154624.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107006587, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35388922691345215, "reduced_train_loss": 3.312713861465454}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4863.0, "samples_count": 155648.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107006820, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35397250331152463}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107006820, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 4864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107006820, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 155648, "step": 4864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107006902, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.32158422470092773}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 576, "samples_count": 18464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107006988, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08558487892150879}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 577, "samples_count": 18496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08923006057739258}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 578, "samples_count": 18528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09122252464294434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 579, "samples_count": 18560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007255, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08713984489440918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 580, "samples_count": 18592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007344, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08889961242675781}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 581, "samples_count": 18624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08782792091369629}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 582, "samples_count": 18656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007518, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08601045608520508}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 583, "samples_count": 18688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007605, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08700966835021973}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 584, "samples_count": 18720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007695, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0896596908569336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 585, "samples_count": 18752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007796, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.1011500358581543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 586, "samples_count": 18784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007889, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09351539611816406}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 587, "samples_count": 18816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107007976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08701205253601074}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 588, "samples_count": 18848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008067, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0908663272857666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 589, "samples_count": 18880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008155, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0881960391998291}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 590, "samples_count": 18912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008245, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09003806114196777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 591, "samples_count": 18944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008333, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08731436729431152}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 592, "samples_count": 18976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008424, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09113192558288574}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 593, "samples_count": 19008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008510, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08569526672363281}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 594, "samples_count": 19040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008599, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08901214599609375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 595, "samples_count": 19072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008689, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09032273292541504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 596, "samples_count": 19104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008781, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09209346771240234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 597, "samples_count": 19136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008875, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09385323524475098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 598, "samples_count": 19168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107008968, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09284305572509766}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 599, "samples_count": 19200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08969831466674805}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 600, "samples_count": 19232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009146, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08905768394470215}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 601, "samples_count": 19264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009231, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08491730690002441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 602, "samples_count": 19296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009323, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09127926826477051}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 603, "samples_count": 19328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009409, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08598685264587402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 604, "samples_count": 19360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08810615539550781}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 605, "samples_count": 19392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009587, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09028935432434082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 606, "samples_count": 19424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009679, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09171819686889648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 607, "samples_count": 19456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009682, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.3898332118988037, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 155648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009682, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.862794006243348}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 4864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009683, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 155648, "step": 4864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107009683, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 4864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107020995, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3542015552520752, "reduced_train_loss": 3.369619369506836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4895.0, "samples_count": 156672.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107032291, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35323667526245117, "reduced_train_loss": 3.4461569786071777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4927.0, "samples_count": 157696.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107043587, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3559732437133789, "reduced_train_loss": 3.4151923656463623}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4959.0, "samples_count": 158720.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107054887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3509204387664795, "reduced_train_loss": 3.3891375064849854}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 4991.0, "samples_count": 159744.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107066186, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35569262504577637, "reduced_train_loss": 3.3896639347076416}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5023.0, "samples_count": 160768.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107077492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35203075408935547, "reduced_train_loss": 3.35155987739563}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5055.0, "samples_count": 161792.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107088793, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35268282890319824, "reduced_train_loss": 3.4560296535491943}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5087.0, "samples_count": 162816.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100096, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35327625274658203, "reduced_train_loss": 3.314704179763794}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5119.0, "samples_count": 163840.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100328, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540821363349096}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100328, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 5120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100328, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 163840, "step": 5120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100409, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3196728229522705}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 608, "samples_count": 19488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100499, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08957219123840332}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 609, "samples_count": 19520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0874013900756836}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 610, "samples_count": 19552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100672, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08542513847351074}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 611, "samples_count": 19584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0885457992553711}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 612, "samples_count": 19616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08703923225402832}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 613, "samples_count": 19648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107100933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08581018447875977}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 614, "samples_count": 19680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08751177787780762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 615, "samples_count": 19712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08659958839416504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 616, "samples_count": 19744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09005546569824219}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 617, "samples_count": 19776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101301, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10410332679748535}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 618, "samples_count": 19808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101395, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09427046775817871}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 619, "samples_count": 19840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101483, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08797073364257812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 620, "samples_count": 19872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101571, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08795404434204102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 621, "samples_count": 19904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0880887508392334}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 622, "samples_count": 19936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101746, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08665084838867188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 623, "samples_count": 19968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101832, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08541274070739746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 624, "samples_count": 20000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107101922, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09050393104553223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 625, "samples_count": 20032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102010, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08747673034667969}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 626, "samples_count": 20064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102095, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0851583480834961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 627, "samples_count": 20096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09051108360290527}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 628, "samples_count": 20128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102279, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09378910064697266}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 629, "samples_count": 20160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09393596649169922}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 630, "samples_count": 20192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09154415130615234}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 631, "samples_count": 20224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102553, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08818650245666504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 632, "samples_count": 20256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102645, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09203314781188965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 633, "samples_count": 20288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102733, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08877015113830566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 634, "samples_count": 20320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102820, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08687853813171387}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 635, "samples_count": 20352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102905, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08483266830444336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 636, "samples_count": 20384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107102994, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08848261833190918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 637, "samples_count": 20416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107103085, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09109354019165039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 638, "samples_count": 20448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107103175, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08989691734313965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 639, "samples_count": 20480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107103178, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.3759031295776367, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 163840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107103178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.850537338294089}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 5120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107103178, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 163840, "step": 5120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107103178, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 5120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107114500, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3526134490966797, "reduced_train_loss": 3.303544759750366}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5151.0, "samples_count": 164864.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107125785, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35176730155944824, "reduced_train_loss": 3.4023683071136475}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5183.0, "samples_count": 165888.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107137078, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3521268367767334, "reduced_train_loss": 3.3749215602874756}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5215.0, "samples_count": 166912.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107148389, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3533635139465332, "reduced_train_loss": 3.2769722938537598}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5247.0, "samples_count": 167936.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107159687, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35292744636535645, "reduced_train_loss": 3.2481868267059326}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5279.0, "samples_count": 168960.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107170999, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35454416275024414, "reduced_train_loss": 3.317962408065796}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5311.0, "samples_count": 169984.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107182291, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540000915527344, "reduced_train_loss": 3.319620132446289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5343.0, "samples_count": 171008.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107193609, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35586071014404297, "reduced_train_loss": 3.293013334274292}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5375.0, "samples_count": 172032.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107193848, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35417805885481357}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107193848, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107193848, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 172032, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107193929, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.32657694816589355}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 640, "samples_count": 20512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194014, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08466887474060059}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 641, "samples_count": 20544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194099, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08523297309875488}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 642, "samples_count": 20576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194183, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0841827392578125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 643, "samples_count": 20608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194269, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08597373962402344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 644, "samples_count": 20640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194356, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08731889724731445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 645, "samples_count": 20672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194442, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0854339599609375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 646, "samples_count": 20704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194529, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08725094795227051}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 647, "samples_count": 20736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194616, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08653092384338379}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 648, "samples_count": 20768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194702, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08656120300292969}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 649, "samples_count": 20800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194801, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09915041923522949}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 650, "samples_count": 20832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194899, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09772849082946777}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 651, "samples_count": 20864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107194987, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08811473846435547}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 652, "samples_count": 20896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195073, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08609604835510254}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 653, "samples_count": 20928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195164, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09078454971313477}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 654, "samples_count": 20960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195250, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08571243286132812}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 655, "samples_count": 20992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195341, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09154391288757324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 656, "samples_count": 21024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195428, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08694958686828613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 657, "samples_count": 21056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08667230606079102}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 658, "samples_count": 21088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195604, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08953380584716797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 659, "samples_count": 21120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195694, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08926916122436523}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 660, "samples_count": 21152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195788, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09428548812866211}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 661, "samples_count": 21184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195881, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09287738800048828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 662, "samples_count": 21216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107195970, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08900976181030273}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 663, "samples_count": 21248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0895242691040039}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 664, "samples_count": 21280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196149, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08987998962402344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 665, "samples_count": 21312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196239, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0894930362701416}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 666, "samples_count": 21344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0901026725769043}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 667, "samples_count": 21376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196416, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08682084083557129}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 668, "samples_count": 21408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196505, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08949780464172363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 669, "samples_count": 21440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196594, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08891630172729492}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 670, "samples_count": 21472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196685, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09089517593383789}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 671, "samples_count": 21504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196685, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.3527441024780273, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 172032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196686, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8379317708313465}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196686, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 172032, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107196686, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 5376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107207988, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35317134857177734, "reduced_train_loss": 3.3743896484375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5407.0, "samples_count": 173056.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107219287, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35477137565612793, "reduced_train_loss": 3.30698561668396}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5439.0, "samples_count": 174080.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107230590, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35468149185180664, "reduced_train_loss": 3.2529730796813965}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5471.0, "samples_count": 175104.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107241877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3535466194152832, "reduced_train_loss": 3.4251725673675537}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5503.0, "samples_count": 176128.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107253182, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.354250431060791, "reduced_train_loss": 3.357555389404297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5535.0, "samples_count": 177152.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107264478, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3536076545715332, "reduced_train_loss": 3.322092056274414}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5567.0, "samples_count": 178176.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107275777, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35249757766723633, "reduced_train_loss": 3.327620029449463}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5599.0, "samples_count": 179200.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287075, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3533482551574707, "reduced_train_loss": 3.3763961791992188}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5631.0, "samples_count": 180224.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287310, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540013622969127}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287310, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 5632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287310, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 180224, "step": 5632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287392, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.32528042793273926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 672, "samples_count": 21536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287484, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09226012229919434}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 673, "samples_count": 21568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287573, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08874058723449707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 674, "samples_count": 21600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287661, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08815932273864746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 675, "samples_count": 21632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287747, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08536219596862793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 676, "samples_count": 21664}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287832, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08495974540710449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 677, "samples_count": 21696}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107287921, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08908700942993164}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 678, "samples_count": 21728}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288007, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08679080009460449}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 679, "samples_count": 21760}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288094, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08677363395690918}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 680, "samples_count": 21792}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288182, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08754897117614746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 681, "samples_count": 21824}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288282, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10016226768493652}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 682, "samples_count": 21856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288375, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09276843070983887}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 683, "samples_count": 21888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08970975875854492}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 684, "samples_count": 21920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288552, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08737063407897949}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 685, "samples_count": 21952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09071874618530273}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 686, "samples_count": 21984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08730435371398926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 687, "samples_count": 22016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288817, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08757448196411133}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 688, "samples_count": 22048}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288905, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08794116973876953}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 689, "samples_count": 22080}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107288992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08698821067810059}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 690, "samples_count": 22112}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289080, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08730483055114746}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 691, "samples_count": 22144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08857131004333496}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 692, "samples_count": 22176}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289261, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09245944023132324}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 693, "samples_count": 22208}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289356, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09578418731689453}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 694, "samples_count": 22240}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289446, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08948516845703125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 695, "samples_count": 22272}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289532, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08651494979858398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 696, "samples_count": 22304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289627, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09433984756469727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 697, "samples_count": 22336}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08838176727294922}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 698, "samples_count": 22368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289800, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08491730690002441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 699, "samples_count": 22400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08721661567687988}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 700, "samples_count": 22432}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107289976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08863210678100586}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 701, "samples_count": 22464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107290066, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09036636352539062}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 702, "samples_count": 22496}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107290156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08962702751159668}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 703, "samples_count": 22528}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107290163, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.3327159881591797, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 180224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107290163, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.8532717530615628}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 5632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107290163, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 180224, "step": 5632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107290163, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 5632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107301457, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35118579864501953, "reduced_train_loss": 3.289354085922241}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5663.0, "samples_count": 181248.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107312746, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.354489803314209, "reduced_train_loss": 3.282435417175293}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5695.0, "samples_count": 182272.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107324039, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35336756706237793, "reduced_train_loss": 3.2824625968933105}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5727.0, "samples_count": 183296.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107335327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35378575325012207, "reduced_train_loss": 3.383833408355713}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5759.0, "samples_count": 184320.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107346621, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3515620231628418, "reduced_train_loss": 3.3072516918182373}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5791.0, "samples_count": 185344.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107357910, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3518338203430176, "reduced_train_loss": 3.1974804401397705}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5823.0, "samples_count": 186368.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107369209, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3522181510925293, "reduced_train_loss": 3.340330123901367}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5855.0, "samples_count": 187392.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107380510, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35376691818237305, "reduced_train_loss": 3.2557239532470703}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5887.0, "samples_count": 188416.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107380748, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3538473236367281}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107380749, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 5888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107380749, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 188416, "step": 5888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107380830, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3263881206512451}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 704, "samples_count": 22560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107380914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0842893123626709}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 705, "samples_count": 22592}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381001, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08736920356750488}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 706, "samples_count": 22624}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381087, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08558821678161621}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 707, "samples_count": 22656}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381172, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08527088165283203}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 708, "samples_count": 22688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381261, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08911681175231934}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 709, "samples_count": 22720}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381348, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08707976341247559}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 710, "samples_count": 22752}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381434, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08595871925354004}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 711, "samples_count": 22784}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381521, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08654403686523438}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 712, "samples_count": 22816}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381606, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08560872077941895}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 713, "samples_count": 22848}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381714, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.10828971862792969}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 714, "samples_count": 22880}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381807, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09297633171081543}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 715, "samples_count": 22912}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381895, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08762764930725098}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 716, "samples_count": 22944}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107381985, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08962225914001465}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 717, "samples_count": 22976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382074, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08886098861694336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 718, "samples_count": 23008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382161, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0873420238494873}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 719, "samples_count": 23040}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382247, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08574056625366211}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 720, "samples_count": 23072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382333, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08639049530029297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 721, "samples_count": 23104}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382422, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08910107612609863}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 722, "samples_count": 23136}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382509, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0866389274597168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 723, "samples_count": 23168}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382600, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09105849266052246}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 724, "samples_count": 23200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382693, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09290790557861328}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 725, "samples_count": 23232}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382790, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09694623947143555}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 726, "samples_count": 23264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382881, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09094095230102539}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 727, "samples_count": 23296}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107382971, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09073019027709961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 728, "samples_count": 23328}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383060, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08912467956542969}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 729, "samples_count": 23360}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383145, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08459043502807617}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 730, "samples_count": 23392}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383232, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08732104301452637}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 731, "samples_count": 23424}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383322, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08986115455627441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 732, "samples_count": 23456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383408, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0860283374786377}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 733, "samples_count": 23488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383498, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08952736854553223}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 734, "samples_count": 23520}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383587, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08922672271728516}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 735, "samples_count": 23552}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383592, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.3151865005493164, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 188416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383593, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.844471814110875}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 5888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383593, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 188416, "step": 5888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107383593, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 5888}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107394903, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3521254062652588, "reduced_train_loss": 3.3644561767578125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5919.0, "samples_count": 189440.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107406203, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3532121181488037, "reduced_train_loss": 3.343881607055664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5951.0, "samples_count": 190464.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107417497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35152268409729004, "reduced_train_loss": 3.253051280975342}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 5983.0, "samples_count": 191488.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107428801, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3546102046966553, "reduced_train_loss": 3.3022661209106445}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6015.0, "samples_count": 192512.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107440099, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35457921028137207, "reduced_train_loss": 3.304015636444092}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6047.0, "samples_count": 193536.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107451395, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3519325256347656, "reduced_train_loss": 3.358096122741699}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6079.0, "samples_count": 194560.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107462695, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3542633056640625, "reduced_train_loss": 3.250990152359009}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6111.0, "samples_count": 195584.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107473982, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3526947498321533, "reduced_train_loss": 3.5278289318084717}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6143.0, "samples_count": 196608.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474217, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3540016447150265}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474217, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474218, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 196608, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474300, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.3246884346008301}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 736, "samples_count": 23584}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474387, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08672142028808594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 737, "samples_count": 23616}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474472, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08491873741149902}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 738, "samples_count": 23648}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474558, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08609461784362793}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 739, "samples_count": 23680}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08448481559753418}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 740, "samples_count": 23712}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474729, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08693814277648926}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 741, "samples_count": 23744}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474819, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0896458625793457}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 742, "samples_count": 23776}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474907, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08849668502807617}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 743, "samples_count": 23808}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107474995, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0876016616821289}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 744, "samples_count": 23840}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475085, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09028840065002441}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 745, "samples_count": 23872}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09995508193969727}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 746, "samples_count": 23904}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475275, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08979034423828125}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 747, "samples_count": 23936}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475368, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09342622756958008}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 748, "samples_count": 23968}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475454, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08533000946044922}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 749, "samples_count": 24000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475543, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08920431137084961}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 750, "samples_count": 24032}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0846107006072998}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 751, "samples_count": 24064}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08787965774536133}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 752, "samples_count": 24096}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475808, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09234142303466797}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 753, "samples_count": 24128}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08495163917541504}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 754, "samples_count": 24160}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107475982, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08887767791748047}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 755, "samples_count": 24192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476073, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09128308296203613}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 756, "samples_count": 24224}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476169, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0961751937866211}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 757, "samples_count": 24256}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476261, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09151101112365723}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 758, "samples_count": 24288}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476352, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0911412239074707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 759, "samples_count": 24320}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476441, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08891558647155762}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 760, "samples_count": 24352}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476530, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0894932746887207}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 761, "samples_count": 24384}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476617, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08671021461486816}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 762, "samples_count": 24416}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476704, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08686614036560059}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 763, "samples_count": 24448}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476790, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08637309074401855}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 764, "samples_count": 24480}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08726739883422852}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 765, "samples_count": 24512}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107476969, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0912163257598877}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 766, "samples_count": 24544}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107477059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09015250205993652}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 767, "samples_count": 24576}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107477061, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.4876489639282227, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 196608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107477061, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.84397129714489}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107477061, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 196608, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107477061, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 185, "samples_count": 8192, "step": 6144}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107488379, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35135722160339355, "reduced_train_loss": 3.3559837341308594}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6175.0, "samples_count": 197632.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107499690, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35348963737487793, "reduced_train_loss": 3.3493881225585938}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6207.0, "samples_count": 198656.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107511000, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35184669494628906, "reduced_train_loss": 3.255743980407715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6239.0, "samples_count": 199680.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107522306, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35430192947387695, "reduced_train_loss": 3.393162727355957}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6271.0, "samples_count": 200704.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107533613, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35199856758117676, "reduced_train_loss": 3.3095667362213135}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6303.0, "samples_count": 201728.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107544906, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3543128967285156, "reduced_train_loss": 3.3423092365264893}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6335.0, "samples_count": 202752.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107556190, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.3536217212677002, "reduced_train_loss": 3.3154358863830566}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6367.0, "samples_count": 203776.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107567496, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35217905044555664, "reduced_train_loss": 3.2689361572265625}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 6399.0, "samples_count": 204800.0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107567727, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"train_step_time": 0.35416268512381066}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 210, "samples_count": 8192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107567727, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 194, "samples_count": 8192, "step": 6400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107567727, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 131, "samples_count": 204800, "step": 6400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107567810, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.32007551193237305}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 768, "samples_count": 24608}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107567895, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0850677490234375}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 769, "samples_count": 24640}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107567983, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08826303482055664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 770, "samples_count": 24672}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568070, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08686566352844238}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 771, "samples_count": 24704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08580970764160156}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 772, "samples_count": 24736}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568242, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08587861061096191}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 773, "samples_count": 24768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568328, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08659124374389648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 774, "samples_count": 24800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568414, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08545565605163574}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 775, "samples_count": 24832}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568501, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08749151229858398}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 776, "samples_count": 24864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568590, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08840465545654297}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 777, "samples_count": 24896}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568689, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09934711456298828}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 778, "samples_count": 24928}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568785, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09608626365661621}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 779, "samples_count": 24960}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568875, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09031438827514648}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 780, "samples_count": 24992}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107568964, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08878302574157715}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 781, "samples_count": 25024}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.0876924991607666}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 782, "samples_count": 25056}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569139, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08690953254699707}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 783, "samples_count": 25088}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08488893508911133}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 784, "samples_count": 25120}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569312, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08787274360656738}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 785, "samples_count": 25152}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569400, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08859825134277344}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 786, "samples_count": 25184}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08641958236694336}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 787, "samples_count": 25216}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569574, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08734250068664551}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 788, "samples_count": 25248}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569671, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09668588638305664}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 789, "samples_count": 25280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569763, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09254956245422363}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 790, "samples_count": 25312}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569852, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08919715881347656}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 791, "samples_count": 25344}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107569945, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09227347373962402}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 792, "samples_count": 25376}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08583378791809082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 793, "samples_count": 25408}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08787322044372559}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 794, "samples_count": 25440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570209, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09032893180847168}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 795, "samples_count": 25472}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570295, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08604741096496582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 796, "samples_count": 25504}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08967900276184082}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 797, "samples_count": 25536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570471, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.08714604377746582}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 798, "samples_count": 25568}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570564, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_step_time": 0.09233784675598145}, "metadata": {"file": "/workspace/llm/custom_callbacks.py", "lineno": 476, "step": 799, "samples_count": 25600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570566, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 3.291362762451172, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 272, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570567, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"validation_time": 2.839953603222966}, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 163, "step": 6400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570567, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 148, "samples_count": 204800, "step": 6400}}
 0: Average train_step_time 0.35291106544435025
 0: :::MLLOG {"namespace": "", "time_ms": 1760107570571, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/mlperf_common/callbacks/logging.py", "lineno": 106, "step": 6400, "samples_count": 204800, "status": "success"}}
 0: [NeMo I 2025-10-10 09:46:10 nemo_logging:393] ======== Unregistering Distributed Connecton ========
 0: [NeMo I 2025-10-10 09:46:10 nemo_logging:393] ======== Distributed Connecton destroyed ========
 1: [rank1]:[W1010 09:46:52.884758655 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 0: [rank0]:[W1010 09:46:52.907934060 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 8: [rank8]:[W1010 09:46:52.996293909 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
17: [rank17]:[W1010 09:46:52.887102336 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
16: [rank16]:[W1010 09:46:52.899120200 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
32: [rank32]:[W1010 09:46:52.845986536 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
33: [rank33]:[W1010 09:46:52.846281146 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
40: [rank40]:[W1010 09:46:52.103419242 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
48: [rank48]:[W1010 09:46:52.986394814 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
56: [rank56]:[W1010 09:46:52.022268207 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
49: [rank49]:[W1010 09:46:52.007148941 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
24: [rank24]:[W1010 09:46:52.287197204 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
++ date +%s
+ echo 'RUNANDTIME_STOP 1760107618'
RUNANDTIME_STOP 1760107618
+ set -e
